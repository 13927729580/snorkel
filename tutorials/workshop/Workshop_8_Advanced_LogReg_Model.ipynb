{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 4: Training our End Extraction Model w/ Logisitic Regression\n",
    "\n",
    "In this final section of the tutorial, we'll use the noisy training labels we generated in the last tutorial part to train our end extraction model.\n",
    "\n",
    "For this tutorial, we will be training a simple - but fairly effective - logistic regression model.  More generally, however, Snorkel plugs in with many ML libraries including [TensorFlow](https://www.tensorflow.org/), making it easy to use almost any state-of-the-art model as the end extractor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "from lib.init import *\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We repeat our definition of the `Spouse` `Candidate` subclass, and load the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1 Training a `SparseLogReg` Discriminative Model\n",
    "We use the training marginals to train a discriminative model that classifies each `Candidate` as a true or false mention. We'll use a random hyperparameter search, evaluated on the development set labels, to find the best hyperparameters for our model. To run a hyperparameter search, we need labels for a development set. If they aren't already available, we can manually create labels using the Viewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Extraction\n",
    "Instead of using a deep learning approach to start, let's look at a standard sparse logistic regression model. First, we need to extract out features. This can take a while, but we only have to do it once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "from lib.features import hybrid_span_mention_ftrs\n",
    "\n",
    "featurizer = FeatureAnnotator()\n",
    "\n",
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev = featurizer.load_matrix(session, split=1)\n",
    "F_test = featurizer.load_matrix(session, split=2)\n",
    "\n",
    "if F_train.size == 0:    \n",
    "    %time F_train = featurizer.apply(split=0, parallelism=2, annotation_generator=hybrid_span_mention_ftrs)\n",
    "if F_dev.size == 0:     \n",
    "    %time F_dev  = featurizer.apply_existing(split=1, parallelism=2, annotation_generator=hybrid_span_mention_ftrs)\n",
    "if F_test.size == 0:\n",
    "    %time F_test = featurizer.apply_existing(split=2, parallelism=2, annotation_generator=hybrid_span_mention_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, F_train, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following code performs model selection by tuning our learning algorithm's hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 1. Search space size = 25.\n",
      "============================================================\n",
      "[1] Testing lr = 4.49e-06, l1_penalty = 1.00e-02, l2_penalty = 1.00e-04, batch_size = 512\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=17214  #epochs=2000  batch size=512\n",
      "[SparseLogisticRegression] Epoch 0 (2.01s)\tAverage loss=291.227203\n",
      "[SparseLogisticRegression] Epoch 250 (520.72s)\tAverage loss=290.167267\n",
      "[SparseLogisticRegression] Epoch 500 (1050.85s)\tAverage loss=289.672699\n",
      "[SparseLogisticRegression] Epoch 750 (1568.22s)\tAverage loss=289.481781\n",
      "[SparseLogisticRegression] Epoch 1000 (2103.25s)\tAverage loss=289.478210\n",
      "[SparseLogisticRegression] Epoch 1250 (2631.88s)\tAverage loss=289.584717\n",
      "[SparseLogisticRegression] Epoch 1500 (3171.83s)\tAverage loss=289.755707\n",
      "[SparseLogisticRegression] Epoch 1750 (3706.07s)\tAverage loss=289.960297\n",
      "[SparseLogisticRegression] Epoch 1999 (4218.17s)\tAverage loss=290.183441\n",
      "[SparseLogisticRegression] Training done (4218.17s)\n",
      "[SparseLogisticRegression] F1 Score: 0.201117318436\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/SparseLogisticRegression_0/SparseLogisticRegression_0-0\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_0>\n",
      "         lr  l1_penalty  l2_penalty  batch_size     Prec.      Rec.        F1\n",
      "0  0.000004        0.01      0.0001         512  0.214286  0.189474  0.201117\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.utils import MentionScorer\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "from snorkel.learning import SparseLogisticRegression\n",
    "disc_model = SparseLogisticRegression()\n",
    "\n",
    "# Searching over learning rate\n",
    "#rate_param        = RangeParameter('lr', 1e-6, 1e-2, step=1, log_base=10)\n",
    "rate_param        = ListParameter('lr', [0.1 / train_marginals.shape[0]])\n",
    "l1_param          = RangeParameter('l1_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "l2_param          = RangeParameter('l2_penalty', 1e-6, 1e-2, step=1, log_base=10)\n",
    "batch_size_param  = ListParameter('batch_size', [512]) # 32, 64, \n",
    "#b_param           = ListParameter('b', [0.5, 0.6, 0.7])\n",
    "#balance_param     = ListParameter('rebalance', [0.0, 0.3, 0.5])\n",
    "\n",
    "param_grid = [rate_param, l1_param, l2_param, batch_size_param] # b_param, balance_param\n",
    "\n",
    "np.random.seed(1701)\n",
    "searcher = RandomSearch(SparseLogisticRegression, param_grid, F_train,\n",
    "                        Y_train=train_marginals, n=1, n_threads=4)\n",
    "\n",
    "logreg, run_stats = searcher.fit(F_dev, L_gold_dev, n_epochs=2000, print_freq=250, n_threads=1)\n",
    "print run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Examining Features\n",
    "Extracting features allows us to inspect and interperet our learned weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363725\n",
      "[-0.44589204, u'BETWEEN_SEQ_LEMMAS[sprinkling and]']\n",
      "[-0.42697382, u'BETWEEN_SEQ_LEMMAS[february and]']\n",
      "[-0.42161661, u'WIN_RIGHT_SEQ_LEMMAS[-PRON- husband joe]']\n",
      "[-0.41500682, u'BETWEEN_SEQ_LEMMAS[yogi , grow]']\n",
      "[-0.40838289, u'WIN_RIGHT_SEQ_LEMMAS[admire throng]']\n",
      "[-0.4075236, u'WIN_LEFT_SEQ_POS_TAGS[CC NNP :]']\n",
      "[-0.40371552, u'BETWEEN_SEQ_LEMMAS[criticism ,]']\n",
      "[-0.40125224, u'BETWEEN_SEQ_LEMMAS[people like to]']\n",
      "[-0.39913782, u'BETWEEN_SEQ_LEMMAS[to lobby]']\n",
      "[-0.39903417, u'BETWEEN_SEQ_LEMMAS[dean mcdermott tell]']\n",
      "[-0.39445403, u'BETWEEN_SEQ_LEMMAS[abbott and -PRON-]']\n",
      "[-0.3905988, u'BETWEEN_SEQ_LEMMAS[into a 50-acre]']\n",
      "[-0.39038658, u'BETWEEN_SEQ_LEMMAS[and meet kim]']\n",
      "[-0.38999209, u\"BETWEEN_SEQ_LEMMAS[execution : ']\"]\n",
      "[-0.38748351, u'WIN_LEFT_SEQ_LEMMAS[-PRON- diamond ,]']\n",
      "[-0.38694522, u'WIN_RIGHT_SEQ_LEMMAS[the launch party]']\n",
      "[-0.38580975, u'BETWEEN_SEQ_LEMMAS[by question about]']\n",
      "[-0.38542014, u'WIN_RIGHT_SEQ_LEMMAS[( bass guitar]']\n",
      "[-0.38492721, u'BETWEEN_SEQ_LEMMAS[unnamed individual]']\n",
      "[-0.38465223, u'BETWEEN_SEQ_LEMMAS[of huntington]']\n",
      "[-0.3835417, u'BETWEEN_SEQ_POS_TAGS[PRP VB NNP]']\n",
      "[-0.38351706, u'BETWEEN_SEQ_LEMMAS[, geometric -]']\n",
      "[-0.38097024, u'WIN_RIGHT_SEQ_LEMMAS[sit together]']\n",
      "[-0.38064906, u'WIN_LEFT_SEQ_LEMMAS[, chrystie scott]']\n",
      "[-0.37805367, u'BETWEEN_SEQ_LEMMAS[blue slack .]']\n",
      "[-0.37718365, u'WIN_RIGHT_SEQ_POS_TAGS[, WP DT]']\n",
      "[-0.37663609, u'BETWEEN_SEQ_LEMMAS[of xxx]']\n",
      "[-0.37635615, u'BETWEEN_SEQ_LEMMAS[-PRON- pour]']\n",
      "[-0.37614524, u'BETWEEN_SEQ_LEMMAS[domestic world]']\n",
      "[-0.37612653, u'BETWEEN_SEQ_LEMMAS[a senior and]']\n",
      "[-0.37444234, u'BETWEEN_SEQ_LEMMAS[coat while]']\n",
      "[-0.37442872, u\"WIN_RIGHT_SEQ_LEMMAS[badawi 's]\"]\n",
      "[-0.37378928, u'BETWEEN_SEQ_LEMMAS[apart from -PRON-]']\n",
      "[-0.37345797, u'WIN_RIGHT_SEQ_LEMMAS[home life that]']\n",
      "[-0.37253731, u'BETWEEN_SEQ_LEMMAS[training vanish on]']\n",
      "[-0.37144673, u'BETWEEN_SEQ_LEMMAS[the new furry]']\n",
      "[-0.37080643, u'WIN_RIGHT_SEQ_LEMMAS[have long cultivate]']\n",
      "[-0.37033644, u'BETWEEN_SEQ_LEMMAS[backlash earlier]']\n",
      "[-0.37007657, u'BETWEEN_SEQ_LEMMAS[asian adventure]']\n",
      "[-0.37007645, u'BETWEEN_SEQ_LEMMAS[and bank -]']\n",
      "[-0.36902359, u'BETWEEN_SEQ_LEMMAS[india 5 day]']\n",
      "[-0.36844656, u'BETWEEN_SEQ_LEMMAS[be search  ]']\n",
      "[-0.3647134, u'WIN_RIGHT_SEQ_LEMMAS[the caption ,]']\n",
      "[-0.36461702, u'BETWEEN_SEQ_LEMMAS[smoking \\u2013]']\n",
      "[-0.36424354, u'BETWEEN_SEQ_POS_TAGS[CD NNPS POS]']\n",
      "[-0.36397859, u'BETWEEN_SEQ_LEMMAS[national and]']\n",
      "[-0.36325809, u'WIN_RIGHT_SEQ_LEMMAS[, would often]']\n",
      "[-0.36286876, u'BETWEEN_SEQ_LEMMAS[corn - silk]']\n",
      "[-0.36233309, u'BETWEEN_SEQ_LEMMAS[\\xa0    radio 1]']\n",
      "[-0.36187536, u'BETWEEN_SEQ_LEMMAS[-PRON- classical]']\n",
      "--------------------\n",
      "[0.37013224, u\"WIN_LEFT_SEQ_LEMMAS[' stand]\"]\n",
      "[0.37021971, u'BETWEEN_SEQ_LEMMAS[initially go]']\n",
      "[0.37024397, u'WIN_RIGHT_SEQ_LEMMAS[private dinner]']\n",
      "[0.37067774, u'BETWEEN_SEQ_LEMMAS[kill father vincent]']\n",
      "[0.37138969, u'BETWEEN_SEQ_LEMMAS[( from]']\n",
      "[0.37181422, u'BETWEEN_SEQ_LEMMAS[stanley matthews ,]']\n",
      "[0.37208942, u'BETWEEN_SEQ_LEMMAS[high profile]']\n",
      "[0.37223002, u'BETWEEN_SEQ_LEMMAS[- blaney ,]']\n",
      "[0.37265, u'BETWEEN_SEQ_LEMMAS[however and]']\n",
      "[0.37447315, u'BETWEEN_SEQ_LEMMAS[and three count]']\n",
      "[0.37624493, u'WIN_RIGHT_SEQ_LEMMAS[clan at]']\n",
      "[0.37626606, u'WIN_RIGHT_SEQ_LEMMAS[of which -PRON-]']\n",
      "[0.3765201, u'BETWEEN_SEQ_LEMMAS[of idea]']\n",
      "[0.37703595, u'BETWEEN_SEQ_LEMMAS[be maul]']\n",
      "[0.377478, u'BETWEEN_SEQ_LEMMAS[   yesterday ,]']\n",
      "[0.37827164, u'BETWEEN_SEQ_LEMMAS[solo adventure be]']\n",
      "[0.3795757, u'BETWEEN_SEQ_LEMMAS[be singularly focused]']\n",
      "[0.3801451, u\"BETWEEN_SEQ_POS_TAGS['' WRB TO]\"]\n",
      "[0.38095585, u'WIN_LEFT_SEQ_LEMMAS[also speak]']\n",
      "[0.38163987, u'WIN_LEFT_SEQ_LEMMAS[during the 1980]']\n",
      "[0.38235629, u'BETWEEN_SEQ_LEMMAS[democratic chairman dick]']\n",
      "[0.38259667, u'WIN_LEFT_SEQ_LEMMAS[convince -PRON- lover]']\n",
      "[0.38300401, u'BETWEEN_SEQ_LEMMAS[) shield -PRON-]']\n",
      "[0.38408905, u'BETWEEN_SEQ_LEMMAS[job quality that]']\n",
      "[0.38449818, u'BETWEEN_SEQ_LEMMAS[primary win]']\n",
      "[0.38457471, u'BETWEEN_SEQ_LEMMAS[: a cat]']\n",
      "[0.38636065, u'BETWEEN_SEQ_LEMMAS[use for]']\n",
      "[0.39146101, u'WIN_LEFT_SEQ_LEMMAS[as effective]']\n",
      "[0.39254898, u'BETWEEN_SEQ_LEMMAS[famous thank to]']\n",
      "[0.3927145, u'BETWEEN_SEQ_LEMMAS[xmit : liberty]']\n",
      "[0.39277765, u'WIN_LEFT_LEMMAS[rande]']\n",
      "[0.39390758, u'WIN_RIGHT_SEQ_LEMMAS[back against those]']\n",
      "[0.3940675, u'WIN_RIGHT_SEQ_LEMMAS[( stana katic]']\n",
      "[0.39673242, u'WIN_LEFT_SEQ_LEMMAS[emmy award be]']\n",
      "[0.40142515, u'BETWEEN_SEQ_LEMMAS[may have create]']\n",
      "[0.40327644, u'BETWEEN_SEQ_LEMMAS[take solace]']\n",
      "[0.40439841, u'WIN_RIGHT_SEQ_LEMMAS[in -PRON- high]']\n",
      "[0.41033521, u'BETWEEN_SEQ_LEMMAS[test at]']\n",
      "[0.41039661, u'BETWEEN_SEQ_LEMMAS[manchester united]']\n",
      "[0.41194037, u'BETWEEN_SEQ_LEMMAS[for fingerprint]']\n",
      "[0.41255167, u'BETWEEN_SEQ_LEMMAS[also notice]']\n",
      "[0.41713202, u'BETWEEN_SEQ_LEMMAS[that the family]']\n",
      "[0.42070484, u'WIN_RIGHT_SEQ_LEMMAS[some thing]']\n",
      "[0.42168251, u'WIN_RIGHT_SEQ_LEMMAS[\\u2019s mother]']\n",
      "[0.42220843, u'BETWEEN_SEQ_LEMMAS[of the child]']\n",
      "[0.4233335, u'BETWEEN_SEQ_LEMMAS[strength to carry]']\n",
      "[0.44332573, u'WIN_LEFT_SEQ_LEMMAS[screen siren julianne]']\n",
      "[0.45240831, u'BETWEEN_SEQ_LEMMAS[on saturday -]']\n",
      "[0.47971275, u'WIN_LEFT_SEQ_LEMMAS[-PRON- or]']\n"
     ]
    }
   ],
   "source": [
    "from lib.scoring import *\n",
    "print_top_k_features(session, logreg, F_train, top_k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, _, _, _ = disc_model.score(session, F_test, L_gold_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
