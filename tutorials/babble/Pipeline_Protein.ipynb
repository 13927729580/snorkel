{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'protein',\n",
    "    'postgres': False,\n",
    "    'debug': False,\n",
    "    'babbler_candidate_split': 1,\n",
    "    'babbler_label_split': 1,\n",
    "    'supervision': 'traditional',\n",
    "    'traditional_split': 1,\n",
    "    'disc_model_class': 'logreg',    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_protein.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting domain=None to domain=protein\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting supervision=generative to supervision=traditional\n",
      "Overwriting traditional_split=0 to traditional_split=1\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "if config['debug']:\n",
    "    print(\"NOTE: --debug=True: modifying parameters...\")\n",
    "    config['max_docs'] = 100\n",
    "    config['gen_model_search_space'] = 1\n",
    "    config['disc_model_search_space'] = 1\n",
    "    config['gen_params_default']['epochs'] = 25\n",
    "    config['disc_params_default']['n_epochs'] = 5\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe.babbler.filtered_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...skipping 'supervise' stage.\n",
      "CPU times: user 359 µs, sys: 220 µs, total: 579 µs\n",
      "Wall time: 428 µs\n"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...grabbing candidate and gold label subsets.\n",
      "NOTE: using split 1 for traditional supervision. Be aware of unfair evaluation.\n",
      "NOTE: traditional supervision helper assumes all candidates have labels.\n",
      "No value found for max_train. Using all available gold labels.\n",
      "Using 1168 traditional gold labels\n",
      "(1168,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104ec5f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [7.1] Begin training discriminative model\n",
      "============================================================\n",
      "[1] Testing dim = 64, dropout = 2.50e-01, rebalance = 0.00e+00, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=1168  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.05s)\tAverage loss=0.753161\tDev F1=31.51\n",
      "[SparseLogisticRegression] Epoch 1 (0.14s)\tAverage loss=0.667256\tDev F1=33.03\n",
      "[SparseLogisticRegression] Epoch 2 (0.21s)\tAverage loss=0.614904\tDev F1=34.81\n",
      "[SparseLogisticRegression] Epoch 3 (0.29s)\tAverage loss=0.555658\tDev F1=36.36\n",
      "[SparseLogisticRegression] Epoch 4 (0.37s)\tAverage loss=0.514127\tDev F1=38.66\n",
      "[SparseLogisticRegression] Epoch 5 (0.45s)\tAverage loss=0.481751\tDev F1=36.68\n",
      "[SparseLogisticRegression] Epoch 6 (0.53s)\tAverage loss=0.464190\tDev F1=38.18\n",
      "[SparseLogisticRegression] Epoch 7 (0.61s)\tAverage loss=0.430826\tDev F1=38.73\n",
      "[SparseLogisticRegression] Epoch 8 (0.69s)\tAverage loss=0.425461\tDev F1=39.74\n",
      "[SparseLogisticRegression] Epoch 9 (0.77s)\tAverage loss=0.397043\tDev F1=39.46\n",
      "[SparseLogisticRegression] Epoch 10 (0.85s)\tAverage loss=0.399909\tDev F1=40.80\n",
      "[SparseLogisticRegression] Epoch 11 (0.92s)\tAverage loss=0.367147\tDev F1=40.68\n",
      "[SparseLogisticRegression] Epoch 12 (1.00s)\tAverage loss=0.358104\tDev F1=42.57\n",
      "[SparseLogisticRegression] Epoch 13 (1.08s)\tAverage loss=0.348996\tDev F1=43.24\n",
      "[SparseLogisticRegression] Epoch 14 (1.16s)\tAverage loss=0.343099\tDev F1=45.33\n",
      "[SparseLogisticRegression] Epoch 15 (1.24s)\tAverage loss=0.336432\tDev F1=46.51\n",
      "[SparseLogisticRegression] Epoch 16 (1.32s)\tAverage loss=0.330069\tDev F1=48.84\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.59s)\tAverage loss=0.314916\tDev F1=51.47\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (2.01s)\tAverage loss=0.309627\tDev F1=53.55\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.33s)\tAverage loss=0.293040\tDev F1=55.13\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.74s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.551282051282\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "============================================================\n",
      "[2] Testing dim = 128, dropout = 5.00e-01, rebalance = 2.50e-01, lr = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=896  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.04s)\tAverage loss=0.785985\tDev F1=26.70\n",
      "[SparseLogisticRegression] Epoch 1 (0.11s)\tAverage loss=0.779710\tDev F1=26.71\n",
      "[SparseLogisticRegression] Epoch 2 (0.18s)\tAverage loss=0.773630\tDev F1=26.91\n",
      "[SparseLogisticRegression] Epoch 3 (0.25s)\tAverage loss=0.767673\tDev F1=26.79\n",
      "[SparseLogisticRegression] Epoch 4 (0.32s)\tAverage loss=0.761827\tDev F1=26.63\n",
      "[SparseLogisticRegression] Epoch 5 (0.38s)\tAverage loss=0.756013\tDev F1=26.51\n",
      "[SparseLogisticRegression] Epoch 6 (0.45s)\tAverage loss=0.750478\tDev F1=26.86\n",
      "[SparseLogisticRegression] Epoch 7 (0.52s)\tAverage loss=0.744738\tDev F1=27.22\n",
      "[SparseLogisticRegression] Epoch 8 (0.59s)\tAverage loss=0.739290\tDev F1=26.82\n",
      "[SparseLogisticRegression] Epoch 9 (0.65s)\tAverage loss=0.733845\tDev F1=27.17\n",
      "[SparseLogisticRegression] Epoch 10 (0.72s)\tAverage loss=0.728495\tDev F1=26.96\n",
      "[SparseLogisticRegression] Epoch 11 (0.79s)\tAverage loss=0.723238\tDev F1=26.46\n",
      "[SparseLogisticRegression] Epoch 12 (0.86s)\tAverage loss=0.718137\tDev F1=26.47\n",
      "[SparseLogisticRegression] Epoch 13 (0.93s)\tAverage loss=0.713026\tDev F1=26.43\n",
      "[SparseLogisticRegression] Epoch 14 (0.99s)\tAverage loss=0.707972\tDev F1=26.87\n",
      "[SparseLogisticRegression] Epoch 15 (1.06s)\tAverage loss=0.703095\tDev F1=27.17\n",
      "[SparseLogisticRegression] Epoch 16 (1.12s)\tAverage loss=0.698177\tDev F1=26.99\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.52s)\tAverage loss=0.693467\tDev F1=27.13\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (1.80s)\tAverage loss=0.688743\tDev F1=27.06\n",
      "[SparseLogisticRegression] Epoch 19 (1.87s)\tAverage loss=0.684110\tDev F1=27.29\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.26s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.272863568216\n",
      "============================================================\n",
      "[3] Testing dim = 128, dropout = 1.00e-01, rebalance = 5.00e-01, lr = 1.00e-02\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=448  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=0.680773\tDev F1=46.35\n",
      "[SparseLogisticRegression] Epoch 1 (0.07s)\tAverage loss=0.492259\tDev F1=57.66\n",
      "[SparseLogisticRegression] Epoch 2 (0.12s)\tAverage loss=0.394538\tDev F1=61.72\n",
      "[SparseLogisticRegression] Epoch 3 (0.17s)\tAverage loss=0.324160\tDev F1=64.01\n",
      "[SparseLogisticRegression] Epoch 4 (0.23s)\tAverage loss=0.277162\tDev F1=66.36\n",
      "[SparseLogisticRegression] Epoch 5 (0.28s)\tAverage loss=0.238048\tDev F1=67.71\n",
      "[SparseLogisticRegression] Epoch 6 (0.33s)\tAverage loss=0.209814\tDev F1=68.34\n",
      "[SparseLogisticRegression] Epoch 7 (0.37s)\tAverage loss=0.189157\tDev F1=68.97\n",
      "[SparseLogisticRegression] Epoch 8 (0.42s)\tAverage loss=0.172287\tDev F1=68.75\n",
      "[SparseLogisticRegression] Epoch 9 (0.47s)\tAverage loss=0.154686\tDev F1=68.97\n",
      "[SparseLogisticRegression] Epoch 10 (0.52s)\tAverage loss=0.140384\tDev F1=68.97\n",
      "[SparseLogisticRegression] Epoch 11 (0.57s)\tAverage loss=0.136767\tDev F1=69.61\n",
      "[SparseLogisticRegression] Epoch 12 (0.62s)\tAverage loss=0.123637\tDev F1=70.27\n",
      "[SparseLogisticRegression] Epoch 13 (0.67s)\tAverage loss=0.114177\tDev F1=70.49\n",
      "[SparseLogisticRegression] Epoch 14 (0.72s)\tAverage loss=0.108040\tDev F1=70.81\n",
      "[SparseLogisticRegression] Epoch 15 (0.77s)\tAverage loss=0.101257\tDev F1=70.93\n",
      "[SparseLogisticRegression] Epoch 16 (0.82s)\tAverage loss=0.095968\tDev F1=71.04\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.19s)\tAverage loss=0.094558\tDev F1=70.93\n",
      "[SparseLogisticRegression] Epoch 18 (1.24s)\tAverage loss=0.084565\tDev F1=70.91\n",
      "[SparseLogisticRegression] Epoch 19 (1.29s)\tAverage loss=0.079849\tDev F1=70.79\n",
      "[SparseLogisticRegression] Training done (1.33s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.7104\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_2>\n",
      "============================================================\n",
      "[4] Testing dim = 64, dropout = 5.00e-01, rebalance = 5.00e-01, lr = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=448  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=0.756589\tDev F1=25.24\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.761167\tDev F1=25.77\n",
      "[SparseLogisticRegression] Epoch 2 (0.12s)\tAverage loss=0.757133\tDev F1=26.04\n",
      "[SparseLogisticRegression] Epoch 3 (0.17s)\tAverage loss=0.743115\tDev F1=26.57\n",
      "[SparseLogisticRegression] Epoch 4 (0.22s)\tAverage loss=0.745388\tDev F1=26.98\n",
      "[SparseLogisticRegression] Epoch 5 (0.28s)\tAverage loss=0.743137\tDev F1=27.08\n",
      "[SparseLogisticRegression] Epoch 6 (0.45s)\tAverage loss=0.737918\tDev F1=27.11\n",
      "[SparseLogisticRegression] Epoch 7 (0.50s)\tAverage loss=0.742319\tDev F1=27.21\n",
      "[SparseLogisticRegression] Epoch 8 (0.55s)\tAverage loss=0.743338\tDev F1=27.18\n",
      "[SparseLogisticRegression] Epoch 9 (0.60s)\tAverage loss=0.737389\tDev F1=27.24\n",
      "[SparseLogisticRegression] Epoch 10 (0.65s)\tAverage loss=0.735665\tDev F1=27.75\n",
      "[SparseLogisticRegression] Epoch 11 (0.70s)\tAverage loss=0.733055\tDev F1=28.02\n",
      "[SparseLogisticRegression] Epoch 12 (0.75s)\tAverage loss=0.733908\tDev F1=28.09\n",
      "[SparseLogisticRegression] Epoch 13 (0.80s)\tAverage loss=0.735979\tDev F1=28.19\n",
      "[SparseLogisticRegression] Epoch 14 (0.85s)\tAverage loss=0.726618\tDev F1=28.47\n",
      "[SparseLogisticRegression] Epoch 15 (0.90s)\tAverage loss=0.727261\tDev F1=28.88\n",
      "[SparseLogisticRegression] Epoch 16 (0.96s)\tAverage loss=0.718335\tDev F1=28.88\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.21s)\tAverage loss=0.714791\tDev F1=28.88\n",
      "[SparseLogisticRegression] Epoch 18 (1.26s)\tAverage loss=0.718126\tDev F1=29.02\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (1.64s)\tAverage loss=0.717267\tDev F1=29.44\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (1.90s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.294403892944\n",
      "============================================================\n",
      "[5] Testing dim = 128, dropout = 1.00e-01, rebalance = 5.00e-01, lr = 1.00e-02\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=448  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=0.740907\tDev F1=42.50\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.532190\tDev F1=54.65\n",
      "[SparseLogisticRegression] Epoch 2 (0.13s)\tAverage loss=0.428905\tDev F1=59.44\n",
      "[SparseLogisticRegression] Epoch 3 (0.18s)\tAverage loss=0.347622\tDev F1=61.92\n",
      "[SparseLogisticRegression] Epoch 4 (0.23s)\tAverage loss=0.299225\tDev F1=62.90\n",
      "[SparseLogisticRegression] Epoch 5 (0.28s)\tAverage loss=0.254658\tDev F1=64.70\n",
      "[SparseLogisticRegression] Epoch 6 (0.33s)\tAverage loss=0.225541\tDev F1=67.07\n",
      "[SparseLogisticRegression] Epoch 7 (0.38s)\tAverage loss=0.202699\tDev F1=68.74\n",
      "[SparseLogisticRegression] Epoch 8 (0.43s)\tAverage loss=0.182441\tDev F1=69.50\n",
      "[SparseLogisticRegression] Epoch 9 (0.48s)\tAverage loss=0.164810\tDev F1=69.83\n",
      "[SparseLogisticRegression] Epoch 10 (0.53s)\tAverage loss=0.149491\tDev F1=70.27\n",
      "[SparseLogisticRegression] Epoch 11 (0.58s)\tAverage loss=0.144373\tDev F1=70.61\n",
      "[SparseLogisticRegression] Epoch 12 (0.63s)\tAverage loss=0.131234\tDev F1=71.18\n",
      "[SparseLogisticRegression] Epoch 13 (0.68s)\tAverage loss=0.120650\tDev F1=71.15\n",
      "[SparseLogisticRegression] Epoch 14 (0.73s)\tAverage loss=0.114210\tDev F1=71.27\n",
      "[SparseLogisticRegression] Epoch 15 (0.78s)\tAverage loss=0.106173\tDev F1=71.38\n",
      "[SparseLogisticRegression] Epoch 16 (0.83s)\tAverage loss=0.101135\tDev F1=71.50\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.07s)\tAverage loss=0.098536\tDev F1=71.50\n",
      "[SparseLogisticRegression] Epoch 18 (1.12s)\tAverage loss=0.088667\tDev F1=71.79\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (1.49s)\tAverage loss=0.083681\tDev F1=71.91\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (1.74s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.719101123596\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_4>\n",
      "============================================================\n",
      "[6] Testing dim = 128, dropout = 1.00e-01, rebalance = 5.00e-01, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=448  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=0.731857\tDev F1=28.45\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.705880\tDev F1=30.85\n",
      "[SparseLogisticRegression] Epoch 2 (0.12s)\tAverage loss=0.684971\tDev F1=32.78\n",
      "[SparseLogisticRegression] Epoch 3 (0.17s)\tAverage loss=0.669396\tDev F1=35.13\n",
      "[SparseLogisticRegression] Epoch 4 (0.22s)\tAverage loss=0.651086\tDev F1=36.62\n",
      "[SparseLogisticRegression] Epoch 5 (0.27s)\tAverage loss=0.630362\tDev F1=38.24\n",
      "[SparseLogisticRegression] Epoch 6 (0.32s)\tAverage loss=0.610987\tDev F1=39.43\n",
      "[SparseLogisticRegression] Epoch 7 (0.37s)\tAverage loss=0.590510\tDev F1=41.77\n",
      "[SparseLogisticRegression] Epoch 8 (0.42s)\tAverage loss=0.585767\tDev F1=43.37\n",
      "[SparseLogisticRegression] Epoch 9 (0.48s)\tAverage loss=0.567352\tDev F1=44.64\n",
      "[SparseLogisticRegression] Epoch 10 (0.53s)\tAverage loss=0.549096\tDev F1=45.26\n",
      "[SparseLogisticRegression] Epoch 11 (0.59s)\tAverage loss=0.543283\tDev F1=46.96\n",
      "[SparseLogisticRegression] Epoch 12 (0.63s)\tAverage loss=0.527933\tDev F1=48.55\n",
      "[SparseLogisticRegression] Epoch 13 (0.69s)\tAverage loss=0.511494\tDev F1=49.71\n",
      "[SparseLogisticRegression] Epoch 14 (0.74s)\tAverage loss=0.504773\tDev F1=50.58\n",
      "[SparseLogisticRegression] Epoch 15 (0.80s)\tAverage loss=0.494613\tDev F1=51.55\n",
      "[SparseLogisticRegression] Epoch 16 (0.85s)\tAverage loss=0.483552\tDev F1=52.74\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.24s)\tAverage loss=0.470944\tDev F1=53.67\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (1.50s)\tAverage loss=0.460452\tDev F1=54.04\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (1.93s)\tAverage loss=0.452747\tDev F1=55.51\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.21s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.555066079295\n",
      "============================================================\n",
      "[7] Testing dim = 128, dropout = 1.00e-01, rebalance = 2.50e-01, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=896  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.05s)\tAverage loss=0.703072\tDev F1=30.32\n",
      "[SparseLogisticRegression] Epoch 1 (0.11s)\tAverage loss=0.656047\tDev F1=31.79\n",
      "[SparseLogisticRegression] Epoch 2 (0.18s)\tAverage loss=0.615090\tDev F1=32.98\n",
      "[SparseLogisticRegression] Epoch 3 (0.25s)\tAverage loss=0.581133\tDev F1=36.33\n",
      "[SparseLogisticRegression] Epoch 4 (0.44s)\tAverage loss=0.551824\tDev F1=36.28\n",
      "[SparseLogisticRegression] Epoch 5 (0.51s)\tAverage loss=0.526473\tDev F1=37.77\n",
      "[SparseLogisticRegression] Epoch 6 (0.57s)\tAverage loss=0.504564\tDev F1=38.97\n",
      "[SparseLogisticRegression] Epoch 7 (0.65s)\tAverage loss=0.484906\tDev F1=39.68\n",
      "[SparseLogisticRegression] Epoch 8 (0.72s)\tAverage loss=0.467882\tDev F1=41.90\n",
      "[SparseLogisticRegression] Epoch 9 (0.80s)\tAverage loss=0.452143\tDev F1=43.06\n",
      "[SparseLogisticRegression] Epoch 10 (0.87s)\tAverage loss=0.438219\tDev F1=43.99\n",
      "[SparseLogisticRegression] Epoch 11 (0.94s)\tAverage loss=0.425465\tDev F1=46.43\n",
      "[SparseLogisticRegression] Epoch 12 (1.00s)\tAverage loss=0.413434\tDev F1=47.93\n",
      "[SparseLogisticRegression] Epoch 13 (1.07s)\tAverage loss=0.402047\tDev F1=50.75\n",
      "[SparseLogisticRegression] Epoch 14 (1.14s)\tAverage loss=0.391831\tDev F1=54.39\n",
      "[SparseLogisticRegression] Epoch 15 (1.21s)\tAverage loss=0.381823\tDev F1=55.81\n",
      "[SparseLogisticRegression] Epoch 16 (1.28s)\tAverage loss=0.372819\tDev F1=60.80\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.57s)\tAverage loss=0.363895\tDev F1=62.75\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (2.01s)\tAverage loss=0.355711\tDev F1=66.48\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.32s)\tAverage loss=0.347794\tDev F1=68.13\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.72s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.681318681319\n",
      "============================================================\n",
      "[8] Testing dim = 128, dropout = 5.00e-01, rebalance = 5.00e-01, lr = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=448  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.03s)\tAverage loss=0.698565\tDev F1=34.32\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.697875\tDev F1=34.53\n",
      "[SparseLogisticRegression] Epoch 2 (0.14s)\tAverage loss=0.697597\tDev F1=34.60\n",
      "[SparseLogisticRegression] Epoch 3 (0.19s)\tAverage loss=0.699656\tDev F1=34.54\n",
      "[SparseLogisticRegression] Epoch 4 (0.24s)\tAverage loss=0.701194\tDev F1=34.75\n",
      "[SparseLogisticRegression] Epoch 5 (0.29s)\tAverage loss=0.693448\tDev F1=34.89\n",
      "[SparseLogisticRegression] Epoch 6 (0.34s)\tAverage loss=0.694484\tDev F1=35.00\n",
      "[SparseLogisticRegression] Epoch 7 (0.39s)\tAverage loss=0.680209\tDev F1=35.04\n",
      "[SparseLogisticRegression] Epoch 8 (0.44s)\tAverage loss=0.686711\tDev F1=35.15\n",
      "[SparseLogisticRegression] Epoch 9 (0.50s)\tAverage loss=0.685585\tDev F1=35.18\n",
      "[SparseLogisticRegression] Epoch 10 (0.55s)\tAverage loss=0.678207\tDev F1=35.22\n",
      "[SparseLogisticRegression] Epoch 11 (0.60s)\tAverage loss=0.681872\tDev F1=35.37\n",
      "[SparseLogisticRegression] Epoch 12 (0.66s)\tAverage loss=0.673798\tDev F1=35.41\n",
      "[SparseLogisticRegression] Epoch 13 (0.71s)\tAverage loss=0.676008\tDev F1=35.52\n",
      "[SparseLogisticRegression] Epoch 14 (0.78s)\tAverage loss=0.675225\tDev F1=35.56\n",
      "[SparseLogisticRegression] Epoch 15 (0.84s)\tAverage loss=0.664061\tDev F1=35.67\n",
      "[SparseLogisticRegression] Epoch 16 (0.88s)\tAverage loss=0.670458\tDev F1=35.88\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.25s)\tAverage loss=0.662376\tDev F1=35.92\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (1.50s)\tAverage loss=0.669711\tDev F1=36.31\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (1.91s)\tAverage loss=0.665940\tDev F1=36.46\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.35s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.36460554371\n",
      "============================================================\n",
      "[9] Testing dim = 128, dropout = 2.50e-01, rebalance = 2.50e-01, lr = 1.00e-02\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=896  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.04s)\tAverage loss=0.615037\tDev F1=29.74\n",
      "[SparseLogisticRegression] Epoch 1 (0.11s)\tAverage loss=0.402543\tDev F1=44.67\n",
      "[SparseLogisticRegression] Epoch 2 (0.18s)\tAverage loss=0.316907\tDev F1=70.99\n",
      "[SparseLogisticRegression] Epoch 3 (0.25s)\tAverage loss=0.257302\tDev F1=78.55\n",
      "[SparseLogisticRegression] Epoch 4 (0.32s)\tAverage loss=0.215800\tDev F1=84.13\n",
      "[SparseLogisticRegression] Epoch 5 (0.39s)\tAverage loss=0.186496\tDev F1=89.20\n",
      "[SparseLogisticRegression] Epoch 6 (0.45s)\tAverage loss=0.164121\tDev F1=91.65\n",
      "[SparseLogisticRegression] Epoch 7 (0.52s)\tAverage loss=0.147189\tDev F1=92.41\n",
      "[SparseLogisticRegression] Epoch 8 (0.59s)\tAverage loss=0.133079\tDev F1=93.81\n",
      "[SparseLogisticRegression] Epoch 9 (0.65s)\tAverage loss=0.122265\tDev F1=93.65\n",
      "[SparseLogisticRegression] Epoch 10 (0.73s)\tAverage loss=0.112281\tDev F1=93.45\n",
      "[SparseLogisticRegression] Epoch 11 (0.79s)\tAverage loss=0.103815\tDev F1=94.14\n",
      "[SparseLogisticRegression] Epoch 12 (0.85s)\tAverage loss=0.096623\tDev F1=94.35\n",
      "[SparseLogisticRegression] Epoch 13 (0.92s)\tAverage loss=0.090430\tDev F1=94.81\n",
      "[SparseLogisticRegression] Epoch 14 (0.99s)\tAverage loss=0.084873\tDev F1=94.60\n",
      "[SparseLogisticRegression] Epoch 15 (1.06s)\tAverage loss=0.079847\tDev F1=94.60\n",
      "[SparseLogisticRegression] Epoch 16 (1.13s)\tAverage loss=0.075323\tDev F1=94.40\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.52s)\tAverage loss=0.071279\tDev F1=94.60\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (1.80s)\tAverage loss=0.067722\tDev F1=94.81\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.21s)\tAverage loss=0.064383\tDev F1=94.83\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.48s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.948275862069\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_8>\n",
      "============================================================\n",
      "[10] Testing dim = 128, dropout = 5.00e-01, rebalance = 2.50e-01, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=896  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.04s)\tAverage loss=0.718790\tDev F1=30.01\n",
      "[SparseLogisticRegression] Epoch 1 (0.11s)\tAverage loss=0.669739\tDev F1=30.28\n",
      "[SparseLogisticRegression] Epoch 2 (0.17s)\tAverage loss=0.628487\tDev F1=33.16\n",
      "[SparseLogisticRegression] Epoch 3 (0.24s)\tAverage loss=0.592492\tDev F1=36.54\n",
      "[SparseLogisticRegression] Epoch 4 (0.31s)\tAverage loss=0.562337\tDev F1=37.26\n",
      "[SparseLogisticRegression] Epoch 5 (0.38s)\tAverage loss=0.535686\tDev F1=38.43\n",
      "[SparseLogisticRegression] Epoch 6 (0.45s)\tAverage loss=0.513071\tDev F1=40.00\n",
      "[SparseLogisticRegression] Epoch 7 (0.52s)\tAverage loss=0.492610\tDev F1=41.45\n",
      "[SparseLogisticRegression] Epoch 8 (0.58s)\tAverage loss=0.475038\tDev F1=43.01\n",
      "[SparseLogisticRegression] Epoch 9 (0.65s)\tAverage loss=0.458735\tDev F1=45.90\n",
      "[SparseLogisticRegression] Epoch 10 (0.72s)\tAverage loss=0.444312\tDev F1=49.30\n",
      "[SparseLogisticRegression] Epoch 11 (0.79s)\tAverage loss=0.431148\tDev F1=52.27\n",
      "[SparseLogisticRegression] Epoch 12 (0.85s)\tAverage loss=0.418902\tDev F1=55.68\n",
      "[SparseLogisticRegression] Epoch 13 (0.92s)\tAverage loss=0.407228\tDev F1=58.36\n",
      "[SparseLogisticRegression] Epoch 14 (0.99s)\tAverage loss=0.396676\tDev F1=61.06\n",
      "[SparseLogisticRegression] Epoch 15 (1.06s)\tAverage loss=0.386564\tDev F1=63.16\n",
      "[SparseLogisticRegression] Epoch 16 (1.13s)\tAverage loss=0.377317\tDev F1=64.46\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.38s)\tAverage loss=0.368290\tDev F1=65.57\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (1.78s)\tAverage loss=0.359945\tDev F1=67.76\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.08s)\tAverage loss=0.351851\tDev F1=69.57\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.48s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.695652173913\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_8>\n",
      "   dim  dropout  rebalance      lr     Prec.      Rec.     F-1.0\n",
      "8  128     0.25       0.25  0.0100  0.916667  0.982143  0.948276\n",
      "4  128     0.10       0.50  0.0100  0.561404  1.000000  0.719101\n",
      "2  128     0.10       0.50  0.0100  0.553616  0.991071  0.710400\n",
      "9  128     0.50       0.25  0.0010  0.888889  0.571429  0.695652\n",
      "6  128     0.10       0.25  0.0010  0.885714  0.553571  0.681319\n",
      "5  128     0.10       0.50  0.0010  0.413567  0.843750  0.555066\n",
      "0   64     0.25       0.00  0.0010  0.977273  0.383929  0.551282\n",
      "7  128     0.50       0.50  0.0001  0.239496  0.763393  0.364606\n",
      "3   64     0.50       0.50  0.0001  0.202341  0.540179  0.294404\n",
      "1  128     0.50       0.25  0.0001  0.205418  0.406250  0.272864\n",
      "[SparseLogisticRegression] Model saved as <discriminative_protein>\n",
      "### Done in 27.0s.\n",
      "\n",
      "### [7.2] Evaluate generative model (opt_b=0.5)\n",
      "gen_model is undefined. Skipping.\n",
      "### Done in 0.0s.\n",
      "\n",
      "### [7.3] Evaluate discriminative model (opt_b=0.5)\n",
      "### Done in 0.0s.\n",
      "\n",
      "      F1 Score  Precision   Recall\n",
      "Disc  0.545894   0.610811  0.49345\n",
      "CPU times: user 37.9 s, sys: 2.73 s, total: 40.6 s\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
