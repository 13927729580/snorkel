{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to find candidates for explanations that do not have a candidate for consistency checking. For each explanation missing a candidate, loop through the candidates until you find one that matches. Confirm that the parse of the function is the right one, then move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'protein',\n",
    "    'debug': False,\n",
    "    'postgres': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_protein.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gen_f_beta=0.5 to gen_f_beta=1.0\n",
      "Overwriting domain=None to domain=protein\n",
      "Overwriting babbler_candidate_split=1 to babbler_candidate_split=[0, 1, 2]\n",
      "Overwriting traditional_split=0 to traditional_split=1\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = session.query(pipe.candidate_class).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7615"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WARNING: hardcoded\n",
    "from tutorials.babble.protein.protein_examples import get_explanations, get_user_lists\n",
    "# WARNING: hardcoded\n",
    "\n",
    "explanations = get_explanations()\n",
    "user_lists = get_user_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import Explanation\n",
    "\n",
    "explanations = [\n",
    "    Explanation(\n",
    "        name='LF_between_before',\n",
    "        label=True,\n",
    "        condition=\"\"\"the word \"between\" is within 50 caracters before the Protein or the Kinase and the word \"and\" is between Protein and Kinase\"\"\",\n",
    "        candidate=None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 0 unique target candidate ids from 1 explanations.\n",
      "No candidate hashes were provided. Skipping linking.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.babble.utils import link_explanation_candidates\n",
    "explanations = link_explanation_candidates(explanations, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for e in explanations:\n",
    "#     print(e.condition)\n",
    "#     if e.candidate:\n",
    "#         print(e.candidate[0].get_span(), e.candidate[1].get_span())\n",
    "#         print(e.candidate.get_parent())\n",
    "#         print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 598 rules\n",
      "WARNING: Number of candidates (1011) does not equal the number of pos (220) + neg (779) = 999 labels.\n",
      "Flushing all parses from previous explanation set.\n",
      "1 explanation(s) out of 1 were parseable.\n",
      "10 parse(s) generated from 1 explanation(s).\n",
      "8 parse(s) remain (2 parse(s) removed by DuplicateSemanticsFilter).\n",
      "Note: 8 LFs did not have candidates and therefore could not be filtered.\n",
      "8 parse(s) remain (0 parse(s) removed by ConsistencyFilter).\n",
      "### Applying labeling functions to split 1\n",
      "[========================================] 100%\n",
      "\n",
      "### Done in 4.1s.\n",
      "\n",
      "4 parse(s) remain (4 parse(s) removed by UniformSignatureFilter: (4 None, 0 All)).\n",
      "3 parse(s) remain (1 parse(s) removed by DuplicateSignatureFilter).\n",
      "Added 3 parse(s) from 1 explanations to set. (Total # parses = 3)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.babble import Babbler\n",
    "\n",
    "babbler = Babbler(session,\n",
    "                  mode='text', \n",
    "                  candidate_class=pipe.candidate_class, \n",
    "                  user_lists=user_lists)\n",
    "babbler.apply(explanations, \n",
    "              split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(translate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation(\"LF_between_before: True, the word \"between\" is within 50 caracters before the Protein or the Kinase and the word \"and\" is between Protein and Kinase\")\n",
      "('.root', ('.label', ('.bool', True), ('.or', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1)), ('.string', '.eq'), ('.int', 50), ('.string', 'words')))), ('.string', u'between')), ('.call', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.index_word', ('.string', u'and'), ('.int', 0))))))\n",
      "return 1 if ('between'.in(text(exactly 50 word(s) to the left of X)) or 'and'[0].in(text(between([X,Y])))) else 0\n",
      "\n",
      "Explanation(\"LF_between_before: True, the word \"between\" is within 50 caracters before the Protein or the Kinase and the word \"and\" is between Protein and Kinase\")\n",
      "('.root', ('.label', ('.bool', True), ('.or', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1)), ('.string', '.leq'), ('.int', 50), ('.string', 'words')))), ('.string', u'between')), ('.all', ('.map', ('.composite_and', ('.eq',), ('.list', ('.arg_to_string', ('.arg', ('.int', 1))), ('.arg_to_string', ('.arg', ('.int', 2))))), ('.list', ('.arg_to_string', ('.arg', ('.int', 2))), ('.string', u'and')))))))\n",
      "return 1 if ('between'.in(text(no more than 50 word(s) to the left of X)) or all([s.(.eq(z) for all z in [text(X),text(Y)]) for s in [text(Y),'and']])) else 0\n",
      "\n",
      "Explanation(\"LF_between_before: True, the word \"between\" is within 50 caracters before the Protein or the Kinase and the word \"and\" is between Protein and Kinase\")\n",
      "('.root', ('.label', ('.bool', True), ('.or', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1)), ('.string', '.leq'), ('.int', 50), ('.string', 'words')))), ('.string', u'between')), ('.call', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.index_word', ('.string', u'and'), ('.int', 0))))))\n",
      "return 1 if ('between'.in(text(no more than 50 word(s) to the left of X)) or 'and'[0].in(text(between([X,Y])))) else 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for parse in parses:\n",
    "    print(parse.explanation)\n",
    "    print(parse.semantics)\n",
    "    print(babbler.semparser.grammar.translate(parse.semantics))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "explanation_map = defaultdict(list)\n",
    "for parse in parses:\n",
    "    if parse.explanation.candidate is None:\n",
    "        print(parse.explanation)\n",
    "        print(\"\")\n",
    "        for c in candidates:\n",
    "            if parse.function(c):\n",
    "                print((c[0].get_span(), c[1].get_span()))\n",
    "                print(\"\")\n",
    "                print(c.get_parent().text)\n",
    "                print(\"\")\n",
    "                print(c.get_stable_id())\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN = 0\n",
    "# candidates = session.query(pipe.candidate_class).filter(\n",
    "#     pipe.candidate_class.split == TRAIN)\n",
    "# for c in candidates:\n",
    "#     sentence = c.get_parent().text\n",
    "#     if 'develop' in sentence and 'following' in sentence:\n",
    "#         print(sentence)\n",
    "#         print(\"\")\n",
    "#         print(c)\n",
    "#         print(c.get_stable_id())\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
