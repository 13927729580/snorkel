{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'protein',\n",
    "    'babbler_candidate_split': 1,\n",
    "    'babbler_label_split': 1,\n",
    "    'supervision': 'traditional',\n",
    "    'max_train': 30,\n",
    "    'traditional_split': 1,\n",
    "    'disc_model_class': 'logreg',    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_protein.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting domain=None to domain=protein\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting max_train=None to max_train=30\n",
      "Overwriting supervision=generative to supervision=traditional\n",
      "Overwriting traditional_split=0 to traditional_split=1\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "if config['debug']:\n",
    "    print(\"NOTE: --debug=True: modifying parameters...\")\n",
    "    config['max_docs'] = 100\n",
    "    config['gen_model_search_space'] = 1\n",
    "    config['disc_model_search_space'] = 1\n",
    "    config['gen_params_default']['epochs'] = 25\n",
    "    config['disc_params_default']['n_epochs'] = 5\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pipe.babbler.filtered_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...skipping 'supervise' stage.\n",
      "CPU times: user 150 µs, sys: 110 µs, total: 260 µs\n",
      "Wall time: 157 µs\n"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...grabbing candidate and gold label subsets.\n",
      "NOTE: using split 1 for traditional supervision. Be aware of unfair evaluation.\n",
      "NOTE: traditional supervision helper assumes all candidates have labels.\n",
      "Using 30 traditional gold labels\n",
      "(30,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTRh0SWri/wBVg+pAhXSQWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1c2f8190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [7.1] Begin training discriminative model\n",
      "============================================================\n",
      "[1] Testing dim = 64, dropout = 2.50e-01, rebalance = 0.00e+00, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=30  #epochs=20  batch size=30\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.771640\tDev F1=29.14\n",
      "[SparseLogisticRegression] Epoch 1 (0.07s)\tAverage loss=0.756871\tDev F1=29.00\n",
      "[SparseLogisticRegression] Epoch 2 (0.12s)\tAverage loss=0.742379\tDev F1=29.03\n",
      "[SparseLogisticRegression] Epoch 3 (0.18s)\tAverage loss=0.728166\tDev F1=29.82\n",
      "[SparseLogisticRegression] Epoch 4 (0.23s)\tAverage loss=0.714237\tDev F1=29.68\n",
      "[SparseLogisticRegression] Epoch 5 (0.29s)\tAverage loss=0.700593\tDev F1=29.72\n",
      "[SparseLogisticRegression] Epoch 6 (0.34s)\tAverage loss=0.687237\tDev F1=29.70\n",
      "[SparseLogisticRegression] Epoch 7 (0.39s)\tAverage loss=0.674170\tDev F1=30.07\n",
      "[SparseLogisticRegression] Epoch 8 (0.45s)\tAverage loss=0.661393\tDev F1=29.99\n",
      "[SparseLogisticRegression] Epoch 9 (0.50s)\tAverage loss=0.648907\tDev F1=30.44\n",
      "[SparseLogisticRegression] Epoch 10 (0.56s)\tAverage loss=0.636710\tDev F1=30.50\n",
      "[SparseLogisticRegression] Epoch 11 (0.61s)\tAverage loss=0.624803\tDev F1=30.49\n",
      "[SparseLogisticRegression] Epoch 12 (0.67s)\tAverage loss=0.613182\tDev F1=30.47\n",
      "[SparseLogisticRegression] Epoch 13 (0.72s)\tAverage loss=0.601846\tDev F1=29.98\n",
      "[SparseLogisticRegression] Epoch 14 (0.78s)\tAverage loss=0.590791\tDev F1=30.17\n",
      "[SparseLogisticRegression] Epoch 15 (0.83s)\tAverage loss=0.580015\tDev F1=30.19\n",
      "[SparseLogisticRegression] Epoch 16 (0.89s)\tAverage loss=0.569513\tDev F1=30.42\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.23s)\tAverage loss=0.559281\tDev F1=30.14\n",
      "[SparseLogisticRegression] Epoch 18 (1.28s)\tAverage loss=0.549314\tDev F1=29.79\n",
      "[SparseLogisticRegression] Epoch 19 (1.33s)\tAverage loss=0.539608\tDev F1=29.99\n",
      "[SparseLogisticRegression] Training done (1.39s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.304182509506\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "============================================================\n",
      "[2] Testing dim = 128, dropout = 5.00e-01, rebalance = 2.50e-01, lr = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=24  #epochs=20  batch size=24\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.742173\tDev F1=25.67\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.740708\tDev F1=25.67\n",
      "[SparseLogisticRegression] Epoch 2 (0.14s)\tAverage loss=0.739245\tDev F1=25.74\n",
      "[SparseLogisticRegression] Epoch 3 (0.19s)\tAverage loss=0.737784\tDev F1=25.78\n",
      "[SparseLogisticRegression] Epoch 4 (0.26s)\tAverage loss=0.736326\tDev F1=25.82\n",
      "[SparseLogisticRegression] Epoch 5 (0.32s)\tAverage loss=0.734871\tDev F1=25.89\n",
      "[SparseLogisticRegression] Epoch 6 (0.38s)\tAverage loss=0.733419\tDev F1=25.89\n",
      "[SparseLogisticRegression] Epoch 7 (0.44s)\tAverage loss=0.731969\tDev F1=25.93\n",
      "[SparseLogisticRegression] Epoch 8 (0.50s)\tAverage loss=0.730522\tDev F1=25.93\n",
      "[SparseLogisticRegression] Epoch 9 (0.56s)\tAverage loss=0.729078\tDev F1=26.00\n",
      "[SparseLogisticRegression] Epoch 10 (0.62s)\tAverage loss=0.727637\tDev F1=26.00\n",
      "[SparseLogisticRegression] Epoch 11 (0.68s)\tAverage loss=0.726198\tDev F1=26.07\n",
      "[SparseLogisticRegression] Epoch 12 (0.74s)\tAverage loss=0.724763\tDev F1=26.11\n",
      "[SparseLogisticRegression] Epoch 13 (0.80s)\tAverage loss=0.723331\tDev F1=26.11\n",
      "[SparseLogisticRegression] Epoch 14 (0.87s)\tAverage loss=0.721902\tDev F1=26.11\n",
      "[SparseLogisticRegression] Epoch 15 (0.93s)\tAverage loss=0.720475\tDev F1=26.11\n",
      "[SparseLogisticRegression] Epoch 16 (0.99s)\tAverage loss=0.719052\tDev F1=26.15\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.48s)\tAverage loss=0.717633\tDev F1=26.15\n",
      "[SparseLogisticRegression] Epoch 18 (1.54s)\tAverage loss=0.716216\tDev F1=26.19\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (1.94s)\tAverage loss=0.714802\tDev F1=26.22\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.45s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.262247838617\n",
      "============================================================\n",
      "[3] Testing dim = 128, dropout = 1.00e-01, rebalance = 5.00e-01, lr = 1.00e-02\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=12  #epochs=20  batch size=12\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.787003\tDev F1=29.86\n",
      "[SparseLogisticRegression] Epoch 1 (0.10s)\tAverage loss=0.640244\tDev F1=31.04\n",
      "[SparseLogisticRegression] Epoch 2 (0.18s)\tAverage loss=0.520690\tDev F1=31.51\n",
      "[SparseLogisticRegression] Epoch 3 (0.27s)\tAverage loss=0.426800\tDev F1=32.90\n",
      "[SparseLogisticRegression] Epoch 4 (0.35s)\tAverage loss=0.353753\tDev F1=33.29\n",
      "[SparseLogisticRegression] Epoch 5 (0.44s)\tAverage loss=0.296202\tDev F1=33.54\n",
      "[SparseLogisticRegression] Epoch 6 (0.52s)\tAverage loss=0.250066\tDev F1=33.90\n",
      "[SparseLogisticRegression] Epoch 7 (0.61s)\tAverage loss=0.212580\tDev F1=34.80\n",
      "[SparseLogisticRegression] Epoch 8 (0.69s)\tAverage loss=0.181841\tDev F1=35.32\n",
      "[SparseLogisticRegression] Epoch 9 (0.78s)\tAverage loss=0.156467\tDev F1=36.13\n",
      "[SparseLogisticRegression] Epoch 10 (0.86s)\tAverage loss=0.135408\tDev F1=35.92\n",
      "[SparseLogisticRegression] Epoch 11 (0.95s)\tAverage loss=0.117845\tDev F1=36.13\n",
      "[SparseLogisticRegression] Epoch 12 (1.03s)\tAverage loss=0.103126\tDev F1=35.84\n",
      "[SparseLogisticRegression] Epoch 13 (1.12s)\tAverage loss=0.090734\tDev F1=35.67\n",
      "[SparseLogisticRegression] Epoch 14 (1.20s)\tAverage loss=0.080253\tDev F1=35.47\n",
      "[SparseLogisticRegression] Epoch 15 (1.29s)\tAverage loss=0.071350\tDev F1=35.35\n",
      "[SparseLogisticRegression] Epoch 16 (1.37s)\tAverage loss=0.063753\tDev F1=35.41\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.84s)\tAverage loss=0.057243\tDev F1=35.41\n",
      "[SparseLogisticRegression] Epoch 18 (1.93s)\tAverage loss=0.051641\tDev F1=35.33\n",
      "[SparseLogisticRegression] Epoch 19 (2.01s)\tAverage loss=0.046801\tDev F1=35.75\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.40s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.357466063348\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_2>\n",
      "============================================================\n",
      "[4] Testing dim = 64, dropout = 5.00e-01, rebalance = 5.00e-01, lr = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=12  #epochs=20  batch size=12\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.787840\tDev F1=32.26\n",
      "[SparseLogisticRegression] Epoch 1 (0.10s)\tAverage loss=0.786240\tDev F1=32.22\n",
      "[SparseLogisticRegression] Epoch 2 (0.19s)\tAverage loss=0.784643\tDev F1=32.22\n",
      "[SparseLogisticRegression] Epoch 3 (0.27s)\tAverage loss=0.783049\tDev F1=32.15\n",
      "[SparseLogisticRegression] Epoch 4 (0.35s)\tAverage loss=0.781458\tDev F1=32.15\n",
      "[SparseLogisticRegression] Epoch 5 (0.44s)\tAverage loss=0.779870\tDev F1=32.19\n",
      "[SparseLogisticRegression] Epoch 6 (0.53s)\tAverage loss=0.778286\tDev F1=32.15\n",
      "[SparseLogisticRegression] Epoch 7 (0.61s)\tAverage loss=0.776704\tDev F1=32.15\n",
      "[SparseLogisticRegression] Epoch 8 (0.70s)\tAverage loss=0.775126\tDev F1=32.12\n",
      "[SparseLogisticRegression] Epoch 9 (0.79s)\tAverage loss=0.773551\tDev F1=32.12\n",
      "[SparseLogisticRegression] Epoch 10 (0.87s)\tAverage loss=0.771980\tDev F1=32.15\n",
      "[SparseLogisticRegression] Epoch 11 (0.96s)\tAverage loss=0.770411\tDev F1=32.12\n",
      "[SparseLogisticRegression] Epoch 12 (1.05s)\tAverage loss=0.768846\tDev F1=32.15\n",
      "[SparseLogisticRegression] Epoch 13 (1.13s)\tAverage loss=0.767285\tDev F1=32.19\n",
      "[SparseLogisticRegression] Epoch 14 (1.21s)\tAverage loss=0.765727\tDev F1=32.22\n",
      "[SparseLogisticRegression] Epoch 15 (1.30s)\tAverage loss=0.764173\tDev F1=32.22\n",
      "[SparseLogisticRegression] Epoch 16 (1.38s)\tAverage loss=0.762622\tDev F1=32.33\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.73s)\tAverage loss=0.761075\tDev F1=32.33\n",
      "[SparseLogisticRegression] Epoch 18 (1.81s)\tAverage loss=0.759531\tDev F1=32.33\n",
      "[SparseLogisticRegression] Epoch 19 (1.90s)\tAverage loss=0.757991\tDev F1=32.33\n",
      "[SparseLogisticRegression] Training done (1.98s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.323340471092\n",
      "============================================================\n",
      "[5] Testing dim = 128, dropout = 1.00e-01, rebalance = 5.00e-01, lr = 1.00e-02\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=12  #epochs=20  batch size=12\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.591690\tDev F1=33.84\n",
      "[SparseLogisticRegression] Epoch 1 (0.10s)\tAverage loss=0.474517\tDev F1=35.28\n",
      "[SparseLogisticRegression] Epoch 2 (0.18s)\tAverage loss=0.385338\tDev F1=35.46\n",
      "[SparseLogisticRegression] Epoch 3 (0.27s)\tAverage loss=0.318581\tDev F1=36.32\n",
      "[SparseLogisticRegression] Epoch 4 (0.35s)\tAverage loss=0.267835\tDev F1=36.73\n",
      "[SparseLogisticRegression] Epoch 5 (0.44s)\tAverage loss=0.228235\tDev F1=37.54\n",
      "[SparseLogisticRegression] Epoch 6 (0.53s)\tAverage loss=0.196561\tDev F1=37.24\n",
      "[SparseLogisticRegression] Epoch 7 (0.61s)\tAverage loss=0.170713\tDev F1=37.15\n",
      "[SparseLogisticRegression] Epoch 8 (0.70s)\tAverage loss=0.149283\tDev F1=37.06\n",
      "[SparseLogisticRegression] Epoch 9 (0.78s)\tAverage loss=0.131294\tDev F1=36.87\n",
      "[SparseLogisticRegression] Epoch 10 (0.87s)\tAverage loss=0.116046\tDev F1=37.24\n",
      "[SparseLogisticRegression] Epoch 11 (0.95s)\tAverage loss=0.103021\tDev F1=37.05\n",
      "[SparseLogisticRegression] Epoch 12 (1.04s)\tAverage loss=0.091826\tDev F1=37.23\n",
      "[SparseLogisticRegression] Epoch 13 (1.12s)\tAverage loss=0.082156\tDev F1=37.04\n",
      "[SparseLogisticRegression] Epoch 14 (1.21s)\tAverage loss=0.073767\tDev F1=37.08\n",
      "[SparseLogisticRegression] Epoch 15 (1.29s)\tAverage loss=0.066464\tDev F1=36.70\n",
      "[SparseLogisticRegression] Epoch 16 (1.38s)\tAverage loss=0.060086\tDev F1=36.98\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.71s)\tAverage loss=0.054501\tDev F1=36.98\n",
      "[SparseLogisticRegression] Epoch 18 (1.79s)\tAverage loss=0.049597\tDev F1=37.02\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.16s)\tAverage loss=0.045279\tDev F1=36.98\n",
      "[SparseLogisticRegression] Training done (2.24s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.37019790454\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_4>\n",
      "============================================================\n",
      "[6] Testing dim = 128, dropout = 1.00e-01, rebalance = 5.00e-01, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=12  #epochs=20  batch size=12\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.469150\tDev F1=33.26\n",
      "[SparseLogisticRegression] Epoch 1 (0.10s)\tAverage loss=0.459216\tDev F1=33.37\n",
      "[SparseLogisticRegression] Epoch 2 (0.18s)\tAverage loss=0.449532\tDev F1=33.37\n",
      "[SparseLogisticRegression] Epoch 3 (0.27s)\tAverage loss=0.440095\tDev F1=33.33\n",
      "[SparseLogisticRegression] Epoch 4 (0.35s)\tAverage loss=0.430904\tDev F1=33.37\n",
      "[SparseLogisticRegression] Epoch 5 (0.44s)\tAverage loss=0.421954\tDev F1=33.48\n",
      "[SparseLogisticRegression] Epoch 6 (0.52s)\tAverage loss=0.413241\tDev F1=33.87\n",
      "[SparseLogisticRegression] Epoch 7 (0.61s)\tAverage loss=0.404761\tDev F1=33.95\n",
      "[SparseLogisticRegression] Epoch 8 (0.69s)\tAverage loss=0.396509\tDev F1=33.88\n",
      "[SparseLogisticRegression] Epoch 9 (0.78s)\tAverage loss=0.388481\tDev F1=34.24\n",
      "[SparseLogisticRegression] Epoch 10 (0.87s)\tAverage loss=0.380672\tDev F1=34.53\n",
      "[SparseLogisticRegression] Epoch 11 (0.96s)\tAverage loss=0.373075\tDev F1=34.35\n",
      "[SparseLogisticRegression] Epoch 12 (1.05s)\tAverage loss=0.365687\tDev F1=34.35\n",
      "[SparseLogisticRegression] Epoch 13 (1.13s)\tAverage loss=0.358502\tDev F1=34.35\n",
      "[SparseLogisticRegression] Epoch 14 (1.22s)\tAverage loss=0.351514\tDev F1=34.46\n",
      "[SparseLogisticRegression] Epoch 15 (1.30s)\tAverage loss=0.344717\tDev F1=34.72\n",
      "[SparseLogisticRegression] Epoch 16 (1.39s)\tAverage loss=0.338107\tDev F1=34.83\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.73s)\tAverage loss=0.331677\tDev F1=34.91\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 18 (2.23s)\tAverage loss=0.325422\tDev F1=34.95\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.63s)\tAverage loss=0.319338\tDev F1=34.84\n",
      "[SparseLogisticRegression] Training done (2.72s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.349450549451\n",
      "============================================================\n",
      "[7] Testing dim = 128, dropout = 1.00e-01, rebalance = 2.50e-01, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=24  #epochs=20  batch size=24\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.895587\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.879289\tDev F1=25.67\n",
      "[SparseLogisticRegression] Epoch 2 (0.13s)\tAverage loss=0.863218\tDev F1=25.26\n",
      "[SparseLogisticRegression] Epoch 3 (0.19s)\tAverage loss=0.847382\tDev F1=25.16\n",
      "[SparseLogisticRegression] Epoch 4 (0.25s)\tAverage loss=0.831785\tDev F1=25.05\n",
      "[SparseLogisticRegression] Epoch 5 (0.31s)\tAverage loss=0.816433\tDev F1=24.61\n",
      "[SparseLogisticRegression] Epoch 6 (0.37s)\tAverage loss=0.801332\tDev F1=24.81\n",
      "[SparseLogisticRegression] Epoch 7 (0.43s)\tAverage loss=0.786485\tDev F1=24.84\n",
      "[SparseLogisticRegression] Epoch 8 (0.49s)\tAverage loss=0.771897\tDev F1=24.97\n",
      "[SparseLogisticRegression] Epoch 9 (0.56s)\tAverage loss=0.757572\tDev F1=25.08\n",
      "[SparseLogisticRegression] Epoch 10 (0.62s)\tAverage loss=0.743512\tDev F1=25.33\n",
      "[SparseLogisticRegression] Epoch 11 (0.68s)\tAverage loss=0.729721\tDev F1=25.08\n",
      "[SparseLogisticRegression] Epoch 12 (0.74s)\tAverage loss=0.716201\tDev F1=25.11\n",
      "[SparseLogisticRegression] Epoch 13 (0.80s)\tAverage loss=0.702953\tDev F1=24.97\n",
      "[SparseLogisticRegression] Epoch 14 (0.86s)\tAverage loss=0.689979\tDev F1=24.97\n",
      "[SparseLogisticRegression] Epoch 15 (0.92s)\tAverage loss=0.677279\tDev F1=24.80\n",
      "[SparseLogisticRegression] Epoch 16 (0.98s)\tAverage loss=0.664853\tDev F1=24.63\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.30s)\tAverage loss=0.652702\tDev F1=24.62\n",
      "[SparseLogisticRegression] Epoch 18 (1.36s)\tAverage loss=0.640823\tDev F1=24.06\n",
      "[SparseLogisticRegression] Epoch 19 (1.42s)\tAverage loss=0.629215\tDev F1=24.20\n",
      "[SparseLogisticRegression] Training done (1.48s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.246260069045\n",
      "============================================================\n",
      "[8] Testing dim = 128, dropout = 5.00e-01, rebalance = 5.00e-01, lr = 1.00e-04\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=12  #epochs=20  batch size=12\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.735358\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 1 (0.10s)\tAverage loss=0.733904\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 2 (0.19s)\tAverage loss=0.732452\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 3 (0.27s)\tAverage loss=0.731004\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 4 (0.36s)\tAverage loss=0.729559\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 5 (0.44s)\tAverage loss=0.728117\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 6 (0.53s)\tAverage loss=0.726679\tDev F1=25.46\n",
      "[SparseLogisticRegression] Epoch 7 (0.61s)\tAverage loss=0.725243\tDev F1=25.44\n",
      "[SparseLogisticRegression] Epoch 8 (0.70s)\tAverage loss=0.723811\tDev F1=25.61\n",
      "[SparseLogisticRegression] Epoch 9 (0.78s)\tAverage loss=0.722382\tDev F1=25.79\n",
      "[SparseLogisticRegression] Epoch 10 (0.87s)\tAverage loss=0.720957\tDev F1=25.82\n",
      "[SparseLogisticRegression] Epoch 11 (0.96s)\tAverage loss=0.719535\tDev F1=25.85\n",
      "[SparseLogisticRegression] Epoch 12 (1.05s)\tAverage loss=0.718116\tDev F1=25.85\n",
      "[SparseLogisticRegression] Epoch 13 (1.13s)\tAverage loss=0.716701\tDev F1=25.82\n",
      "[SparseLogisticRegression] Epoch 14 (1.22s)\tAverage loss=0.715290\tDev F1=25.82\n",
      "[SparseLogisticRegression] Epoch 15 (1.30s)\tAverage loss=0.713882\tDev F1=25.82\n",
      "[SparseLogisticRegression] Epoch 16 (1.39s)\tAverage loss=0.712478\tDev F1=25.82\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.74s)\tAverage loss=0.711077\tDev F1=25.82\n",
      "[SparseLogisticRegression] Epoch 18 (1.83s)\tAverage loss=0.709680\tDev F1=26.00\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (2.32s)\tAverage loss=0.708287\tDev F1=26.02\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (2.72s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.260245901639\n",
      "============================================================\n",
      "[9] Testing dim = 128, dropout = 2.50e-01, rebalance = 2.50e-01, lr = 1.00e-02\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=24  #epochs=20  batch size=24\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.742170\tDev F1=25.04\n",
      "[SparseLogisticRegression] Epoch 1 (0.08s)\tAverage loss=0.615070\tDev F1=24.71\n",
      "[SparseLogisticRegression] Epoch 2 (0.13s)\tAverage loss=0.511214\tDev F1=25.31\n",
      "[SparseLogisticRegression] Epoch 3 (0.19s)\tAverage loss=0.427328\tDev F1=26.72\n",
      "[SparseLogisticRegression] Epoch 4 (0.26s)\tAverage loss=0.359744\tDev F1=27.86\n",
      "[SparseLogisticRegression] Epoch 5 (0.32s)\tAverage loss=0.305116\tDev F1=28.07\n",
      "[SparseLogisticRegression] Epoch 6 (0.38s)\tAverage loss=0.260702\tDev F1=28.77\n",
      "[SparseLogisticRegression] Epoch 7 (0.43s)\tAverage loss=0.224348\tDev F1=29.04\n",
      "[SparseLogisticRegression] Epoch 8 (0.50s)\tAverage loss=0.194382\tDev F1=29.81\n",
      "[SparseLogisticRegression] Epoch 9 (0.56s)\tAverage loss=0.169505\tDev F1=30.05\n",
      "[SparseLogisticRegression] Epoch 10 (0.62s)\tAverage loss=0.148706\tDev F1=30.42\n",
      "[SparseLogisticRegression] Epoch 11 (0.68s)\tAverage loss=0.131196\tDev F1=30.46\n",
      "[SparseLogisticRegression] Epoch 12 (0.74s)\tAverage loss=0.116356\tDev F1=30.26\n",
      "[SparseLogisticRegression] Epoch 13 (0.80s)\tAverage loss=0.103700\tDev F1=31.20\n",
      "[SparseLogisticRegression] Epoch 14 (0.87s)\tAverage loss=0.092842\tDev F1=30.81\n",
      "[SparseLogisticRegression] Epoch 15 (0.93s)\tAverage loss=0.083479\tDev F1=31.13\n",
      "[SparseLogisticRegression] Epoch 16 (0.99s)\tAverage loss=0.075365\tDev F1=31.22\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.32s)\tAverage loss=0.068303\tDev F1=31.22\n",
      "[SparseLogisticRegression] Epoch 18 (1.39s)\tAverage loss=0.062134\tDev F1=30.24\n",
      "[SparseLogisticRegression] Epoch 19 (1.45s)\tAverage loss=0.056726\tDev F1=30.24\n",
      "[SparseLogisticRegression] Training done (1.51s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.312169312169\n",
      "============================================================\n",
      "[10] Testing dim = 128, dropout = 5.00e-01, rebalance = 2.50e-01, lr = 1.00e-03\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=24  #epochs=20  batch size=24\n",
      "[SparseLogisticRegression] Epoch 0 (0.01s)\tAverage loss=0.663182\tDev F1=28.24\n",
      "[SparseLogisticRegression] Epoch 1 (0.07s)\tAverage loss=0.649710\tDev F1=27.91\n",
      "[SparseLogisticRegression] Epoch 2 (0.14s)\tAverage loss=0.636473\tDev F1=26.94\n",
      "[SparseLogisticRegression] Epoch 3 (0.20s)\tAverage loss=0.623475\tDev F1=26.51\n",
      "[SparseLogisticRegression] Epoch 4 (0.26s)\tAverage loss=0.610720\tDev F1=26.56\n",
      "[SparseLogisticRegression] Epoch 5 (0.32s)\tAverage loss=0.598212\tDev F1=26.72\n",
      "[SparseLogisticRegression] Epoch 6 (0.38s)\tAverage loss=0.585955\tDev F1=26.34\n",
      "[SparseLogisticRegression] Epoch 7 (0.44s)\tAverage loss=0.573952\tDev F1=26.04\n",
      "[SparseLogisticRegression] Epoch 8 (0.50s)\tAverage loss=0.562205\tDev F1=26.12\n",
      "[SparseLogisticRegression] Epoch 9 (0.56s)\tAverage loss=0.550716\tDev F1=26.42\n",
      "[SparseLogisticRegression] Epoch 10 (0.63s)\tAverage loss=0.539486\tDev F1=27.05\n",
      "[SparseLogisticRegression] Epoch 11 (0.69s)\tAverage loss=0.528515\tDev F1=27.45\n",
      "[SparseLogisticRegression] Epoch 12 (0.75s)\tAverage loss=0.517803\tDev F1=27.98\n",
      "[SparseLogisticRegression] Epoch 13 (0.81s)\tAverage loss=0.507349\tDev F1=27.41\n",
      "[SparseLogisticRegression] Epoch 14 (0.87s)\tAverage loss=0.497151\tDev F1=27.66\n",
      "[SparseLogisticRegression] Epoch 15 (0.93s)\tAverage loss=0.487209\tDev F1=27.60\n",
      "[SparseLogisticRegression] Epoch 16 (1.00s)\tAverage loss=0.477518\tDev F1=27.76\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (1.45s)\tAverage loss=0.468077\tDev F1=27.75\n",
      "[SparseLogisticRegression] Epoch 18 (1.51s)\tAverage loss=0.458881\tDev F1=28.11\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 19 (1.86s)\tAverage loss=0.449928\tDev F1=27.50\n",
      "[SparseLogisticRegression] Training done (1.92s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.281098546042\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_4>\n",
      "   dim  dropout  rebalance      lr     Prec.      Rec.     F-1.0\n",
      "4  128     0.10       0.50  0.0100  0.250394  0.709821  0.370198\n",
      "2  128     0.10       0.50  0.0100  0.239394  0.705357  0.357466\n",
      "5  128     0.10       0.50  0.0010  0.231778  0.709821  0.349451\n",
      "3   64     0.50       0.50  0.0001  0.212676  0.674107  0.323340\n",
      "8  128     0.25       0.25  0.0100  0.383117  0.263393  0.312169\n",
      "0   64     0.25       0.00  0.0010  0.212389  0.535714  0.304183\n",
      "9  128     0.50       0.25  0.0010  0.220253  0.388393  0.281099\n",
      "1  128     0.50       0.25  0.0001  0.193617  0.406250  0.262248\n",
      "7  128     0.50       0.50  0.0001  0.168883  0.566964  0.260246\n",
      "6  128     0.10       0.25  0.0010  0.165891  0.477679  0.246260\n",
      "[SparseLogisticRegression] Model saved as <discriminative_protein>\n",
      "### Done in 27.2s.\n",
      "\n",
      "### [7.2] Evaluate generative model (opt_b=0.5)\n",
      "gen_model is undefined. Skipping.\n",
      "### Done in 0.0s.\n",
      "\n",
      "### [7.3] Evaluate discriminative model (opt_b=0.5)\n",
      "### Done in 0.0s.\n",
      "\n",
      "      F1 Score  Precision    Recall\n",
      "Disc  0.358068   0.245161  0.663755\n",
      "CPU times: user 38.5 s, sys: 2.52 s, total: 41 s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote Results:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "      F1 Score  Precision    Recall\n",
    "Disc  0.349336   0.228000  0.746725\n",
    "Gen   0.180124   0.311828  0.126638"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Results:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "      F1 Score  Precision    Recall\n",
    "Disc  0.327907   0.223455  0.615721\n",
    "Gen   0.189024   0.313131  0.135371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional Supervision Results: (n=30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "      F1 Score  Precision    Recall\n",
    "Disc  0.400477    0.27541  0.733624 (n=30)\n",
    "Disc  0.358068   0.245161  0.663755 (n=30)\n",
    "\n",
    "Disc  0.395604   0.533333  0.31441  (n=300)\n",
    "Disc  0.545894   0.610811  0.49345  (n=1168)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
