{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Visual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.remove('snorkel.db')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from pdb import set_trace as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PDF to HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Adobe Acrobat (or other program of your choice) to convert PDF -> HTML with structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse HTML and PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2474 pdf words\n",
      "Elapsed: 0.536 s\n",
      "Extracted 2631 html words\n",
      "Elapsed: 0.062 s\n",
      "2474\n",
      "2474\n",
      "(54, 76)\n",
      "[(u\"''\", u'(BR)CBO'),\n",
      " (u\"'s\", u'(BR)CEO'),\n",
      " ('(', u'(BR)EBO'),\n",
      " (u'+125', u'(I'),\n",
      " (u'-55', u'(MHz'),\n",
      " (u'.5', u'(NORMALIZED'),\n",
      " (u'1050', u'(Note'),\n",
      " (u'2175', u'(Pb\\u2212Free'),\n",
      " (u'2176', u'(SCILLC)'),\n",
      " (u'226', u'(T'),\n",
      " (u'25', u'(TO\\u2212226'),\n",
      " (u'282', u'(V'),\n",
      " (u'303', u'(VOLTS'),\n",
      " (u'344', u'(mA'),\n",
      " (u'3860', u'(mAdc'),\n",
      " (u'3867', u'(mV'),\n",
      " (u'421\\xa033\\xa0790\\xa02910', u'(pF'),\n",
      " (u'55', u'*For'),\n",
      " (u'5817', u'+125\\xb0C'),\n",
      " (u'675', u'-55\\xb0C'),\n",
      " (u'81', u'/I'),\n",
      " (u'92', u'125\\xb0C'),\n",
      " (u'9855', u'25\\xb0C'),\n",
      " (u'AYW', u'2910'),\n",
      " (u'Adc', u'29\\u221211'),\n",
      " (u'Ambient', u'303\\u2212675\\u22122175'),\n",
      " (u'BR', u'303\\u2212675\\u22122176'),\n",
      " (u'C/W', u'33'),\n",
      " (u'Case', u'421'),\n",
      " (u'JA', u'790'),\n",
      " (u'JC', u'800\\u2212282\\u22129855'),\n",
      " (u'M', u'800\\u2212344\\u22123860'),\n",
      " (u'Marking.pdf', u'800\\u2212344\\u22123867'),\n",
      " (u'N.', u'81\\u22123\\u22125817\\u22121050'),\n",
      " (u'P.O.', u'AYWW'),\n",
      " (u'Pb', u'BE(on'),\n",
      " (u'Q', u'BE(sat'),\n",
      " (u'Rev.', u'Base\\u2212Emitter'),\n",
      " (u'SIGNAL', u'CE(sat'),\n",
      " (u'SMALL', u'Current\\u2212Gain'),\n",
      " (u'TO', u'Df'),\n",
      " (u'Typical', u'Junction\\u2212to\\u2212Ambient'),\n",
      " (u'Typicals', u'Junction\\u2212to\\u2212Case'),\n",
      " (u'V.', u'P.O'),\n",
      " (u'VOLTS', u'Pb\\u2212Free'),\n",
      " (u'Y14', u'Rev'),\n",
      " (u'``', u'SCILLC\\u2019s'),\n",
      " (u'k', u'SMALL\\u2212SIGNAL'),\n",
      " (u'loca', u'TO\\u221292'),\n",
      " (u'mV', u'VCE'),\n",
      " (u'orderlit@onsemi.com\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n",
      "  u'WW'),\n",
      " (u'sat', u'X\\u2212X'),\n",
      " (u'www.onsemi.com/site/pdf/Patent', u'Y14.5M'),\n",
      " (u'\\xb5', u'customer\\u2019s'),\n",
      " (None, u'f\\x02'),\n",
      " (None, u'hFE'),\n",
      " (None, u'kW'),\n",
      " (None, u'local'),\n",
      " (None, u'mW/\\xb0C'),\n",
      " (None, u'orderlit@onsemi.com'),\n",
      " (None, u'q'),\n",
      " (None, u'qJA'),\n",
      " (None, u'qJC'),\n",
      " (None, u'www.onsemi.com/site/pdf/Patent\\u2212Marking.pdf'),\n",
      " (None, u'\\xa9'),\n",
      " (None, u'\\xb0'),\n",
      " (None, u'\\xb0C'),\n",
      " (None, u'\\xb0C/W'),\n",
      " (None, u'\\u03b8'),\n",
      " (None, u'\\u201cOn'),\n",
      " (None, u'\\u201cSaturation'),\n",
      " (None, u'\\u201cTypical'),\n",
      " (None, u'\\u201cTypicals'),\n",
      " (None, u'\\u201d'),\n",
      " (None, u'\\u2020For'),\n",
      " (None, u'\\u221255')]\n",
      "> /Users/bradenhancock/snorkel/snorkel/visual.py(58)visual_parse_and_link()\n",
      "-> tic = timer()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser import HTMLParser\n",
    "from snorkel.parser import OmniParser\n",
    "\n",
    "pdf_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_pdf/'\n",
    "html_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_html2/'\n",
    "\n",
    "filename = 'bc546-d'\n",
    "html_file = html_path + filename + '.html'\n",
    "\n",
    "doc_parser = HTMLParser(path=html_file)\n",
    "context_parser = OmniParser(pdf_path=pdf_path, session=session)\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=1) \n",
    "\n",
    "%time corpus = cp.parse_corpus(name='Hardware', session=session)\n",
    "\n",
    "# Save results\n",
    "# os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from snorkel.models import Corpus\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "\n",
    "# os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from snorkel.models import Corpus, candidate_subclass\n",
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp, get_gold_dict\n",
    "\n",
    "# Candidate Type\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "    \n",
    "# CandidateSpaces\n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=None, n_max=3) # NOTE: no part linking right now\n",
    "temp_ngrams = OmniNgramsTemp(n_max=2)\n",
    "\n",
    "# Matchers\n",
    "eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)')\n",
    "jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)')\n",
    "jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)')\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "temp_matcher = RegexMatchSpan(rgx=r'[0-9]+[05]', longest_match_only=False)\n",
    "\n",
    "# Throttler\n",
    "part_throttler = lambda x: x[0].parent.page == x[1].parent.page\n",
    "\n",
    "# Extractor\n",
    "ce = CandidateExtractor(Part_Temp, \n",
    "                        [part_ngrams, temp_ngrams], \n",
    "                        [parts_matcher, temp_matcher], \n",
    "                        throttler=part_throttler)\n",
    "\n",
    "# Extract\n",
    "for corpus_name in ['Hardware']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(\\\n",
    "        corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = candidates[15]\n",
    "print c.part\n",
    "print c.part.char_start, c.part.char_end\n",
    "print c.part.parent.page\n",
    "print c.part.get_attrib_tokens('top')\n",
    "print c.part.get_attrib_tokens('bottom')\n",
    "print c.part.get_attrib_tokens('left')\n",
    "print c.part.get_attrib_tokens('right')\n",
    "\n",
    "\n",
    "from snorkel.entity_features import visual_binary_features\n",
    "from snorkel.lf_helpers import get_aligned_lemmas, _bbox_from_span\n",
    "\n",
    "print c.part.parent.document\n",
    "for c in candidates:\n",
    "    \n",
    "    span1, span2 = c.get_arguments()\n",
    "    \n",
    "    feats = set()\n",
    "    for f in visual_binary_features(span1, span2):\n",
    "        feats.add(f)\n",
    "    text1 =   span1.get_span()\n",
    "    text2 = span2.get_span()\n",
    "    if not  'Y_ALIGNED' in feats or span1.parent.page!=2: continue\n",
    "    print '='*20\n",
    "    print 'For candidate pair:'\n",
    "    print span1.get_span()\n",
    "    print span2.get_span()\n",
    "    print 'Visual features are:'\n",
    "    for f in feats: print f\n",
    "    print 'LF is_aligned_with_lemmas:', 'min' in get_aligned_lemmas(span2)\n",
    "    print 'Phrase1', span1.parent,  span1.parent.page#.text, span1.parent.bbox\n",
    "    print 'Phrase2', span2.parent,  span2.parent.page#.text, span2.parent.bbox, span2.parent.page\n",
    "    print _bbox_from_span(span1), _bbox_from_span(span2)\n",
    "    \n",
    "print len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_parser.vizlink.display_links(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: Select image and press any key to close image.\n",
    "context_parser.vizlink.display_candidates(candidates, page_num=2, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pdf_file = context_parser.vizlink.pdf_file\n",
    "\n",
    "# context_parser.vizlink.display_word('BC546', page_num=2)\n",
    "# context_parser.vizlink.display_candidates(candidates, page_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from visual_linking import display_boxes, get_box\n",
    "\n",
    "# boxes = []\n",
    "# for c in candidates:\n",
    "#     boxes.append(get_box(c.part))\n",
    "# boxes = list(set(boxes))\n",
    "# display_boxes(pdf_file, boxes, page_num=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Ordering of PDF Word List "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Ordering on a black page - Not very easy to display because of superposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import math\n",
    "\n",
    "# page_num = 2\n",
    "# page_height = 792\n",
    "# page_width = 612\n",
    "# img = np.ones((page_height,page_width,3))*255\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# letter_width = 3\n",
    "# i = 0\n",
    "# for word_id, _ in pdf_word_list:\n",
    "#     if word_id[0] == page_num:\n",
    "#         i += 1\n",
    "#         _, top, left, bottom, right = coordinate_map[word_id]\n",
    "#         cv2.rectangle(img, (left, top), (right, bottom), (0,255,0), 1)\n",
    "#         cv2.putText(img, \n",
    "#                     str(i), \n",
    "#                     ((left + right)/2 - letter_width*int(math.ceil(math.log10(i))), \n",
    "#                     bottom + (top - bottom)/4), \n",
    "#                     font, \n",
    "#                     0.3, \n",
    "#                     (255,0,0), \n",
    "#                     1)\n",
    "# cv2.imshow('PDF Word List Order',img)\n",
    "# cv2.waitKey() # press any key to exit the opencv output \n",
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
