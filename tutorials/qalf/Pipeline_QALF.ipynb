{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'qalf',\n",
    "    'domain': 'tacred',\n",
    "    'relation': 'per_title',\n",
    "    'splits': [0],\n",
    "    'supervision': 'traditional',\n",
    "    'max_train': 2000,\n",
    "#     'max_lfs': 1,\n",
    "#     'learn_deps': True,\n",
    "#     'gen_model_search_space': 1,\n",
    "#     'gen_init_params': {\n",
    "#         'lf_propensity'         : True,\n",
    "#         'class_prior'           : True,\n",
    "#         'lf_class_propensity'   : True,\n",
    "#         'seed'                  : None,\n",
    "#     },\n",
    "#     'gen_params_default': {\n",
    "#         'step_size'     : 0.0001,\n",
    "#         'decay'         : 0.90,\n",
    "#         'reg_param'     : 0.50,\n",
    "#         'epochs'        : 25,\n",
    "#     },    \n",
    "    'disc_model_class': 'logreg',    \n",
    "    'disc_model_search_space': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///qalf_tacred_per_title.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = (config['project'] + '_' + config['domain'] + \n",
    "                   ('_' + config['relation'] if config['relation'] else '') +\n",
    "                   ('_debug' if config.get('debug', False) else ''))\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting disc_model_search_space=10 to disc_model_search_space=1\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting domain=None to domain=tacred\n",
      "Overwriting max_sentence_length=100 to max_sentence_length=200\n",
      "Overwriting rebalance=0.25 to rebalance=False\n",
      "Overwriting disc_model_search_space=10 to disc_model_search_space=1\n",
      "Overwriting splits=[0, 1, 2] to splits=[0]\n",
      "Overwriting max_train=None to max_train=2000\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting supervision=generative to supervision=traditional\n",
      "Overwriting project=babble to project=qalf\n",
      "Using TacredQalfPipeline object.\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'], config['project'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: 5200 Candidates\n",
      "Split 1: 1935 Candidates\n",
      "Split 2: 0 Candidates\n"
     ]
    }
   ],
   "source": [
    "for split in [0,1,2]:\n",
    "    num_cands = pipe.session.query(pipe.candidate_class).filter(\n",
    "        pipe.candidate_class.split == split).count()\n",
    "    print(\"Split {}: {} Candidates\".format(split, num_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*QalfPipeline objects load QA result matrices in the label() method.\n",
      "CPU times: user 109 µs, sys: 124 µs, total: 233 µs\n",
      "Wall time: 137 µs\n"
     ]
    }
   ],
   "source": [
    "%time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/bradenjh/repos/snorkel/tutorials/qalf/qalf_converter.py(44)convert()\n",
      "-> with open(mat_path, 'rb') as tsv:\n",
      "(Pdb) c\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 13.6 s, sys: 291 ms, total: 13.9 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels\n",
    "# L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "# pipe.L_train.lf_stats(session, labels=L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels\n",
    "# L_gold_dev   = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# pipe.L_dev.lf_stats(session, labels=L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...skipping 'supervise' stage.\n",
      "CPU times: user 196 µs, sys: 121 µs, total: 317 µs\n",
      "Wall time: 214 µs\n"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...grabbing candidate and gold label subsets.\n",
      "NOTE: traditional supervision helper assumes all candidates have labels.\n",
      "Using 2000 traditional gold labels\n",
      "(2000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a21cc6850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [7.1] Begin training discriminative model\n",
      "Skipping grid search.\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=2000  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.07s)\tAverage loss=0.592741\tDev F1=75.08\n",
      "[SparseLogisticRegression] Epoch 1 (0.16s)\tAverage loss=0.502883\tDev F1=74.95\n",
      "[SparseLogisticRegression] Epoch 2 (0.27s)\tAverage loss=0.474242\tDev F1=75.69\n",
      "[SparseLogisticRegression] Epoch 3 (0.37s)\tAverage loss=0.454843\tDev F1=75.76\n",
      "[SparseLogisticRegression] Epoch 4 (0.48s)\tAverage loss=0.437939\tDev F1=75.88\n",
      "[SparseLogisticRegression] Epoch 5 (0.58s)\tAverage loss=0.424129\tDev F1=75.55\n",
      "[SparseLogisticRegression] Epoch 6 (0.68s)\tAverage loss=0.415995\tDev F1=75.48\n",
      "[SparseLogisticRegression] Epoch 7 (0.78s)\tAverage loss=0.409246\tDev F1=74.57\n",
      "[SparseLogisticRegression] Epoch 8 (0.88s)\tAverage loss=0.403903\tDev F1=73.76\n",
      "[SparseLogisticRegression] Epoch 9 (0.98s)\tAverage loss=0.395950\tDev F1=74.83\n",
      "[SparseLogisticRegression] Epoch 10 (1.08s)\tAverage loss=0.393205\tDev F1=73.74\n",
      "[SparseLogisticRegression] Epoch 11 (1.19s)\tAverage loss=0.387141\tDev F1=73.74\n",
      "[SparseLogisticRegression] Epoch 12 (1.29s)\tAverage loss=0.382774\tDev F1=73.77\n",
      "[SparseLogisticRegression] Epoch 13 (1.39s)\tAverage loss=0.384157\tDev F1=73.91\n",
      "[SparseLogisticRegression] Epoch 14 (1.49s)\tAverage loss=0.373786\tDev F1=72.89\n",
      "[SparseLogisticRegression] Epoch 15 (1.59s)\tAverage loss=0.373343\tDev F1=73.62\n",
      "[SparseLogisticRegression] Epoch 16 (1.69s)\tAverage loss=0.371989\tDev F1=73.53\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (2.28s)\tAverage loss=0.368410\tDev F1=73.10\n",
      "[SparseLogisticRegression] Epoch 18 (2.39s)\tAverage loss=0.365393\tDev F1=72.30\n",
      "[SparseLogisticRegression] Epoch 19 (2.49s)\tAverage loss=0.364249\tDev F1=73.34\n",
      "[SparseLogisticRegression] Training done (2.54s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Model saved as <discriminative_tacred>\n",
      "### Done in 3.4s.\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [F1 Score, Precision, Recall]\n",
      "Index: []\n",
      "CPU times: user 7.19 s, sys: 501 ms, total: 7.69 s\n",
      "Wall time: 7 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Sentence\n",
    "# s = pipe.session.query(Sentence).first()\n",
    "# s.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from spacy.lemmatizer import Lemmatizer\n",
    "# from spacy.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "# lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "# lemmas = lemmatizer(u'ducks', u'NOUN')\n",
    "# print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from spacy.lemmatizer import Lemmatizer\n",
    "# lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
