{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DOMAIN = 'test'\n",
    "# DOMAIN = 'cdr'\n",
    "# DOMAIN = 'spouse'\n",
    "DOMAIN = 'bike'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "db = {\n",
    "    'test':   'postgres://localhost:5432/babble_test_unittest',\n",
    "    'spouse': 'postgres://localhost:5432/babble_test_spouse',\n",
    "    'cdr':    'postgres://localhost:5432/babble_test_cdr',\n",
    "    'bike':   'postgres://localhost:5432/babble_test_bike',\n",
    "}\n",
    "\n",
    "os.environ['SNORKELDB'] = db[DOMAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate hashes...\n",
      "Collected 9 target candidate hashes from 9 explanations.\n",
      "Gathering desired candidates...\n",
      "Found 9/9 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 9/9 explanations\n",
      "Domain: spouse\n",
      "Explanations: 9\n",
      "Candidates: 27766\n",
      "CPU times: user 18.7 s, sys: 1 s, total: 19.7 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "    \n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.contrib.babble import link_explanation_candidates\n",
    "\n",
    "# Extract domain-specific explanations and user_lists\n",
    "if DOMAIN == 'test':\n",
    "    sys.path.append(os.path.join(os.environ['SNORKELHOME'], 'test/babble/'))\n",
    "    import unittest_examples\n",
    "    user_lists = unittest_examples.get_user_lists()\n",
    "    explanations = unittest_examples.explanations\n",
    "    Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "    candidate_class = Spouse\n",
    "elif DOMAIN == 'spouse':\n",
    "    import spouse_examples\n",
    "    user_lists = spouse_examples.get_user_lists()\n",
    "    user_lists = {}\n",
    "    explanations = spouse_examples.explanations\n",
    "    Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "    candidate_class = Spouse\n",
    "    spouse_tutorial_path = os.path.join(os.environ['SNORKELHOME'], 'tutorials/') \n",
    "    sys.path.append(spouse_tutorial_path)    \n",
    "elif DOMAIN == 'cdr':\n",
    "    import cdr_examples\n",
    "    user_lists = cdr_examples.get_user_lists()\n",
    "    explanations = cdr_examples.explanations\n",
    "    ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "    candidate_class = ChemicalDisease\n",
    "elif DOMAIN == 'bike':\n",
    "    explanations = None # FIXME\n",
    "    ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "    candidate_class = ChemicalDisease    \n",
    "else:\n",
    "    raise Exception(\"Invalid domain: {}\".format(DOMAIN))\n",
    "    \n",
    "candidates = session.query(candidate_class).all()\n",
    "explanations = link_explanation_candidates(explanations, candidates)\n",
    "print(\"Domain: {}\".format(DOMAIN))\n",
    "print(\"Explanations: {}\".format(len(explanations)))\n",
    "print(\"Candidates: {}\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import Explanation\n",
    "\n",
    "good = Explanation(\"'wife' is in the sentence.\", True)\n",
    "bad1 = Explanation(\"arg 1 is in the sentence.\", True)\n",
    "bad2 = Explanation(\"arg 2 is in the sentence.\", False)\n",
    "explanations = [good, bad1, bad2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created grammar with 360 rules\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.babble import Babbler\n",
    "babbler = Babbler(mode='text', candidate_class=Spouse, \n",
    "                  explanations=explanations, user_lists=user_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 parses created from 3 out of 3 explanation(s)\n"
     ]
    }
   ],
   "source": [
    "lfs = babbler.generate_lfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_wife_in_sentence(c):\n",
    "    \"\"\"A simple example of a labeling function\"\"\"\n",
    "    return 1 if 'wife' in c.get_parent().words else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            0.0\n",
      "Recall               0.0\n",
      "F1                   0.0\n",
      "----------------------------------------\n",
      "TP: 0 | FP: 0 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n",
      "CPU times: user 29.2 s, sys: 1.07 s, total: 30.2 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.lf_helpers import test_LF\n",
    "%time tp, fp, tn, fn = test_LF(session, LF_wife_in_sentence, split=0, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babbler.filter_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import sem_to_str\n",
    "[sem_to_str(p.semantics) for p in babbler.parses[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_dev = babbler.generate_label_matrix(split=1)\n",
    "# L_dev = babbler.load_matrix(session,split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babbler.filter_uniform_signatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "babbler.filter_duplicate_signatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_dev.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum(L_dev, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caught = set(L_dev[:,1].nonzero()[0])\n",
    "for i in range(2811):\n",
    "    if i not in caught:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from snorkel.contrib.babble.text import get_sentence_phrases\n",
    "pprint([p.words for p in get_sentence_phrases(L_dev.get_candidate(session, 843)[0],n_max=7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_candidates = session.query(candidate_class).filter(Spouse.split == 1).all()\n",
    "print(len(dev_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import utils\n",
    "\n",
    "# # Link examples with their corresponding candidates\n",
    "# examples = utils.link_example_candidates(examples, dev_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spouse_label_path = os.path.join(os.environ['SNORKELHOME'], 'tutorials/intro/data/gold_labels.tsv') \n",
    "\n",
    "import intro\n",
    "\n",
    "%time intro.load_external_labels(session, Spouse, annotator_name='gold', path=spouse_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import bz2\n",
    "# import os \n",
    "\n",
    "# spouses_pickle_path = os.path.join(os.environ['SNORKELHOME'], \n",
    "#         'tutorials/intro/data/spouses_dbpedia.csv.bz2') \n",
    "\n",
    "# def strip_special(s):\n",
    "#     return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# def last_name(s):\n",
    "#     name_parts = s.split(' ')\n",
    "#     return name_parts[-1] if len(name_parts) > 1 else None  \n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File(spouses_pickle_path, 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "\n",
    "# def LF_distant_supervision(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     return 1 if (p1, p2) in known_spouses or (p2, p1) in known_spouses else 0\n",
    "\n",
    "# def LF_distant_supervision_last_names(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     p1n, p2n = last_name(p1), last_name(p2)\n",
    "#     return 1 if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# candidate_subset = []\n",
    "# for c in dev_candidates:\n",
    "#     if hash(c) == -2597662937532403956:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "sv = SentenceNgramViewer(dev_candidates[:300], session)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "married = ['husband', 'wife', 'spouse', 'marriage', 'married']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_neighbors(c):\n",
    "    return -1 if (len(c[0].get_attrib_tokens()) == 1 and \n",
    "                  len(c[1].get_attrib_tokens()) == 1 and \n",
    "                  not set(married).intersection(c.get_parent().words)) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled = []\n",
    "for c in session.query(Spouse).filter(Spouse.split == 1).all():\n",
    "    if LF_neighbors(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "sv = SentenceNgramViewer(fn, session)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(dev_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "test_labels     = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.models import Candidate\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "import numpy as np\n",
    "\n",
    "lf = LF_neighbors\n",
    "\n",
    "dev_candidates = session.query(Candidate).filter(Candidate.split == 1).all()\n",
    "test_labels     = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "scorer          = MentionScorer(dev_candidates, test_labels)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in dev_candidates])\n",
    "scorer.score(test_marginals, set_unlabeled_as_neg=False, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(test_candidates))\n",
    "print(test_labels.nnz)\n",
    "max(test_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import Explanation\n",
    "\n",
    "explanations = [\n",
    "    # Tuple\n",
    "    Explanation(\n",
    "        condition=\"label True because the pair (arg 1, arg 2) is the same as the tuple ('foo', 'bar')\",\n",
    "        candidate=('foo', 'bar'),\n",
    "        label=1,\n",
    "        semantics=('.root', ('.label', ('.bool', True), ('.call', ('.eq', ('.tuple', ('.list', ('.string', u'foo'), ('.string', u'bar')))), ('.tuple', ('.list', ('.arg_to_string', ('.arg', ('.int', 1))), ('.arg_to_string', ('.arg', ('.int', 2))))))))),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import SemanticParser\n",
    "\n",
    "%time sp = SemanticParser(candidate_class, user_lists, beam_width=10, top_k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time LFs = sp.parse_and_evaluate(explanations,\\\n",
    "                                  show_everything=True,\\\n",
    "                                  show_nothing=False,\\\n",
    "                                  show_explanation=True,\\\n",
    "                                  show_candidate=False,\\\n",
    "                                  show_sentence=False,\\\n",
    "                                  show_parse=True,\\\n",
    "                                  show_semantics=True,\\\n",
    "                                  show_correct=False,\\\n",
    "                                  show_passing=True,\\\n",
    "                                  show_failing=True,\\\n",
    "                                  pseudo_python=True,\\\n",
    "                                  remove_paren=False,\\\n",
    "                                  paraphrases=False,\\\n",
    "                                  only=[])\n",
    "sp.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print np.sum(sp.results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp.grammar.print_chart(nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sp.grammar.print_grammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Make mini-corpus for test\n",
    "\n",
    "# import os\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import Document, candidate_subclass\n",
    "# from snorkel.parser import TSVDocPreprocessor, CorpusParser\n",
    "# from snorkel.parser.spacy_parser import Spacy\n",
    "# from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "# from snorkel.matchers import PersonMatcher\n",
    "# from snorkel.contrib.babble import SemanticParser, Example\n",
    "\n",
    "# test_article_path = os.environ['SNORKELHOME'] + '/test/babble/test_article.tsv'\n",
    "# doc_preprocessor = TSVDocPreprocessor(test_article_path)\n",
    "# corpus_parser = CorpusParser(parser=Spacy())\n",
    "# corpus_parser.apply(doc_preprocessor)\n",
    "# Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "# ngrams         = Ngrams(n_max=2)\n",
    "# person_matcher = PersonMatcher(longest_match_only=True)\n",
    "# cand_extractor = CandidateExtractor(Spouse, [ngrams, ngrams], [person_matcher, person_matcher], symmetric_relations=False)\n",
    "# docs = session.query(Document).order_by(Document.name).all()\n",
    "# sents = [s for doc in docs for s in doc.sentences]\n",
    "# cand_extractor.apply(sents, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# candidates = session.query(Spouse).all()\n",
    "# for c in candidates:\n",
    "#     print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
