{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'qalf',\n",
    "    'domain': 'tacred',\n",
    "    'relation': 'per_title',\n",
    "    'splits': [0],\n",
    "    'supervision': 'traditional',\n",
    "    'max_train': 2000,\n",
    "#     'max_lfs': 1,\n",
    "#     'learn_deps': True,\n",
    "#     'gen_model_search_space': 1,\n",
    "#     'gen_init_params': {\n",
    "#         'lf_propensity'         : True,\n",
    "#         'class_prior'           : True,\n",
    "#         'lf_class_propensity'   : True,\n",
    "#         'seed'                  : None,\n",
    "#     },\n",
    "#     'gen_params_default': {\n",
    "#         'step_size'     : 0.0001,\n",
    "#         'decay'         : 0.90,\n",
    "#         'reg_param'     : 0.50,\n",
    "#         'epochs'        : 25,\n",
    "#     },    \n",
    "    'disc_model_class': 'logreg',    \n",
    "    'disc_model_search_space': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///qalf_tacred_per_title.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = (config['project'] + '_' + config['domain'] + \n",
    "                   ('_' + config['relation'] if config['relation'] else '') +\n",
    "                   ('_debug' if config.get('debug', False) else ''))\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting disc_model_search_space=10 to disc_model_search_space=1\n",
      "Overwriting splits=[0, 1] to splits=[0]\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting domain=None to domain=tacred\n",
      "Overwriting max_sentence_length=100 to max_sentence_length=200\n",
      "Overwriting rebalance=0.25 to rebalance=False\n",
      "Overwriting disc_model_search_space=10 to disc_model_search_space=1\n",
      "Overwriting splits=[0, 1, 2] to splits=[0]\n",
      "Overwriting max_train=None to max_train=2000\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting supervision=generative to supervision=traditional\n",
      "Overwriting project=babble to project=qalf\n",
      "Using TacredQalfPipeline object.\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'], config['project'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: 5200 Candidates\n",
      "Split 1: 1935 Candidates\n",
      "Split 2: 0 Candidates\n"
     ]
    }
   ],
   "source": [
    "for split in [0,1,2]:\n",
    "    num_cands = pipe.session.query(pipe.candidate_class).filter(\n",
    "        pipe.candidate_class.split == split).count()\n",
    "    print(\"Split {}: {} Candidates\".format(split, num_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*QalfPipeline objects load QA result matrices in the label() method.\n",
      "CPU times: user 306 µs, sys: 286 µs, total: 592 µs\n",
      "Wall time: 326 µs\n"
     ]
    }
   ],
   "source": [
    "%time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 13.5 s, sys: 284 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels\n",
    "# L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "# pipe.L_train.lf_stats(session, labels=L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels\n",
    "# L_gold_dev   = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# pipe.L_dev.lf_stats(session, labels=L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...skipping 'supervise' stage.\n",
      "CPU times: user 191 µs, sys: 123 µs, total: 314 µs\n",
      "Wall time: 204 µs\n"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...grabbing candidate and gold label subsets.\n",
      "NOTE: traditional supervision helper assumes all candidates have labels.\n",
      "Using 2000 traditional gold labels\n",
      "(2000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2ac90e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [7.1] Begin training discriminative model\n",
      "Skipping grid search.\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=2000  #epochs=20  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (0.08s)\tAverage loss=0.593795\tDev F1=75.09\n",
      "[SparseLogisticRegression] Epoch 1 (0.18s)\tAverage loss=0.506632\tDev F1=74.70\n",
      "[SparseLogisticRegression] Epoch 2 (0.28s)\tAverage loss=0.471094\tDev F1=75.24\n",
      "[SparseLogisticRegression] Epoch 3 (0.38s)\tAverage loss=0.450330\tDev F1=75.15\n",
      "[SparseLogisticRegression] Epoch 4 (0.49s)\tAverage loss=0.434225\tDev F1=75.50\n",
      "[SparseLogisticRegression] Epoch 5 (0.58s)\tAverage loss=0.422210\tDev F1=75.33\n",
      "[SparseLogisticRegression] Epoch 6 (0.68s)\tAverage loss=0.412203\tDev F1=75.15\n",
      "[SparseLogisticRegression] Epoch 7 (0.79s)\tAverage loss=0.403008\tDev F1=75.13\n",
      "[SparseLogisticRegression] Epoch 8 (0.88s)\tAverage loss=0.396356\tDev F1=75.19\n",
      "[SparseLogisticRegression] Epoch 9 (0.98s)\tAverage loss=0.391621\tDev F1=74.87\n",
      "[SparseLogisticRegression] Epoch 10 (1.09s)\tAverage loss=0.384324\tDev F1=75.11\n",
      "[SparseLogisticRegression] Epoch 11 (1.19s)\tAverage loss=0.379635\tDev F1=74.91\n",
      "[SparseLogisticRegression] Epoch 12 (1.29s)\tAverage loss=0.375803\tDev F1=74.89\n",
      "[SparseLogisticRegression] Epoch 13 (1.39s)\tAverage loss=0.374947\tDev F1=74.85\n",
      "[SparseLogisticRegression] Epoch 14 (1.49s)\tAverage loss=0.368836\tDev F1=74.95\n",
      "[SparseLogisticRegression] Epoch 15 (1.60s)\tAverage loss=0.367333\tDev F1=75.04\n",
      "[SparseLogisticRegression] Epoch 16 (1.71s)\tAverage loss=0.367971\tDev F1=74.77\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 17 (2.13s)\tAverage loss=0.359993\tDev F1=73.76\n",
      "[SparseLogisticRegression] Epoch 18 (2.22s)\tAverage loss=0.360444\tDev F1=74.24\n",
      "[SparseLogisticRegression] Epoch 19 (2.32s)\tAverage loss=0.355008\tDev F1=74.22\n",
      "[SparseLogisticRegression] Training done (2.37s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Model saved as <discriminative_tacred>\n",
      "### Done in 3.2s.\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [F1 Score, Precision, Recall]\n",
      "Index: []\n",
      "CPU times: user 7 s, sys: 548 ms, total: 7.55 s\n",
      "Wall time: 6.94 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Sentence\n",
    "# s = pipe.session.query(Sentence).first()\n",
    "# s.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from spacy.lemmatizer import Lemmatizer\n",
    "# from spacy.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "# lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "# lemmas = lemmatizer(u'ducks', u'NOUN')\n",
    "# print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from spacy.lemmatizer import Lemmatizer\n",
    "# lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
