{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'bike',\n",
    "    'postgres': False,\n",
    "    'debug': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_bike_debug.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config['debug'] else '')\n",
    "DB_NAME = getattr(config, 'db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: --debug=True: modifying parameters...\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "if config['debug']:\n",
    "    print(\"NOTE: --debug=True: modifying parameters...\")\n",
    "    config['max_docs'] = 100\n",
    "    config['gen_model_search_space'] = 2\n",
    "    config['disc_model_search_space'] = 2\n",
    "    config['gen-params-default']['epochs'] = 25\n",
    "    config['disc-params-default']['n_epochs'] = 5\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Running UDF...\n"
     ]
    }
   ],
   "source": [
    "pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction was performed during parse stage.\n",
      "Candidates [Split 0]: 2406\n",
      "Candidates [Split 1]: 1037\n"
     ]
    }
   ],
   "source": [
    "pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading val CSV!\n",
      "Num HITs unique: 495\n",
      "Num HITs total: 997\n",
      "Unanimous: 311\n",
      "Majority: 772\n",
      "Bad: 131\n",
      "Reading train CSV!\n",
      "Num HITs unique: 602\n",
      "Num HITs total: 1806\n",
      "Unanimous: 1660\n",
      "Majority: 883\n",
      "Bad: 304\n",
      "AnnotatorLabels created: 906\n",
      "AnnotatorLabels created: 2102\n"
     ]
    }
   ],
   "source": [
    "pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train CSV!\n",
      "Num HITs unique: 40\n",
      "Num HITs total: 120\n",
      "Unanimous: 99\n",
      "Majority: 63\n",
      "Bad: 27\n",
      "Building list of target candidate ids...\n",
      "Collected 131 unique target candidate ids from 358 explanations.\n",
      "Gathering desired candidates...\n",
      "Found 131/131 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 358/358 explanations\n",
      "Calling babbler...\n",
      "Created grammar with 431 rules\n",
      "336 parses created from 241 out of 358 explanation(s)\n",
      "Parsed 336 LFs from 358 explanations.\n",
      "Filtered to 98 LFs with duplicate semantics filter (238 filtered).\n",
      "Filtered to 57 LFs with consistency filter (41 filtered).\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Filtered to 47 LFs with uniform signatures filter (10 filtered).\n",
      "Filtered to 33 LFs with duplicate signatures filter (14 filtered).\n"
     ]
    }
   ],
   "source": [
    "pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "\n",
      "Labeled split 0: (2406,33) sparse (nnz = 41059)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "\n",
      "Labeled split 1: (1037,33) sparse (nnz = 17416)\n",
      "                   j  Coverage  Overlaps  Conflicts   TP   FP   FN   TN  \\\n",
      "Explanation11_0    0  0.372228  0.372228   0.372228    0    0   59  278   \n",
      "Explanation12_0    1  0.487946  0.487946   0.487946    0    0   77  357   \n",
      "Explanation147_0   2  0.516876  0.516876   0.516876    0    0  101  374   \n",
      "Explanation16_0    3  0.392478  0.392478   0.392478    0    0   15  353   \n",
      "Explanation172_0   4  0.591128  0.591128   0.591128  144  355    0    0   \n",
      "Explanation185_0   5  0.511090  0.511090   0.511090   98  370    0    0   \n",
      "Explanation197_0   6  0.214079  0.214079   0.214079    0    0    6  195   \n",
      "Explanation20_0    7  0.816779  0.816779   0.816779    0    0  174  571   \n",
      "Explanation22_0    8  0.778206  0.778206   0.778206    0    0  171  528   \n",
      "Explanation249_0   9  0.398264  0.398264   0.398264    0    0   17  357   \n",
      "Explanation254_0  10  0.631630  0.631630   0.631630  149  390    0    0   \n",
      "Explanation254_4  11  0.638380  0.638380   0.638380  150  403    0    0   \n",
      "Explanation254_5  12  0.495661  0.495661   0.495661   80  364    0    0   \n",
      "Explanation28_0   13  0.504339  0.504339   0.504339    0    0   97  365   \n",
      "Explanation291_0  14  0.619094  0.619094   0.619094    0    0  157  377   \n",
      "Explanation294_0  15  0.607522  0.607522   0.607522  162  376    0    0   \n",
      "Explanation30_0   16  0.404050  0.404050   0.404050  102  224    0    0   \n",
      "Explanation31_0   17  0.601736  0.601736   0.601736  160  372    0    0   \n",
      "Explanation327_2  18  0.285439  0.285439   0.285439    0    0   20  260   \n",
      "Explanation330_0  19  0.387657  0.387657   0.387657  102  204    0    0   \n",
      "Explanation331_0  20  0.606557  0.606557   0.606557  131  393    0    0   \n",
      "Explanation341_0  21  0.727097  0.727097   0.727097    0    0   42  624   \n",
      "Explanation351_0  22  0.472517  0.472517   0.472517    0    0  108  281   \n",
      "Explanation36_0   23  0.484089  0.484089   0.484089    0    0   77  358   \n",
      "Explanation39_0   24  0.101254  0.101254   0.101254    0    0    0   97   \n",
      "Explanation40_0   25  0.627772  0.627772   0.627772    0    0  118  451   \n",
      "Explanation5_0    26  0.272903  0.272903   0.272903  135  105    0    0   \n",
      "Explanation53_0   27  0.488910  0.488910   0.488910   79  359    0    0   \n",
      "Explanation6_0    28  0.398264  0.398264   0.398264    0    0   67  250   \n",
      "Explanation60_0   29  0.553520  0.553520   0.553520    0    0  113  354   \n",
      "Explanation71_0   30  0.106075  0.106075   0.106075    0    0    5   88   \n",
      "Explanation86_0   31  0.802314  0.802314   0.802314  169  540    0    0   \n",
      "Explanation94_0   32  0.898746  0.898746   0.898746  177  632    0    0   \n",
      "\n",
      "                  Empirical Acc.  \n",
      "Explanation11_0         0.824926  \n",
      "Explanation12_0         0.822581  \n",
      "Explanation147_0        0.787368  \n",
      "Explanation16_0         0.959239  \n",
      "Explanation172_0        0.288577  \n",
      "Explanation185_0        0.209402  \n",
      "Explanation197_0        0.970149  \n",
      "Explanation20_0         0.766443  \n",
      "Explanation22_0         0.755365  \n",
      "Explanation249_0        0.954545  \n",
      "Explanation254_0        0.276438  \n",
      "Explanation254_4        0.271248  \n",
      "Explanation254_5        0.180180  \n",
      "Explanation28_0         0.790043  \n",
      "Explanation291_0        0.705993  \n",
      "Explanation294_0        0.301115  \n",
      "Explanation30_0         0.312883  \n",
      "Explanation31_0         0.300752  \n",
      "Explanation327_2        0.928571  \n",
      "Explanation330_0        0.333333  \n",
      "Explanation331_0        0.250000  \n",
      "Explanation341_0        0.936937  \n",
      "Explanation351_0        0.722365  \n",
      "Explanation36_0         0.822989  \n",
      "Explanation39_0         1.000000  \n",
      "Explanation40_0         0.792619  \n",
      "Explanation5_0          0.562500  \n",
      "Explanation53_0         0.180365  \n",
      "Explanation6_0          0.788644  \n",
      "Explanation60_0         0.758030  \n",
      "Explanation71_0         0.946237  \n",
      "Explanation86_0         0.238364  \n",
      "Explanation94_0         0.218789  \n"
     ]
    }
   ],
   "source": [
    "pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L_train: <2406x33 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 41059 stored elements in Compressed Sparse Row format>\n",
      "Using L_dev: <1037x33 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 17416 stored elements in Compressed Sparse Row format>\n",
      "============================================================\n",
      "[1] Testing LF_acc_prior_weight_default = 5.00e-01, step_size = 1.00e-02, init_class_prior = -1.15e+00, reg_param = 2.50e-01, decay = 9.50e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.291598023064\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "============================================================\n",
      "[2] Testing LF_acc_prior_weight_default = 1.00e+00, step_size = 1.00e-05, init_class_prior = -1.15e+00, reg_param = 2.50e-01, decay = 9.50e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.435967302452\n",
      "[GenerativeModel] Model saved as <GenerativeModel_1>.\n",
      "[GenerativeModel] Model <GenerativeModel_1> loaded.\n",
      "   LF_acc_prior_weight_default  step_size  init_class_prior  reg_param  decay  \\\n",
      "1                          1.0    0.00001             -1.15       0.25   0.95   \n",
      "0                          0.5    0.01000             -1.15       0.25   0.95   \n",
      "\n",
      "      Prec.      Rec.       F-1  \n",
      "1  0.287253  0.903955  0.435967  \n",
      "0  0.170685  1.000000  0.291598  \n",
      "[GenerativeModel] Model saved as <generative_bike>.\n",
      "\n",
      "Gen. model (DP) score on dev set (b=0.9):\n",
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.825\n",
      "Neg. class accuracy: 0.66\n",
      "Precision            0.333\n",
      "Recall               0.825\n",
      "F1                   0.475\n",
      "----------------------------------------\n",
      "TP: 146 | FP: 292 | TN: 568 | FN: 31\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/1/paroma/anaconda2/envs/py2Env/lib/python2.7/site-packages/matplotlib/font_manager.py:280: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD1FJREFUeJzt3X+s3Xddx/Hny5ZNfih09trUtthqKtgRCXCdEwhBqllh\nxs6ELFWBhiw2holoTKTjD/eHaVISY4DoMM1AaiQ0zVhclR+6FBENbuMOBltb6650W1u69QIKismw\n29s/7td4LL27d+d77zm99/N8JDfn8/18P9/v9/3JvTmv8/2ec743VYUkqU3fN+4CJEnjYwhIUsMM\nAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGrZ63AXMZ+3atbV58+ZxlyFJy8r999//9aqa\nmG/cZR8CmzdvZmpqatxlSNKykuTRhYzzcpAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0z\nBCSpYYaAJDXssv/GsCQtV5v3fmLobR/Zf/0iVjI3zwQkqWGGgCQ1zBCQpIYZApLUMENAkho2bwgk\n+XCS80keGui7KsndSR7uHtcMrLslyXSSk0muG+h/VZIHu3UfSJLFn44k6dlYyJnAR4AdF/XtBY5W\n1VbgaLdMkm3ALuDqbpvbkqzqtvkg8OvA1u7n4n1KkkZs3hCoqs8B37yoeydwsGsfBG4Y6D9UVU9W\n1SlgGrgmyXrgB6vqnqoq4M8HtpEkjcmw7wmsq6pzXftxYF3X3gCcHhh3puvb0LUv7r+kJHuSTCWZ\nmpmZGbJESdJ8er8x3L2yr0WoZXCfB6pqsqomJybm/T/JkqQhDRsCT3SXeOgez3f9Z4FNA+M2dn1n\nu/bF/ZKkMRo2BI4Au7v2buCugf5dSa5MsoXZN4Dv6y4dfTvJtd2ngt42sI0kaUzmvYFcko8BrwfW\nJjkD3ArsBw4nuQl4FLgRoKqOJTkMHAcuADdX1VPdrt7B7CeNngt8qvuRJI3RvCFQVb8yx6rtc4zf\nB+y7RP8U8LJnVZ0kaUn5jWFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqY\nISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkC\nktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUsF4hkOR3khxL8lCSjyX5/iRX\nJbk7ycPd45qB8bckmU5yMsl1/cuXJPUxdAgk2QD8FjBZVS8DVgG7gL3A0araChztlkmyrVt/NbAD\nuC3Jqn7lS5L66Hs5aDXw3CSrgecBXwN2Age79QeBG7r2TuBQVT1ZVaeAaeCanseXJPUwdAhU1Vng\nD4HHgHPAt6rqb4F1VXWuG/Y4sK5rbwBOD+ziTNcnSRqTPpeD1jD76n4L8CPA85O8ZXBMVRVQQ+x7\nT5KpJFMzMzPDlihJmkefy0E/D5yqqpmq+m/gTuDVwBNJ1gN0j+e78WeBTQPbb+z6vkdVHaiqyaqa\nnJiY6FGiJOmZ9AmBx4BrkzwvSYDtwAngCLC7G7MbuKtrHwF2JbkyyRZgK3Bfj+NLknpaPeyGVXVv\nkjuALwIXgC8BB4AXAIeT3AQ8CtzYjT+W5DBwvBt/c1U91bN+SVIPQ4cAQFXdCtx6UfeTzJ4VXGr8\nPmBfn2NKkhaP3xiWpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBD\nQJIaZghIUsMMAUlqmCEgSQ0zBCSpYb3+n8DlbvPeTwy97SP7r1/ESiTp8uSZgCQ1zBCQpIYZApLU\nMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ3r\nFQJJXpTkjiT/nOREkp9NclWSu5M83D2uGRh/S5LpJCeTXNe/fElSH33PBN4PfLqqXgq8HDgB7AWO\nVtVW4Gi3TJJtwC7gamAHcFuSVT2PL0nqYegQSPJC4HXAhwCq6rtV9e/ATuBgN+wgcEPX3gkcqqon\nq+oUMA1cM+zxJUn99TkT2ALMAH+W5EtJbk/yfGBdVZ3rxjwOrOvaG4DTA9uf6fq+R5I9SaaSTM3M\nzPQoUZL0TPqEwGrglcAHq+oVwHfoLv38r6oqoJ7tjqvqQFVNVtXkxMREjxIlSc+kTwicAc5U1b3d\n8h3MhsITSdYDdI/nu/VngU0D22/s+iRJYzJ0CFTV48DpJC/purYDx4EjwO6ubzdwV9c+AuxKcmWS\nLcBW4L5hjy9J6m91z+3fCXw0yRXAV4G3Mxssh5PcBDwK3AhQVceSHGY2KC4AN1fVUz2PL0nqoVcI\nVNUDwOQlVm2fY/w+YF+fY0qSFo/fGJakhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1\nzBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMM\nAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkN6x0CSVYl+VKSv+6W\nr0pyd5KHu8c1A2NvSTKd5GSS6/oeW5LUz2KcCbwLODGwvBc4WlVbgaPdMkm2AbuAq4EdwG1JVi3C\n8SVJQ+oVAkk2AtcDtw907wQOdu2DwA0D/Yeq6smqOgVMA9f0Ob4kqZ++ZwLvA34PeHqgb11Vneva\njwPruvYG4PTAuDNdnyRpTIYOgSS/CJyvqvvnGlNVBdQQ+96TZCrJ1MzMzLAlSpLm0edM4DXALyV5\nBDgEvCHJXwBPJFkP0D2e78afBTYNbL+x6/seVXWgqiaranJiYqJHiZKkZzJ0CFTVLVW1sao2M/uG\n72eq6i3AEWB3N2w3cFfXPgLsSnJlki3AVuC+oSuXJPW2egn2uR84nOQm4FHgRoCqOpbkMHAcuADc\nXFVPLcHxJUkLtCghUFWfBT7btb8BbJ9j3D5g32IcU5LUn98YlqSGGQKS1DBDQJIaZghIUsMMAUlq\nmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZ\nApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEg\nSQ0zBCSpYUOHQJJNSf4uyfEkx5K8q+u/KsndSR7uHtcMbHNLkukkJ5NctxgTkCQNr8+ZwAXgd6tq\nG3AtcHOSbcBe4GhVbQWOdst063YBVwM7gNuSrOpTvCSpn6FDoKrOVdUXu/Z/ACeADcBO4GA37CBw\nQ9feCRyqqier6hQwDVwz7PElSf0tynsCSTYDrwDuBdZV1blu1ePAuq69ATg9sNmZru9S+9uTZCrJ\n1MzMzGKUKEm6hN4hkOQFwMeB366qbw+uq6oC6tnus6oOVNVkVU1OTEz0LVGSNIdeIZDkOcwGwEer\n6s6u+4kk67v164HzXf9ZYNPA5hu7PknSmPT5dFCADwEnquqPBlYdAXZ37d3AXQP9u5JcmWQLsBW4\nb9jjS5L6W91j29cAbwUeTPJA1/ceYD9wOMlNwKPAjQBVdSzJYeA4s58surmqnupxfElST0OHQFX9\nI5A5Vm+fY5t9wL5hjylJWlx+Y1iSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENA\nkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1LA+/1lMkla8zXs/Me4SlpRnApLUMENA\nkhpmCEhSwwwBSWqYISBJDfPTQZehPp9GeGT/9YtYiaSVzjMBSWqYZwJz8NW45uPfiFYCQ0DSSKz0\nL10tV14OkqSGeSawBMb5isdLFJKeDUNATRtXYPc97rgC20s6K48hoGXPJyZpeCMPgSQ7gPcDq4Db\nq2r/qGvQpflkKrVnpCGQZBXwJ8AvAGeALyQ5UlXHR1mHtNwZ2Foso/500DXAdFV9taq+CxwCdo64\nBklSZ9QhsAE4PbB8puuTJI3BZfnGcJI9wJ5u8T+TnBxyV2uBry9OVcuGc25Da3Nubb7kvb3n/KML\nGTTqEDgLbBpY3tj1/T9VdQA40PdgSaaqarLvfpYT59yG1ubc2nxhdHMe9eWgLwBbk2xJcgWwCzgy\n4hokSZ2RnglU1YUkvwn8DbMfEf1wVR0bZQ2SpP8z8vcEquqTwCdHdLjel5SWIefchtbm3Np8YURz\nTlWN4jiSpMuQdxGVpIatiBBIsiPJySTTSfZeYn2SfKBb/5UkrxxHnYtlAfP9tW6eDyb5fJKXj6PO\nxTTfnAfG/XSSC0nePMr6lsJC5pzk9UkeSHIsyd+PusbFtoC/7Rcm+askX+7m/PZx1LlYknw4yfkk\nD82xfumfu6pqWf8w+wbzvwI/BlwBfBnYdtGYNwGfAgJcC9w77rqXeL6vBtZ07Tcu5/kudM4D4z7D\n7HtObx533SP4Pb8IOA68uFv+4XHXPYI5vwd4b9eeAL4JXDHu2nvM+XXAK4GH5li/5M9dK+FMYCG3\notgJ/HnNugd4UZL1oy50kcw736r6fFX9W7d4D7Pfx1jOFnq7kXcCHwfOj7K4JbKQOf8qcGdVPQZQ\nVct93guZcwE/kCTAC5gNgQujLXPxVNXnmJ3DXJb8uWslhMBCbkWxkm5X8WznchOzrySWs3nnnGQD\n8MvAB0dY11JayO/5J4A1ST6b5P4kbxtZdUtjIXP+Y+Anga8BDwLvqqqnR1PeWCz5c9dledsILY4k\nP8dsCLx23LWMwPuAd1fV07MvEpuwGngVsB14LvBPSe6pqn8Zb1lL6jrgAeANwI8Ddyf5h6r69njL\nWr5WQggs5FYUC7pdxTKxoLkk+SngduCNVfWNEdW2VBYy50ngUBcAa4E3JblQVX85mhIX3ULmfAb4\nRlV9B/hOks8BLweWawgsZM5vB/bX7AXz6SSngJcC942mxJFb8ueulXA5aCG3ojgCvK17p/1a4FtV\ndW7UhS6Seeeb5MXAncBbV8irwnnnXFVbqmpzVW0G7gDesYwDABb2d30X8Nokq5M8D/gZ4MSI61xM\nC5nzY8ye+ZBkHfAS4KsjrXK0lvy5a9mfCdQct6JI8hvd+j9l9tMibwKmgf9i9tXEsrTA+f4+8EPA\nbd0r4wu1jG++tcA5rygLmXNVnUjyaeArwNPM/qe+S37UcDlY4O/5D4CPJHmQ2U/MvLuqlu3dRZN8\nDHg9sDbJGeBW4DkwuucuvzEsSQ1bCZeDJElDMgQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwB\nSWrY/wCqcyVb70QdzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94be0a88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing dim = 50, dropout = 2.50e-01, rebalance = 2.50e-01, lr = 1.00e-03\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Bbox' object has no attribute 'get_word_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-10370f9296b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/contrib/babble/pipelines/snorkel_pipeline.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'discriminative_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0meval_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disc-eval-batch-size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         )\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/contrib/babble/pipelines/utils.pyc\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, X_train, Y_train, X_dev, Y_dev, search_size, search_params, rand_seed, n_threads, verbose, cardinality, params_default, model_init_params, model_name, save_dir, beta, eval_batch_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# Run random grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             model, run_stats, opt_b = searcher.fit(X_dev, Y_dev, n_threads=n_threads,\n\u001b[0;32m---> 74\u001b[0;31m                 beta=beta, eval_batch_size=eval_batch_size)\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/utils.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_valid, Y_valid, b, beta, set_unlabeled_as_neg, n_threads, eval_batch_size)\u001b[0m\n\u001b[1;32m    405\u001b[0m             opt_model, run_stats = self._fit_st(X_valid, Y_valid, b=b, \n\u001b[1;32m    406\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_unlabeled_as_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_unlabeled_as_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 eval_batch_size=eval_batch_size)\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mopt_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/utils.pyc\u001b[0m in \u001b[0;36m_fit_st\u001b[0;34m(self, X_valid, Y_valid, b, beta, set_unlabeled_as_neg, eval_batch_size)\u001b[0m\n\u001b[1;32m    455\u001b[0m                     save_dir=self.save_dir, **hps)\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/disc_models/rnn/rnn_base.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, Y_train, X_dev, max_sentence_length, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# Text preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_dev\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/disc_models/rnn/re_rnn.pyc\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, candidates, extend)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Mark sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             args = [\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             ]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Bbox' object has no attribute 'get_word_start'"
     ]
    }
   ],
   "source": [
    "pipe.classify(config)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
