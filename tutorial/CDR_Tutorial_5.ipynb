{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Tagging Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Evaluating the Model on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final part of the tutorial, we will reload the model developed in Part IV and test it on the test `CandidateSet`.\n",
    "\n",
    "A benchmark score for this task, using [TaggerOne](http://www.ncbi.nlm.nih.gov/pubmed/27283952), is **79.6 F1**; we'll see that we will come within 1-2 points F1 score of this already!  (And, if we utilize additional unlabeled data--not covered in this tutorial, but easy to implement!--we can match or exceed it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our definition of the `Disease` `Candidate` subclass from Parts II, III, and IV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test `CandidateSet`\n",
    "\n",
    "We reload the test `CandidateSet` object from the previous parts of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "test = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Test Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features\n",
    "We also generate features for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use the training features feature set, because those are the only features for which we have learned parameters. Features that were not encountered during training, e.g., a token that does not appear in the training set, are ignored, because we do not have any information about them.\n",
    "\n",
    "To do so with the `FeatureManager`, we call update with the new `CandidateSet`, the name of the training `AnnotationKeySet`, and the value `False` for the parameter `extend_key_set` to indicate that the `AnnotationKeySet` should not be expanded with new `Feature` keys encountered during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=                                       ] 0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/snorkel/snorkel/utils.py:16: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  sys.stdout.write(\"\\r[%s%s] %d%%\" % (\"=\"*b, \" \"*(self.length-b), 100*((i+1) / self.nf)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 3min 54s, sys: 7.15 s, total: 4min 1s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%time F_test = feature_manager.update(session, test, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time F_test = feature_manager.load(session, test, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reloading the Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 967 ms, sys: 76.6 ms, total: 1.04 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "%time disc_model.load(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Test `CandidateSet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the test set labels and gold candidates we made in Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "L_test = label_manager.load(session, test, \"CDR Test Labels -- Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_test_set = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Test Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Test set size:\t6407\n",
      "----------------------------------------\n",
      "Pos. class accuracy: 0.948176583493\n",
      "Neg. class accuracy: 0.625724637681\n",
      "----------------------------------------\n",
      "Precision:\t0.769984413271\n",
      "Recall:\t\t0.948176583493\n",
      "F1 Score:\t0.849840255591\n",
      "----------------------------------------\n",
      "TP: 3458 | FP: 1033 | TN: 1727 | FN: 189\n",
      "========================================\n",
      "========================================\n",
      "Recall-corrected Noise-aware Model\n",
      "========================================\n",
      "Pos. class accuracy: 0.78164556962\n",
      "Neg. class accuracy: 0.625724637681\n",
      "Corpus Precision 0.77\n",
      "Corpus Recall    0.782\n",
      "Corpus F1        0.776\n",
      "----------------------------------------\n",
      "TP: 3458 | FP: 1033 | TN: 1727 | FN: 966\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_test, L_test, gold_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've completed the tutorial!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
