{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB_V_MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.parser import CorpusParser, HTMLParser, OmniParser\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.queries import split_corpus\n",
    "\n",
    "html_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_html/'\n",
    "pdf_path  = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_pdf/'\n",
    "doc_parser = HTMLParser(path=html_path)\n",
    "context_parser = OmniParser(flatten=['span'], blacklist=['style'],\n",
    "                            visual=True, pdf_path=pdf_path, session=session)\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "CPU times: user 3min 5s, sys: 7.09 s, total: 3min 12s\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%time corpus = cp.parse_corpus(name='Hardware', session=session)\n",
    "\n",
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 Documents added to corpus Hardware Training\n",
      "19 Documents added to corpus Hardware Development\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "split_corpus(session, corpus, train=0.8, development=0.2, test=0, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "eeca_rgx = '([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)'\n",
    "eeca_matcher = RegexMatchSpan(rgx=eeca_rgx)\n",
    "jedec_rgx = '([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jedec_matcher = RegexMatchSpan(rgx=jedec_rgx)\n",
    "jis_rgx = '(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})'\n",
    "jis_matcher = RegexMatchSpan(rgx=jis_rgx)\n",
    "others_rgx = '((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)'\n",
    "others_matcher = RegexMatchSpan(rgx=others_rgx)\n",
    "parts_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "#NOTE: This is super specific.\n",
    "cb_v_matcher = RegexMatchSpan(rgx=r'\\-?[2-8][0]', longest_match_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# part_finder = re.compile(parts_rgx, re.I)\n",
    "# print any([part_finder.match(x) for x in ['blue', 'red', 'black', 'green']])\n",
    "# print any([part_finder.match(x) for x in ['blue', 'red', 'BC546A', 'green']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp, get_gold_dict\n",
    "\n",
    "# Make parts list\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    parts_by_doc[part[0]].add(part[1])\n",
    "    \n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=parts_by_doc, n_max=3)\n",
    "\n",
    "# TODO: This is missing the current represented as an Amp rather than a milliamp\n",
    "cb_v_ngrams = OmniNgramsTemp(n_max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Throttler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "\n",
    "def cbv_throttler((part_span, attr_span)):\n",
    "    \"\"\"\n",
    "    Keep only those candidates where both spans are on the same page and\n",
    "    either aligned in the same table (visually or structurally) or the part is global.\n",
    "    \"\"\"\n",
    "    return(\n",
    "        same_page((part_span, attr_span)) and\n",
    "        (part_span.parent.table is None or\n",
    "        (same_row((part_span, attr_span)) or is_horz_aligned((part_span, attr_span)))))\n",
    "#     \"\"\"\n",
    "#     Reject any candidates whose attributes are horizontally aligned with at least one \n",
    "#     part number and are not horizontally aligned with the candidate part number\n",
    "#     \"\"\"\n",
    "#     return not (any(part_finder.match(word) for word in get_horz_aligned_ngrams(attr_span)) and \n",
    "#         not is_horz_aligned((part_span, attr_span)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware Training)\n",
      "[========================================] 100%\n",
      "CPU times: user 55.6 s, sys: 607 ms, total: 56.3 s\n",
      "Wall time: 57 s\n",
      "Candidate Set (Hardware Training Candidates) contains 15898 Candidates\n",
      "Extracting Candidates from Corpus (Hardware Development)\n",
      "[========================================] 100%\n",
      "CPU times: user 17.1 s, sys: 114 ms, total: 17.2 s\n",
      "Wall time: 17.4 s\n",
      "Candidate Set (Hardware Development Candidates) contains 5812 Candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "\n",
    "ce = CandidateExtractor(Part_Voltage, \n",
    "                        [part_ngrams, cb_v_ngrams], \n",
    "                        [parts_matcher, cb_v_matcher],\n",
    "                        throttler=cbv_throttler)\n",
    "\n",
    "for corpus_name in ['Hardware Training', 'Hardware Development']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(\\\n",
    "        corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[========================================] 100%\n",
      "========================================\n",
      "Scoring on Entity-Level Total Recall\n",
      "========================================\n",
      "Entity-level Candidates extracted: 3311 \n",
      "Entity-level Gold: 752\n",
      "Intersection Candidates: 661\n",
      "----------------------------------------\n",
      "Overlap with Gold:  0.8790\n",
      "========================================\n",
      "\n",
      "661\n",
      "2650\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import entity_level_total_recall, most_common_document, get_gold_dict\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.models import Candidate, Corpus\n",
    "\n",
    "all_candidates = session.query(Candidate).all()\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "(tp, fp, fn) = entity_level_total_recall(\n",
    "    all_candidates, gold_file, 'cb_v_max', corpus=corpus, relation=True, integerize=True)\n",
    "print len(tp)\n",
    "print len(fp)\n",
    "print len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AUKCS04635-1', '2N3906', -40),\n",
      " ('DISES00490-1', 'BC846AW', 80),\n",
      " ('DISES00490-1', 'BC846BW', 80),\n",
      " ('DISES00490-1', 'BC847AW', 50),\n",
      " ('DISES00490-1', 'BC847BW', 50),\n",
      " ('DISES00490-1', 'BC847CW', 50),\n",
      " ('DISES00616-1', 'BC857', 50),\n",
      " ('DISES00616-1', 'BC857A', 50),\n",
      " ('DISES00616-1', 'BC857B', 50),\n",
      " ('DISES00616-1', 'BC857C', 50)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "fns = list(fn)\n",
    "pprint(sorted(fns)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "# for document in corpus.documents:\n",
    "# #     print document.name\n",
    "#     if document.name == 'MOTOS03160-1':\n",
    "#         doc = document\n",
    "# print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for c in all_candidates:\n",
    "#     if c.part.get_span()=='BC183' and c.part.parent.document.name=='MOTOS03160-1':\n",
    "#         print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for phrase in doc.phrases:\n",
    "#     if 'BC183' in phrase.words:\n",
    "#         print phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from snorkel.models import CandidateSet\n",
    "# from hardware_utils import load_hardware_labels\n",
    "\n",
    "# gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# for set_name in ['Training', 'Development']:\n",
    "#     candidate_set_name = 'Hardware %s Candidates' % set_name\n",
    "#     candidates = session.query(CandidateSet).filter(\n",
    "#         CandidateSet.name == candidate_set_name).one()\n",
    "#     label_set_name = 'Hardware %s Candidates -- Gold' % set_name\n",
    "#     annotation_key_name = 'Hardware %s Labels -- Gold' % set_name\n",
    "#     %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "#                            label_set_name, \\\n",
    "#                            annotation_key_name, \\\n",
    "#                            candidates, \\\n",
    "#                            gold_file, \\\n",
    "#                            attrib='cb_v_max')\n",
    "#     candidates_gold = session.query(CandidateSet).filter(\n",
    "#         CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "#     print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "#         len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ labels snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import CandidateSet\n",
    "# from snorkel.fast_annotations import FeatureManager\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "\n",
    "# train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "# dev   = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "# %time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ featurized');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.fast_annotations import LabelManager\n",
    "from snorkel.lf_helpers import *\n",
    "label_manager = LabelManager()\n",
    "\n",
    "LFs = []\n",
    "\n",
    "###################################################################\n",
    "# BOTH\n",
    "###################################################################\n",
    "\n",
    "# cb_words_individual = set(['collector', 'base', 'voltage'])\n",
    "# cb_words_together = set(['collector-base', 'voltage'])\n",
    "cb_words = set(['collector base', 'collector-base', 'collector - base'])\n",
    "def LF_cb_keywords_all(c):\n",
    "    return 1 if overlap(cb_words, get_row_ngrams(c.voltage, spread=[0,3], n_max=3)) else -1\n",
    "LFs.append(LF_cb_keywords_all)\n",
    "\n",
    "###################################################################\n",
    "# POSITIVE\n",
    "###################################################################\n",
    "    \n",
    "pos_keys = set(['cbo', 'vcbo']) # 'value', 'rating'\n",
    "def LF_pos_keywords_in_row(c):\n",
    "    return 1 if overlap(pos_keys, get_row_ngrams(c.voltage, spread=[0,3])) else 0\n",
    "LFs.append(LF_pos_keywords_in_row)\n",
    "\n",
    "def LF_pos_keywords_horz(c):\n",
    "    return 1 if overlap(pos_keys, get_horz_aligned_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_pos_keywords_horz)\n",
    "\n",
    "###################################################################\n",
    "# NEGATIVE\n",
    "###################################################################\n",
    "\n",
    "eeca_rgx = '([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)'\n",
    "jedec_rgx = '([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jis_rgx = '(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})'\n",
    "others_rgx = '((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)'\n",
    "parts_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "part_sniffer = re.compile(parts_rgx)\n",
    "def LF_cheating_with_another_part(c):\n",
    "    return -1 if (any(part_sniffer.match(x) for x in get_horz_aligned_ngrams(c.voltage)) and \n",
    "                     not is_horz_aligned(c)) else 0\n",
    "LFs.append(LF_cheating_with_another_part)\n",
    "\n",
    "# part_row_ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=2))\n",
    "# volt_row_ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=2))\n",
    "def LF_same_table_must_align(c):\n",
    "    return -1 if (same_table(c) and not is_horz_aligned(c)) else 0\n",
    "LFs.append(LF_same_table_must_align)\n",
    "\n",
    "# A good LF, but made obsolete by the throttling condition\n",
    "def LF_not_horz_aligned(c):\n",
    "    return -1 if (same_table(c) and not is_horz_aligned(c)) else 0\n",
    "LFs.append(LF_not_horz_aligned)\n",
    "\n",
    "def LF_voltage_not_in_table(c):\n",
    "    return -1 if c.voltage.parent.table is None else 0\n",
    "LFs.append(LF_voltage_not_in_table)\n",
    "\n",
    "def LF_low_table_num(c):\n",
    "    return -1 if (c.voltage.parent.table and\n",
    "        c.voltage.parent.table.position > 2) else 0\n",
    "LFs.append(LF_low_table_num)\n",
    "\n",
    "neg_keys = set(['continuous', 'emitter', 'cut-off', 'gain'])\n",
    "def LF_specific_neg_row_keywords(c):\n",
    "    return -1 if overlap(neg_keys, get_row_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_specific_neg_row_keywords)\n",
    "\n",
    "def LF_equals_in_row(c):\n",
    "    return -1 if overlap('=', get_row_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_equals_in_row)\n",
    "\n",
    "def LF_i_in_row(c):\n",
    "    return -1 if overlap('i', get_row_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_i_in_row)\n",
    "\n",
    "def LF_too_many_numbers_row(c):\n",
    "    num_numbers = list(get_row_ngrams(c.voltage, attrib=\"ner_tags\")).count('number')\n",
    "    return -1 if num_numbers >= 4 else 0\n",
    "LFs.append(LF_too_many_numbers_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold set size: 752\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus, CandidateSet, Candidate\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.utils import ProgressBar\n",
    "from hardware_utils import get_gold_dict, candidate_to_entity\n",
    "from pdb import set_trace as t\n",
    "\n",
    "# train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "# dev = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "# dev_corpus = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "candidates = session.query(Candidate).all()\n",
    "\n",
    "attribute = 'cb_v_max'\n",
    "docs = [(doc.name).upper() for doc in corpus.documents] if corpus else None\n",
    "gold_file = gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_set = get_gold_dict(gold_file, docs=docs, \n",
    "                         doc_on=True, part_on=True, val_on=True, \n",
    "                         attrib=attribute)\n",
    "print \"Gold set size: %d\" % len(gold_set)\n",
    "\n",
    "heuristic_LFs_pos = [LF_cb_keywords_all]\n",
    "heuristic_LFs_neg = [LF_cheating_with_another_part,\n",
    "                    LF_not_horz_aligned,\n",
    "                    LF_voltage_not_in_table,\n",
    "                    LF_same_table_must_align,\n",
    "                    LF_specific_neg_row_keywords,\n",
    "                    LF_equals_in_row,\n",
    "                    LF_i_in_row,\n",
    "                    LF_too_many_numbers_row]\n",
    "\n",
    "def heuristic(c): \n",
    "    for lf in heuristic_LFs_pos:\n",
    "        if lf(c) != 1:\n",
    "            return lf.__name__\n",
    "    for lf in heuristic_LFs_neg:\n",
    "        if lf(c) == -1:\n",
    "            return lf.__name__\n",
    "    return None\n",
    "\n",
    "tp = set()\n",
    "fp = set()\n",
    "tn = set()\n",
    "fn = set()\n",
    "tpe = set()\n",
    "fpe = set()\n",
    "tne = set()\n",
    "fne = set()\n",
    "\n",
    "pb = ProgressBar(len(candidates))\n",
    "for i, c in enumerate(candidates):\n",
    "#     pb.bar(i)\n",
    "    entity = candidate_to_entity(c)\n",
    "    failed = heuristic(c)\n",
    "    if failed:\n",
    "        if entity in gold_set:\n",
    "            fn.add(c)\n",
    "            fne.add(entity)\n",
    "        else:\n",
    "            tn.add(c)\n",
    "            tne.add(entity)            \n",
    "    else:\n",
    "        if entity in gold_set:\n",
    "            tp.add(c)\n",
    "            tpe.add(entity)            \n",
    "        else:\n",
    "            fp.add(c)\n",
    "            fpe.add(entity)\n",
    "\n",
    "# pb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21710 21710\n",
      "[478, 2622, 80, 183]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "fne = fne - tpe\n",
    "print len(candidates), sum(map(len, [tp, tn, fp, fn]))\n",
    "print map(len, [tpe, tne, fpe, fne])\n",
    "# pprint(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "%time L_train.lf_stats(train_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.fast_annotations import FeatureManager, LabelManager\n",
    "from snorkel.models import CandidateSet\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "label_manager = LabelManager()\n",
    "%time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=100000, rate=1e-6)\n",
    "%time gen_model.save(session, 'Generative Params')\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-4)\n",
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "\n",
    "dev_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates -- Gold').one()\n",
    "\n",
    "from snorkel.models import CandidateSet\n",
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_dev = label_manager.load(session, dev, 'Hardware Development Labels -- Gold')\n",
    "\n",
    "tp, fp, tn, fn = disc_model.score(F_dev, L_dev, dev_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.857\n",
      "Corpus Recall    0.636\n",
      "Corpus F1        0.73\n",
      "----------------------------------------\n",
      "TP: 478 | FP: 80 | FN: 274\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "dev_corpus = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# NOTE: this is checking on all corpus, not just dev corpus\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware').one()\n",
    "(TP, FP, FN) = entity_level_f1(tp, fp, tn, fn, gold_file, corpus, 'cb_v_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "FN_list = sorted(list(FN))\n",
    "FP_list = sorted(list(FP))\n",
    "TP_list = sorted(list(TP))\n",
    "# pprint(FN_list[:])\n",
    "pprint(FN_list[:10])\n",
    "# pprint(TP_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# docs = set()\n",
    "# for doc in corpus.documents:\n",
    "#     docs.add(doc.name.upper())\n",
    "# pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# docs = set()\n",
    "# for f in itertools.chain.from_iterable([tp, tn, fp, fn]):\n",
    "#     docs.add(f.part.parent.document.name.upper())\n",
    "# #     if f.part.parent.document.name.upper() == 'AUKCS04635-1':\n",
    "# #         print f\n",
    "# pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import entity_to_candidates, part_error_analysis\n",
    "\n",
    "# disc_model.get_feature_weights(F_dev)\n",
    "\n",
    "entity = FN_list[0]\n",
    "matches = entity_to_candidates(entity, dev)\n",
    "print \"Entity: (%d matches)\" % len(matches)\n",
    "print entity\n",
    "\n",
    "stop = False\n",
    "for i, c in enumerate(matches):\n",
    "    part_error_analysis(c)\n",
    "    results = []\n",
    "    for lf in LFs:\n",
    "        name = lf.__name__\n",
    "        result = lf(c)\n",
    "        results.append((name, result))\n",
    "#         if name == 'LF_cb_keywords_all' and result == -1:\n",
    "#             print name\n",
    "#             ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=3))\n",
    "#             print ngrams\n",
    "#             print overlap(ngrams, cb_words)\n",
    "#             stop = False\n",
    "#         if name == 'LF_cheating_with_another_part' and result == -1:\n",
    "#             print name\n",
    "#             horz_ngrams = list(get_horz_aligned_ngrams(c))\n",
    "#             print horz_ngrams\n",
    "#             print [part_sniffer.match(x) for x in horz_ngrams]\n",
    "#             stop = False\n",
    "        if name == 'LF_i_in_row' and result == -1:\n",
    "            print name\n",
    "            ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=3))\n",
    "            print ngrams\n",
    "            stop = False\n",
    "        if stop: break\n",
    "    print \"MATCH %d:\" % i\n",
    "    print heuristic(c)\n",
    "    pprint(results)\n",
    "    print \"--------------------------------------------------------------------------------\"\n",
    "    if stop: break\n",
    "    \n",
    "#     if heuristic(candidate):\n",
    "#         print \"\\nCandidate:\"\n",
    "# #         print candidate\n",
    "#         print part_error_analysis(candidate)\n",
    "#     print heuristic(candidate)\n",
    "#     print LF_voltage_not_in_table(candidate)\n",
    "#         print candidate.voltage.parent.table\n",
    "#     print \"\\nScore:\"\n",
    "#     print disc_model.get_candidate_score(candidate, F_dev)\n",
    "\n",
    "#     print \"\\nFeatures:\"\n",
    "#     pprint(disc_model.get_candidate_feature_weights(candidate, F_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate[0].parent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate[0].get_span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for lf in LFs:\n",
    "    results.append(lf.__name__, lf(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print F_train.shape\n",
    "print F_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ final');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def LF_first_row(c):\n",
    "#     if c.voltage.parent.row_num == 0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "# LFs.append(LF_first_row)\n",
    "    \n",
    "# def LF_not_ce_relevant(c):\n",
    "#     ce_keywords = set(['collector', 'emitter', 'collector-emitter'])\n",
    "#     ngrams = set(get_aligned_ngrams(c.voltage))\n",
    "#     if not set_any_in_set(ce_keywords, ngrams):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 1\n",
    "# LFs.append(LF_not_ce_relevant)\n",
    "\n",
    "# def LF_negative_keywords(c):\n",
    "#     row_neg_keys = set(['ambient',\n",
    "#                     'small-signal',\n",
    "#                     'cut-off',\n",
    "#                     'na',\n",
    "#                     'ma',\n",
    "#                     'cex',\n",
    "#                     'resistance',\n",
    "#                     'power',\n",
    "#                     'junction',\n",
    "#                     'dissipation', \n",
    "#                     'breakdown',\n",
    "#                     'current',\n",
    "#                     'ceo',\n",
    "#                     'vceo'\n",
    "#                     'peak',\n",
    "#                     '=',\n",
    "#                     'f',\n",
    "#                     'p',\n",
    "#                     'base',\n",
    "#                     'mw',\n",
    "#                     'ebo',\n",
    "#                     'vebo',\n",
    "#                     'i c',\n",
    "#                     'total',\n",
    "#                     'device',\n",
    "#                     'c',\n",
    "#                     'mhz',\n",
    "#                     'temperature',\n",
    "#                     'saturation',\n",
    "#                     'operating',\n",
    "#                     'storage'\n",
    "#                     'bandwidth',\n",
    "#                     'derate',\n",
    "#                     'above',\n",
    "#                     'product',\n",
    "#                     'figure',\n",
    "#                     'conditions',\n",
    "#                     'current gain',\n",
    "#                     'saturation',\n",
    "#                     'min',\n",
    "#                     'min.',\n",
    "#                     'typ',\n",
    "#                     'typ.',\n",
    "#                     'max',\n",
    "#                     'max.',\n",
    "#                     'gain',\n",
    "#                     'p',\n",
    "#                     'thermal',\n",
    "#                     'test'])\n",
    "#     row_ngrams = set(get_row_ngrams(c.voltage))\n",
    "#     col_ngrams = set(get_col_ngrams(c.voltage))\n",
    "#     col_neg_keys = set(['conditions', \n",
    "#                         'condition', \n",
    "#                         'parameter', \n",
    "#                         'min',\n",
    "#                         'min.',\n",
    "#                         'typ',\n",
    "#                         'typ.',\n",
    "#                         'max',\n",
    "#                         'max.',\n",
    "#                         'test'])\n",
    "#     if set_any_in_set(row_neg_keys, row_ngrams):\n",
    "#         return -1\n",
    "#     if set_any_in_set(col_neg_keys, col_ngrams):\n",
    "#         return -1\n",
    "#     return 0\n",
    "# LFs.append(LF_negative_keywords)\n",
    "    \n",
    "# def LF_negative_keywords_in_col(c):\n",
    "#     neg_keys = set(['conditions',\n",
    "#                     'condition',\n",
    "#                     'parameter',\n",
    "#                     'test'])\n",
    "#     ngrams = set(get_col_ngrams(c.voltage))\n",
    "#     if set_any_in_set(neg_keys, ngrams):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# LFs.append(LF_negative_keywords_in_col)\n",
    "\n",
    "# def LF_negative_keywords_in_part_aligned(c):\n",
    "#     ngrams = set(get_aligned_ngrams(c.part))\n",
    "#     return -1 if (\n",
    "#         'gain'          in ngrams or\n",
    "#         'small-signal'  in ngrams or\n",
    "#         'small'         in ngrams or\n",
    "#         'cbo'         in ngrams or\n",
    "#         'collector-emitter' in ngrams or\n",
    "#         'value'         in ngrams or\n",
    "#         'thermal'       in ngrams) else 0\n",
    "# LFs.append(LF_negative_keywords_in_part_aligned)\n",
    "\n",
    "# def LF_negative_keywords(c):\n",
    "#     ngrams = set(get_aligned_ngrams(c.voltage))\n",
    "#     return -1 if (\n",
    "#         'collector-base'    in ngrams or\n",
    "#         'cut-off'           in ngrams or\n",
    "#         '='                 in ngrams or\n",
    "#         'gain'              in ngrams or\n",
    "#         'h fe'              in ngrams or\n",
    "#         'typ.'              in ngrams or\n",
    "#         'typ'               in ngrams or\n",
    "#         'min'               in ngrams or\n",
    "#         'min.'              in ngrams or\n",
    "#         'saturation'        in ngrams or\n",
    "#         'mhz'               in ngrams or\n",
    "#         'gain'              in ngrams or\n",
    "#         'obo'               in ngrams or\n",
    "#         'c obo'             in ngrams) else 0\n",
    "# LFs.append(LF_negative_keywords)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
