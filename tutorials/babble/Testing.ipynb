{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOMAIN = 'test'\n",
    "# DOMAIN = 'cdr'\n",
    "DOMAIN = 'spouse'\n",
    "# DOMAIN = 'bike'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "db = {\n",
    "    'test':   'postgres://localhost:5432/babble_test_unittest',\n",
    "    'spouse': 'postgres://localhost:5432/babble_test_spouse',\n",
    "    'cdr':    'postgres://localhost:5432/babble_test_cdr',\n",
    "    'bike':   'postgres://localhost:5432/babble_test_bike',\n",
    "}\n",
    "\n",
    "os.environ['SNORKELDB'] = db[DOMAIN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: spouse\n",
      "Explanations: 9\n",
      "Candidates: 0\n",
      "CPU times: user 1.38 s, sys: 187 ms, total: 1.57 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "    \n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.contrib.babble import link_explanation_candidates\n",
    "\n",
    "# Extract domain-specific explanations and user_lists\n",
    "if DOMAIN == 'test':\n",
    "    sys.path.append(os.path.join(os.environ['SNORKELHOME'], 'test/babble/'))\n",
    "    import unittest_examples\n",
    "    user_lists = unittest_examples.get_user_lists()\n",
    "    explanations = unittest_examples.explanations\n",
    "    Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "    candidate_class = Spouse\n",
    "    mode = 'text'\n",
    "elif DOMAIN == 'spouse':\n",
    "    sys.path.append(os.path.join(os.environ['SNORKELHOME'], 'tutorials/babble/spouse/'))\n",
    "    import spouse_examples\n",
    "    user_lists = spouse_examples.get_user_lists()\n",
    "    explanations = spouse_examples.explanations\n",
    "    Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "    candidate_class = Spouse \n",
    "    mode = 'text'\n",
    "elif DOMAIN == 'cdr':\n",
    "    import cdr_examples\n",
    "    user_lists = cdr_examples.get_user_lists()\n",
    "    explanations = cdr_examples.explanations\n",
    "    ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "    candidate_class = ChemicalDisease\n",
    "    mode = 'text'\n",
    "elif DOMAIN == 'bike':\n",
    "    user_lists = {}\n",
    "    Biker = candidate_subclass('Biker', ['person', 'bike'])\n",
    "    explanations = [] # FIXME\n",
    "    candidate_class = Biker  \n",
    "    mode = 'image'\n",
    "else:\n",
    "    raise Exception(\"Invalid domain: {}\".format(DOMAIN))\n",
    "    \n",
    "candidates = session.query(candidate_class).all()\n",
    "print(\"Domain: {}\".format(DOMAIN))\n",
    "print(\"Explanations: {}\".format(len(explanations)))\n",
    "print(\"Candidates: {}\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 445 explanations from /Users/bradenjh/repo...ata/mturk_explanations_all.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from snorkel.contrib.babble import ExplanationIO\n",
    "\n",
    "fpath = os.environ['SNORKELHOME'] + '/tutorials/babble/spouse/data/mturk_explanations_all.tsv'\n",
    "\n",
    "expio = ExplanationIO()\n",
    "explanations = list(expio.read(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 155 unique target candidate ids from 445 explanations.\n",
      "Gathering desired candidates...\n",
      "Could not find 155 target candidates with the following stable_ids (first 5):\n",
      "(0, '6807fb8a-333f-41fd-bf8b-4b47681a5a08::span:2270:2281~~6807fb8a-333f-41fd-bf8b-4b47681a5a08::span:2370:2378')\n",
      "(1, 'd925621f-5004-4a55-8122-f5da4865a483::span:3757:3762~~d925621f-5004-4a55-8122-f5da4865a483::span:3820:3828')\n",
      "(2, '3494f8e0-ecd4-4f10-86db-95b920744162::span:18:33~~3494f8e0-ecd4-4f10-86db-95b920744162::span:120:125')\n",
      "(3, '292069d7-ba8e-43da-b3c2-81488b552239::span:4807:4819~~292069d7-ba8e-43da-b3c2-81488b552239::span:4909:4914')\n",
      "(4, 'bf3a5294-6ccf-4649-a3f3-b9a6cd0aa5f1::span:1829:1831~~bf3a5294-6ccf-4649-a3f3-b9a6cd0aa5f1::span:1837:1841')\n",
      "Found 0/155 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 0/445 explanations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "explanations = link_explanation_candidates(explanations, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_iterator = iter(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politicians\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'char_start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92f7b3eed73b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceNgramViewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceNgramViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_per_page\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/viewer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, candidates, session, gold, n_per_page, height, annotator_name)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m\"\"\"Viewer for Sentence objects and candidate Spans within them\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_per_page\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentenceNgramViewer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_per_page\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_per_page\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_subspan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/viewer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, candidates, session, gold, n_per_page, height, annotator_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# We get the sorted candidates and all contexts required, either from unary or binary candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontexts\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenjh/repos/snorkel/snorkel/viewer.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# We get the sorted candidates and all contexts required, either from unary or binary candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontexts\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'char_start'"
     ]
    }
   ],
   "source": [
    "exp = exp_iterator.next()\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "print(exp.condition)\n",
    "sv = SentenceNgramViewer([exp.candidate], session, n_per_page=3, height=150)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "explanations = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Bbox\n",
    "# A = Bbox(top=100, bottom=200, left=100, right=200)\n",
    "# B = Bbox(top=150, bottom=250, left=150, right=250)\n",
    "# a_and_b = (A, B)\n",
    "# explanations = [\n",
    "#     Explanation(\n",
    "#         condition=\"box x is near the top left corner of box y\",\n",
    "#         label=True,\n",
    "#         candidate=a_and_b,\n",
    "#         semantics=('.root', ('.label', ('.bool', True), ('.call', ('.near', ('.box', ('.int', 1))), ('.box', ('.int', 0)))))),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import Babbler\n",
    "babbler = Babbler(mode=mode, candidate_class=candidate_class, \n",
    "                  explanations=explanations, user_lists=user_lists, top_k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lfs = babbler.generate_lfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(semantics=True, translate=True)\n",
    "parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explanations = babbler.get_explanations()\n",
    "explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "babbler.semparser.grammar.print_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def LF_wife_in_sentence(c):\n",
    "#     \"\"\"A simple example of a labeling function\"\"\"\n",
    "#     return 1 if 'wife' in c.get_parent().words else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.lf_helpers import test_LF\n",
    "# %time tp, fp, tn, fn = test_LF(session, LF_wife_in_sentence, split=0, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babbler.filter_duplicate_semantics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babbler.filter_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import sem_to_str\n",
    "[sem_to_str(p.semantics) for p in babbler.parses[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_dev = babbler.generate_label_matrix(split=1)\n",
    "# L_dev = babbler.load_matrix(session,split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "babbler.filter_uniform_signatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "babbler.filter_duplicate_signatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_dev.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum(L_dev, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caught = set(L_dev[:,1].nonzero()[0])\n",
    "for i in range(2811):\n",
    "    if i not in caught:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from snorkel.contrib.babble.text import get_sentence_phrases\n",
    "pprint([p.words for p in get_sentence_phrases(L_dev.get_candidate(session, 843)[0],n_max=7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev_candidates = session.query(candidate_class).filter(Spouse.split == 1).all()\n",
    "print(len(dev_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import utils\n",
    "\n",
    "# # Link examples with their corresponding candidates\n",
    "# examples = utils.link_example_candidates(examples, dev_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spouse_label_path = os.path.join(os.environ['SNORKELHOME'], 'tutorials/intro/data/gold_labels.tsv') \n",
    "\n",
    "import intro\n",
    "\n",
    "%time intro.load_external_labels(session, Spouse, annotator_name='gold', path=spouse_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import bz2\n",
    "# import os \n",
    "\n",
    "# spouses_pickle_path = os.path.join(os.environ['SNORKELHOME'], \n",
    "#         'tutorials/intro/data/spouses_dbpedia.csv.bz2') \n",
    "\n",
    "# def strip_special(s):\n",
    "#     return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# def last_name(s):\n",
    "#     name_parts = s.split(' ')\n",
    "#     return name_parts[-1] if len(name_parts) > 1 else None  \n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File(spouses_pickle_path, 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "\n",
    "# def LF_distant_supervision(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     return 1 if (p1, p2) in known_spouses or (p2, p1) in known_spouses else 0\n",
    "\n",
    "# def LF_distant_supervision_last_names(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     p1n, p2n = last_name(p1), last_name(p2)\n",
    "#     return 1 if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# candidate_subset = []\n",
    "# for c in dev_candidates:\n",
    "#     if hash(c) == -2597662937532403956:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "sv = SentenceNgramViewer(dev_candidates[:300], session)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "married = ['husband', 'wife', 'spouse', 'marriage', 'married']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_neighbors(c):\n",
    "    return -1 if (len(c[0].get_attrib_tokens()) == 1 and \n",
    "                  len(c[1].get_attrib_tokens()) == 1 and \n",
    "                  not set(married).intersection(c.get_parent().words)) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled = []\n",
    "for c in session.query(Spouse).filter(Spouse.split == 1).all():\n",
    "    if LF_neighbors(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "sv = SentenceNgramViewer(fn, session)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(dev_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "test_labels     = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.models import Candidate\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "import numpy as np\n",
    "\n",
    "lf = LF_neighbors\n",
    "\n",
    "dev_candidates = session.query(Candidate).filter(Candidate.split == 1).all()\n",
    "test_labels     = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "scorer          = MentionScorer(dev_candidates, test_labels)\n",
    "test_marginals  = np.array([0.5 * (lf(c) + 1) for c in dev_candidates])\n",
    "scorer.score(test_marginals, set_unlabeled_as_neg=False, set_at_thresh_as_neg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(test_candidates))\n",
    "print(test_labels.nnz)\n",
    "max(test_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import Explanation\n",
    "\n",
    "explanations = [\n",
    "    # Tuple\n",
    "    Explanation(\n",
    "        condition=\"label True because the pair (arg 1, arg 2) is the same as the tuple ('foo', 'bar')\",\n",
    "        candidate=('foo', 'bar'),\n",
    "        label=1,\n",
    "        semantics=('.root', ('.label', ('.bool', True), ('.call', ('.eq', ('.tuple', ('.list', ('.string', u'foo'), ('.string', u'bar')))), ('.tuple', ('.list', ('.arg_to_string', ('.arg', ('.int', 1))), ('.arg_to_string', ('.arg', ('.int', 2))))))))),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.babble import SemanticParser\n",
    "\n",
    "%time sp = SemanticParser(candidate_class, user_lists, beam_width=10, top_k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time LFs = sp.parse_and_evaluate(explanations,\\\n",
    "                                  show_everything=True,\\\n",
    "                                  show_nothing=False,\\\n",
    "                                  show_explanation=True,\\\n",
    "                                  show_candidate=False,\\\n",
    "                                  show_sentence=False,\\\n",
    "                                  show_parse=True,\\\n",
    "                                  show_semantics=True,\\\n",
    "                                  show_correct=False,\\\n",
    "                                  show_passing=True,\\\n",
    "                                  show_failing=True,\\\n",
    "                                  pseudo_python=True,\\\n",
    "                                  remove_paren=False,\\\n",
    "                                  paraphrases=False,\\\n",
    "                                  only=[])\n",
    "sp.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print np.sum(sp.results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp.grammar.print_chart(nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sp.grammar.print_grammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Make mini-corpus for test\n",
    "\n",
    "# import os\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import Document, candidate_subclass\n",
    "# from snorkel.parser import TSVDocPreprocessor, CorpusParser\n",
    "# from snorkel.parser.spacy_parser import Spacy\n",
    "# from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "# from snorkel.matchers import PersonMatcher\n",
    "# from snorkel.contrib.babble import SemanticParser, Example\n",
    "\n",
    "# test_article_path = os.environ['SNORKELHOME'] + '/test/babble/test_article.tsv'\n",
    "# doc_preprocessor = TSVDocPreprocessor(test_article_path)\n",
    "# corpus_parser = CorpusParser(parser=Spacy())\n",
    "# corpus_parser.apply(doc_preprocessor)\n",
    "# Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "# ngrams         = Ngrams(n_max=2)\n",
    "# person_matcher = PersonMatcher(longest_match_only=True)\n",
    "# cand_extractor = CandidateExtractor(Spouse, [ngrams, ngrams], [person_matcher, person_matcher], symmetric_relations=False)\n",
    "# docs = session.query(Document).order_by(Document.name).all()\n",
    "# sents = [s for doc in docs for s in doc.sentences]\n",
    "# cand_extractor.apply(sents, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# candidates = session.query(Spouse).all()\n",
    "# for c in candidates:\n",
    "#     print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
