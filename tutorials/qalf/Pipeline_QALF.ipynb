{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'qalf',\n",
    "    'domain': 'tacred',\n",
    "    'relation': 'org_top_members_employees',\n",
    "    'splits': [0, 1],\n",
    "    'supervision': 'traditional',\n",
    "#     'max_train': 500,\n",
    "#     'max_lfs': 1,\n",
    "#     'learn_deps': True,\n",
    "#     'gen_model_search_space': 1,\n",
    "#     'gen_init_params': {\n",
    "#         'lf_propensity'         : True,\n",
    "#         'class_prior'           : True,\n",
    "#         'lf_class_propensity'   : True,\n",
    "#         'seed'                  : None,\n",
    "#     },\n",
    "#     'gen_params_default': {\n",
    "#         'step_size'     : 0.0001,\n",
    "#         'decay'         : 0.90,\n",
    "#         'reg_param'     : 0.50,\n",
    "#         'epochs'        : 25,\n",
    "#     },    \n",
    "    'disc_model_class': 'logreg',    \n",
    "    'disc_model_search_space': 1,\n",
    "    'disc_params_default': {\n",
    "        'lr'        : 1e-4,\n",
    "        'n_epochs'  : 50,\n",
    "        'l1_penalty': 1e-3,\n",
    "        'l2_penalty': 1e-3,\n",
    "    }\n",
    "#     'disc_params_range': {\n",
    "#         'lr'        : [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "#         'l1_penalty': [1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4],\n",
    "#         'l2_penalty': [1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4],\n",
    "#     },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///qalf_tacred_org_top_members_employees.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = (config['project'] + '_' + config['domain'] + \n",
    "                   ('_' + config['relation'] if config['relation'] else '') +\n",
    "                   ('_debug' if config.get('debug', False) else ''))\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting l2_penalty=0 to l2_penalty=0.001\n",
      "Overwriting lr=0.01 to lr=0.0001\n",
      "Overwriting l1_penalty=0 to l1_penalty=0.001\n",
      "Overwriting n_epochs=25 to n_epochs=50\n",
      "Overwriting domain=None to domain=tacred\n",
      "Overwriting batch_size=128 to batch_size=64\n",
      "Overwriting n_epochs=20 to n_epochs=50\n",
      "Overwriting lr=0.01 to lr=0.0001\n",
      "Overwriting l2_penalty=1.0 to l2_penalty=0.001\n",
      "Overwriting l1_penalty=1.0 to l1_penalty=0.001\n",
      "Overwriting disc_model_search_space=10 to disc_model_search_space=1\n",
      "Overwriting splits=[0, 1, 2] to splits=[0]\n",
      "Overwriting max_train=None to max_train=2000\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting supervision=generative to supervision=traditional\n",
      "Overwriting project=babble to project=qalf\n",
      "Overwriting splits=[0, 1, 2] to splits=[0, 1]\n",
      "Using TacredQalfPipeline object.\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'], config['project'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: 7824 Candidates\n",
      "Split 1: 2039 Candidates\n",
      "Split 2: 0 Candidates\n"
     ]
    }
   ],
   "source": [
    "for split in [0,1,2]:\n",
    "    num_cands = pipe.session.query(pipe.candidate_class).filter(\n",
    "        pipe.candidate_class.split == split).count()\n",
    "    print(\"Split {}: {} Candidates\".format(split, num_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "# L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "# L_gold_train\n",
    "# pipe.L_train.lf_stats(session, labels=L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels\n",
    "# L_gold_dev   = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# L_gold_dev\n",
    "# pipe.L_dev.lf_stats(session, labels=L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...grabbing candidate and gold label subsets.\n",
      "NOTE: traditional supervision helper assumes all candidates have labels.\n",
      "No value found for max_train. Using all available gold labels.\n",
      "Using 7824 traditional gold labels\n",
      "(7824,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1097abf90>"
      ]
    },
    {
      "[SparseLogisticRegression] n_train=7824  #epochs=50  batch size=64\n",
      "[SparseLogi...] Epoch 0 (0.35s) \tTrain Loss=1.110\tDev Loss=1.108\tDev F1=19.92\n",
      "[SparseLogi...] Epoch 1 (0.80s) \tTrain Loss=1.068\tDev Loss=1.076\tDev F1=15.57\n",
      "[SparseLogi...] Epoch 2 (1.23s) \tTrain Loss=1.036\tDev Loss=1.051\tDev F1=11.19\n",
      "[SparseLogi...] Epoch 3 (1.65s) \tTrain Loss=1.012\tDev Loss=1.032\tDev F1=4.47\n",
      "[SparseLogi...] Epoch 4 (2.09s) \tTrain Loss=0.993\tDev Loss=1.017\tDev F1=3.04\n",
      "[SparseLogi...] Epoch 5 (2.53s) \tTrain Loss=0.978\tDev Loss=1.004\tDev F1=1.85\n",
      "[SparseLogi...] Epoch 6 (3.08s) \tTrain Loss=0.965\tDev Loss=0.993\tDev F1=1.85\n",
      "[SparseLogi...] Epoch 7 (3.54s) \tTrain Loss=0.955\tDev Loss=0.985\tDev F1=1.85\n",
      "[SparseLogi...] Epoch 8 (4.04s) \tTrain Loss=0.947\tDev Loss=0.977\tDev F1=2.17\n",
      "[SparseLogi...] Epoch 9 (4.46s) \tTrain Loss=0.939\tDev Loss=0.971\tDev F1=3.69\n",
      "[SparseLogi...] Epoch 10 (4.92s) \tTrain Loss=0.931\tDev Loss=0.965\tDev F1=5.18\n",
      "[SparseLogi...] Epoch 11 (5.36s) \tTrain Loss=0.926\tDev Loss=0.960\tDev F1=12.61\n",
      "[SparseLogi...] Epoch 12 (5.80s) \tTrain Loss=0.922\tDev Loss=0.956\tDev F1=37.88\n",
      "[SparseLogi...] Epoch 13 (6.31s) \tTrain Loss=0.917\tDev Loss=0.953\tDev F1=41.86\n",
      "[SparseLogi...] Epoch 14 (6.74s) \tTrain Loss=0.913\tDev Loss=0.950\tDev F1=56.94\n",
      "[SparseLogi...] Epoch 15 (7.19s) \tTrain Loss=0.911\tDev Loss=0.947\tDev F1=59.59\n",
      "[SparseLogi...] Epoch 16 (7.64s) \tTrain Loss=0.907\tDev Loss=0.946\tDev F1=61.38\n",
      "[SparseLogi...] Epoch 17 (8.10s) \tTrain Loss=0.904\tDev Loss=0.944\tDev F1=61.87\n",
      "[SparseLogi...] Epoch 18 (8.68s) \tTrain Loss=0.902\tDev Loss=0.942\tDev F1=62.44\n",
      "[SparseLogi...] Epoch 19 (9.10s) \tTrain Loss=0.900\tDev Loss=0.942\tDev F1=62.89\n",
      "[SparseLogi...] Epoch 20 (9.52s) \tTrain Loss=0.899\tDev Loss=0.941\tDev F1=63.55\n",
      "[SparseLogi...] Epoch 21 (9.92s) \tTrain Loss=0.897\tDev Loss=0.940\tDev F1=63.62\n",
      "[SparseLogi...] Epoch 22 (10.36s) \tTrain Loss=0.896\tDev Loss=0.940\tDev F1=63.69\n",
      "[SparseLogi...] Epoch 23 (10.82s) \tTrain Loss=0.895\tDev Loss=0.940\tDev F1=63.69\n",
      "[SparseLogi...] Epoch 24 (11.27s) \tTrain Loss=0.894\tDev Loss=0.941\tDev F1=63.69\n",
      "[SparseLogi...] Epoch 25 (11.72s) \tTrain Loss=0.893\tDev Loss=0.941\tDev F1=63.35\n",
      "[SparseLogi...] Epoch 26 (12.16s) \tTrain Loss=0.893\tDev Loss=0.942\tDev F1=63.29\n",
      "[SparseLogi...] Epoch 27 (12.61s) \tTrain Loss=0.894\tDev Loss=0.942\tDev F1=63.48\n",
      "[SparseLogi...] Epoch 28 (13.07s) \tTrain Loss=0.894\tDev Loss=0.943\tDev F1=63.48\n",
      "[SparseLogi...] Epoch 29 (13.50s) \tTrain Loss=0.894\tDev Loss=0.944\tDev F1=63.42\n",
      "[SparseLogi...] Epoch 30 (14.05s) \tTrain Loss=0.893\tDev Loss=0.945\tDev F1=63.04\n",
      "[SparseLogi...] Epoch 31 (14.48s) \tTrain Loss=0.893\tDev Loss=0.947\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 32 (14.90s) \tTrain Loss=0.896\tDev Loss=0.948\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 33 (15.32s) \tTrain Loss=0.896\tDev Loss=0.949\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 34 (15.77s) \tTrain Loss=0.895\tDev Loss=0.951\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 35 (16.20s) \tTrain Loss=0.896\tDev Loss=0.953\tDev F1=63.00\n",
      "[SparseLogi...] Epoch 36 (16.63s) \tTrain Loss=0.897\tDev Loss=0.954\tDev F1=63.06\n",
      "[SparseLogi...] Epoch 37 (17.07s) \tTrain Loss=0.899\tDev Loss=0.956\tDev F1=63.05\n",
      "[SparseLogi...] Epoch 38 (17.51s) \tTrain Loss=0.900\tDev Loss=0.958\tDev F1=63.18\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogi...] Epoch 39 (18.37s) \tTrain Loss=0.903\tDev Loss=0.960\tDev F1=63.18\n",
      "[SparseLogi...] Epoch 40 (18.80s) \tTrain Loss=0.902\tDev Loss=0.962\tDev F1=63.12\n",
      "[SparseLogi...] Epoch 41 (19.21s) \tTrain Loss=0.903\tDev Loss=0.965\tDev F1=63.36\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogi...] Epoch 42 (19.96s) \tTrain Loss=0.905\tDev Loss=0.967\tDev F1=63.14\n",
      "[SparseLogi...] Epoch 43 (20.49s) \tTrain Loss=0.907\tDev Loss=0.969\tDev F1=63.14\n",
      "[SparseLogi...] Epoch 44 (20.90s) \tTrain Loss=0.910\tDev Loss=0.972\tDev F1=63.44\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogi...] Epoch 45 (21.69s) \tTrain Loss=0.912\tDev Loss=0.974\tDev F1=63.44\n",
      "[SparseLogi...] Epoch 46 (22.10s) \tTrain Loss=0.912\tDev Loss=0.977\tDev F1=63.44\n",
      "[SparseLogi...] Epoch 47 (22.51s) \tTrain Loss=0.913\tDev Loss=0.979\tDev F1=63.44\n",
      "[SparseLogi...] Epoch 48 (22.92s) \tTrain Loss=0.916\tDev Loss=0.982\tDev F1=63.33\n",
      "[SparseLogi...] Epoch 49 (23.44s) \tTrain Loss=0.920\tDev Loss=0.985\tDev F1=63.33\n",
      "[SparseLogisticRegression] Training done (23.54s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Model saved as <discriminative_tacred>\n",
      "### Done in 24.4s.\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [F1 Score, Precision, Recall]\n",
      "Index: []\n",
      "CPU times: user 35 s, sys: 6.15 s, total: 41.1 s\n",
      "Wall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "# pipe.L_dev.lf_stats(session, labels=L_gold_dev)\n",
    "# L_test.lf_stats(session, labels=L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Sentence\n",
    "# s = pipe.session.query(Sentence).first()\n",
    "# s.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from spacy.lemmatizer import Lemmatizer\n",
    "# from spacy.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "# lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "# lemmas = lemmatizer(u'ducks', u'NOUN')\n",
    "# print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from spacy.lemmatizer import Lemmatizer\n",
    "# lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
