{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STG_TEMP_MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.parser import CorpusParser, HTMLParser, OmniParser\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.queries import split_corpus\n",
    "\n",
    "docs_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_html/'\n",
    "doc_parser = HTMLParser(path=docs_path)\n",
    "context_parser = OmniParser()\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time corpus = cp.parse_corpus(name='Hardware', session=session)\n",
    "\n",
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Corpus\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "split_corpus(session, corpus, train=0.8, development=0.2, test=0, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)')\n",
    "jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)')\n",
    "jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)')\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "temp_matcher = RegexMatchSpan(rgx=r'1[4-6]0', longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp, get_gold_dict\n",
    "\n",
    "# Make parts list\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    parts_by_doc[part[0]].add(part[1])\n",
    "    \n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=parts_by_doc, n_max=3)\n",
    "temp_ngrams = OmniNgramsTemp(n_max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware Training)\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 2min 26s, sys: 1.63 s, total: 2min 27s\n",
      "Wall time: 2min 30s\n",
      "Candidate Set (Hardware Training Candidates) contains 102518 Candidates\n",
      "Extracting Candidates from Corpus (Hardware Development)\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 21.2 s, sys: 197 ms, total: 21.4 s\n",
      "Wall time: 21.7 s\n",
      "Candidate Set (Hardware Development Candidates) contains 10226 Candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "ce = CandidateExtractor(Part_Temp, [part_ngrams, temp_ngrams], [parts_matcher, temp_matcher])\n",
    "\n",
    "for corpus_name in ['Hardware Training', 'Hardware Development']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(\\\n",
    "        corpus.documents, corpus_name + ' Candidates', session, ignore_different_tables=True)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from hardware_utils import entity_level_total_recall\n",
    "\n",
    "all_candidates = session.query(CandidateSet).all()[0]\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "(tp, fp, fn) = entity_level_total_recall(\n",
    "    all_candidates, gold_file, 'stg_temp_max', relation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(tp)\n",
    "print len(fp)\n",
    "print len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.models import CandidateSet\n",
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "for set_name in ['Training', 'Development']:\n",
    "    candidate_set_name = 'Hardware %s Candidates' % set_name\n",
    "    candidates = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name).one()\n",
    "    label_set_name = 'Hardware %s Candidates -- Gold' % set_name\n",
    "    annotation_key_name = 'Hardware %s Labels -- Gold' % set_name\n",
    "    %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "                           label_set_name, \\\n",
    "                           annotation_key_name, \\\n",
    "                           candidates, \\\n",
    "                           gold_file, \\\n",
    "                           gold_attrib='stg_temp_min')\n",
    "    candidates_gold = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "    print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "        len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ labels snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.annotations import FeatureManager\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ featurized');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "from snorkel.lf_helpers import *\n",
    "label_manager = LabelManager()\n",
    "\n",
    "LFs = []\n",
    "\n",
    "# POSITIVE\n",
    "\n",
    "def LF_to_right(c):\n",
    "    return 1 if 'to' in get_right_ngrams(c.temp, window=1) else 0\n",
    "LFs.append(LF_to_right)\n",
    "\n",
    "def LF_150_right(c):\n",
    "    return 1 if '150' in get_right_ngrams(c.temp, window=4) else 0\n",
    "LFs.append(LF_150_right)\n",
    "\n",
    "def LF_storage_row(c):\n",
    "    return 1 if 'storage' in get_row_ngrams(c.temp) else 0\n",
    "LFs.append(LF_storage_row)\n",
    "\n",
    "def LF_operating_row(c):\n",
    "    return 1 if 'operating' in get_row_ngrams(c.temp) else 0\n",
    "LFs.append(LF_operating_row)\n",
    "\n",
    "# def LF_C_phrase(c):\n",
    "#     ngrams =  get_phrase_ngrams(c.temp, n_min=2, n_max=2, lower=False)\n",
    "#     return 1 if ('% C' in ngrams or '%C' in ngrams) else 0\n",
    "# LFs.append(LF_C_phrase)\n",
    "\n",
    "def LF_temperature_row(c):\n",
    "    return 1 if 'temperature' in get_row_ngrams(c.temp) else 0\n",
    "LFs.append(LF_temperature_row)\n",
    "\n",
    "def LF_tstg_row(c):\n",
    "    row_ngrams = get_row_ngrams(c.temp)\n",
    "    return 1 if ('tstg' in row_ngrams or \n",
    "                 'ts' in row_ngrams or \n",
    "                 'stg' in row_ngrams) else 0\n",
    "LFs.append(LF_tstg_row)\n",
    "\n",
    "# NEGATIVE\n",
    "\n",
    "def LF_not_temp_relevant(c):\n",
    "    ngrams = get_aligned_ngrams(c.temp)\n",
    "    return -1 if not ('storage' in ngrams or\n",
    "                      'temperature' in ngrams or\n",
    "                      'tstg' in ngrams or\n",
    "                      'ts' in ngrams or\n",
    "                      'stg' in ngrams) else 0\n",
    "LFs.append(LF_not_temp_relevant)\n",
    "\n",
    "def LF_temp_outside_table(c):\n",
    "    return -1 if c.temp.parent.row is None else 0\n",
    "LFs.append(LF_temp_outside_table)\n",
    "\n",
    "def LF_too_many_numbers_row(c):\n",
    "    num_numbers = list(get_row_ngrams(c.temp, attrib=\"ner_tags\")).count('number')\n",
    "    return -1 if num_numbers >= 3 else 0\n",
    "LFs.append(LF_too_many_numbers_row)\n",
    "\n",
    "def LF_collector_aligned(c):\n",
    "    ngrams = get_aligned_ngrams(c.temp)\n",
    "    return -1 if (\n",
    "        'collector'         in ngrams or\n",
    "        'collector-current' in ngrams or\n",
    "        'collector-base'    in ngrams or\n",
    "        'collector-emitter' in ngrams) else 0\n",
    "LFs.append(LF_collector_aligned)\n",
    "\n",
    "def LF_current_aligned(c):\n",
    "    ngrams = get_aligned_ngrams(c.temp)\n",
    "    return -1 if (\n",
    "        'current' in ngrams or\n",
    "        'dc'      in ngrams or\n",
    "        'ic'      in ngrams) else 0    \n",
    "LFs.append(LF_current_aligned)\n",
    "\n",
    "def LF_voltage_row_temp(c):\n",
    "    ngrams = get_aligned_ngrams(c.temp)\n",
    "    return -1 if (\n",
    "        'voltage' in ngrams or\n",
    "        'cbo'     in ngrams or\n",
    "        'ceo'     in ngrams or\n",
    "        'ebo'     in ngrams or\n",
    "        'v'       in ngrams) else 0\n",
    "LFs.append(LF_voltage_row_temp)\n",
    "\n",
    "def LF_voltage_row_part(c):\n",
    "    ngrams = get_aligned_ngrams(c.temp)\n",
    "    return -1 if (\n",
    "        'voltage' in ngrams or\n",
    "        'cbo'     in ngrams or\n",
    "        'ceo'     in ngrams or\n",
    "        'ebo'     in ngrams or\n",
    "        'v'       in ngrams) else 0\n",
    "LFs.append(LF_voltage_row_part)\n",
    "\n",
    "def LF_typ_row(c):\n",
    "    ngrams = get_row_ngrams(c.temp)\n",
    "    return -1 if ('typ' in ngrams or\n",
    "                  'typ.' in ngrams) else 0\n",
    "LFs.append(LF_typ_row)\n",
    "\n",
    "def LF_test_condition_aligned(c):\n",
    "    ngrams = get_aligned_ngrams(c.temp)\n",
    "    return -1 if ('test'      in ngrams or\n",
    "                  'condition' in ngrams) else 0\n",
    "LFs.append(LF_test_condition_aligned)\n",
    "\n",
    "def LF_complement_left_row(c):\n",
    "    return -1 if 'complement' in get_row_ngrams(c.part) else 0\n",
    "LFs.append(LF_complement_left_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "%time L_train.lf_stats(train_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager, LabelManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "\n",
    "label_manager = LabelManager()\n",
    "%time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
