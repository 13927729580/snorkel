{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 3: Training the Generative Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "from lib.init import *\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Loading Labeling Matricies \n",
    "\n",
    "First we'll load our label matrices from notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "labeler = LabelAnnotator()\n",
    "L_train = labeler.load_matrix(session, split=0)\n",
    "L_dev   = labeler.load_matrix(session, split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up and run the hyperparameter search, training our model with different hyperparamters and picking the best model configuration to keep. We'll set the random seed to maintain reproducibility.\n",
    "\n",
    "Note that we are fitting our model's parameters to the training set generated by our labeling functions, while we are picking hyperparamters with respect to score over the development set labels which we created by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Unifying supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Majority Vote\n",
    "The most simple way to unify the output of all your LFs is by computed the _unweighted majority vote_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos/neg    190:2621 6.8%/93.2%\n",
      "precision  42.65\n",
      "recall     30.53\n",
      "f1         35.58\n"
     ]
    }
   ],
   "source": [
    "from lib.scoring import *\n",
    "\n",
    "majority_vote_score(L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Generative Model\n",
    "In data programming, we use a more sophisitcated model to unify our labeling functions. We know that these labeling functions will not be perfect, and some may be quite low-quality, so we will _model_ their accuracies with a generative model, which Snorkel will help us easily apply.\n",
    "\n",
    "This will ultimately produce a single set of **noise-aware training labels**, which we will then use to train an end extraction model in the next notebook.  For more technical details of this overall approach, see our [NIPS 2016 paper](https://arxiv.org/abs/1605.07723)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training the Model\n",
    "When training the generative model, we'll tune our hyperparamters using a simple grid search. \n",
    "\n",
    "**Parameter Definitions**\n",
    "    \n",
    "    epochs     A single pass through all the data in your training set\n",
    "    step_size  The factor by which we update model weights after computing the gradient\n",
    "    decay      The rate our update factor dimishes (decay) over time.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized RandomSearch search of size 10. Search space size = 48.\n",
      "============================================================\n",
      "[1] Testing step_size = 4.49e-06, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03, LF_acc_prior_weight_default = 8.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.413994169096\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "============================================================\n",
      "[2] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03, LF_acc_prior_weight_default = 9.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.360856269113\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-06, LF_acc_prior_weight_default = 9.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.355828220859\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03, LF_acc_prior_weight_default = 1.00e+00\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.355828220859\n",
      "============================================================\n",
      "[5] Testing step_size = 4.49e-06, decay = 9.50e-01, epochs = 10, reg_param = 1.00e-06, LF_acc_prior_weight_default = 8.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.413994169096\n",
      "============================================================\n",
      "[6] Testing step_size = 4.49e-06, decay = 9.50e-01, epochs = 10, reg_param = 1.00e-06, LF_acc_prior_weight_default = 8.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.413994169096\n",
      "============================================================\n",
      "[7] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03, LF_acc_prior_weight_default = 8.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.360856269113\n",
      "============================================================\n",
      "[8] Testing step_size = 4.49e-06, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-06, LF_acc_prior_weight_default = 1.00e+00\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.413994169096\n",
      "============================================================\n",
      "[9] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03, LF_acc_prior_weight_default = 9.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.355828220859\n",
      "============================================================\n",
      "[10] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03, LF_acc_prior_weight_default = 9.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F1 Score: 0.355828220859\n",
      "[GenerativeModel] Model <GenerativeModel_0> loaded.\n",
      "CPU times: user 5min 13s, sys: 1.23 s, total: 5min 15s\n",
      "Wall time: 5min 14s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>decay</th>\n",
       "      <th>epochs</th>\n",
       "      <th>reg_param</th>\n",
       "      <th>LF_acc_prior_weight_default</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.413994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.413994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.413994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464052</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.413994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.430657</td>\n",
       "      <td>0.310526</td>\n",
       "      <td>0.360856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.430657</td>\n",
       "      <td>0.310526</td>\n",
       "      <td>0.360856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.355828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.355828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.355828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.355828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_size  decay  epochs  reg_param  LF_acc_prior_weight_default     Prec.  \\\n",
       "0   0.000004   0.90      50   0.001000                          0.8  0.464052   \n",
       "4   0.000004   0.95      10   0.000001                          0.8  0.464052   \n",
       "5   0.000004   0.95      10   0.000001                          0.8  0.464052   \n",
       "7   0.000004   0.95      50   0.000001                          1.0  0.464052   \n",
       "1   0.000010   0.90      50   0.001000                          0.9  0.430657   \n",
       "6   0.000010   0.90      50   0.001000                          0.8  0.430657   \n",
       "2   0.000010   0.95      50   0.000001                          0.9  0.426471   \n",
       "3   0.000010   0.95      50   0.001000                          1.0  0.426471   \n",
       "8   0.000010   0.95      50   0.001000                          0.9  0.426471   \n",
       "9   0.000010   0.95      50   0.001000                          0.9  0.426471   \n",
       "\n",
       "       Rec.        F1  \n",
       "0  0.373684  0.413994  \n",
       "4  0.373684  0.413994  \n",
       "5  0.373684  0.413994  \n",
       "7  0.373684  0.413994  \n",
       "1  0.310526  0.360856  \n",
       "6  0.310526  0.360856  \n",
       "2  0.305263  0.355828  \n",
       "3  0.305263  0.355828  \n",
       "8  0.305263  0.355828  \n",
       "9  0.305263  0.355828  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "# use grid search to optimize the generative model\n",
    "step_size_param     = ListParameter('step_size', [0.1 / L_train.shape[0], 1e-5])\n",
    "decay_param         = ListParameter('decay', [0.9, 0.95])\n",
    "epochs_param        = ListParameter('epochs', [10, 50])\n",
    "reg_param           = ListParameter('reg_param', [1e-3, 1e-6])\n",
    "prior_param         = ListParameter('LF_acc_prior_weight_default', [1.0, 0.9, 0.8])\n",
    "\n",
    "\n",
    "# search for the best model\n",
    "param_grid = [step_size_param, decay_param, epochs_param, reg_param, prior_param]\n",
    "searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=10, lf_propensity=False)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev, deps=set())\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Accuracies\n",
    "These are the weights learned for each LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_marriage_[between|words]_TRUE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.071861</td>\n",
       "      <td>0.027037</td>\n",
       "      <td>0.027037</td>\n",
       "      <td>64</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.331606</td>\n",
       "      <td>0.515712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_DIST_SUPERVISION_dbpedia_TRUE</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.501877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_almost_married_[between|words]_FALSE</th>\n",
       "      <td>2</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.498272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_kb_and_marriage</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_contrarian</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.509825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_almost_married_[left|words|window=1]_FALSE</th>\n",
       "      <td>5</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_almost_married_[left|words|window=2]_FALSE</th>\n",
       "      <td>6</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_almost_married_[left|words|window=3]_FALSE</th>\n",
       "      <td>7</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_almost_married_[left|words|window=4]_FALSE</th>\n",
       "      <td>8</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_too_far_apart</th>\n",
       "      <td>9</td>\n",
       "      <td>0.179651</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>465</td>\n",
       "      <td>0.954825</td>\n",
       "      <td>0.503053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    j  Coverage  Overlaps  \\\n",
       "LF_TERMS_marriage_[between|words]_TRUE              0  0.071861  0.027037   \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                    1  0.009249  0.009249   \n",
       "LF_TERMS_almost_married_[between|words]_FALSE       2  0.012451  0.004980   \n",
       "LF_kb_and_marriage                                  3  0.003557  0.003557   \n",
       "LF_contrarian                                       4  0.009249  0.009249   \n",
       "LF_TERMS_almost_married_[left|words|window=1]_F...  5  0.004625  0.004625   \n",
       "LF_TERMS_almost_married_[left|words|window=2]_F...  6  0.004980  0.004980   \n",
       "LF_TERMS_almost_married_[left|words|window=3]_F...  7  0.006403  0.006403   \n",
       "LF_TERMS_almost_married_[left|words|window=4]_F...  8  0.006403  0.006403   \n",
       "LF_too_far_apart                                    9  0.179651  0.024902   \n",
       "\n",
       "                                                    Conflicts  TP   FP  FN  \\\n",
       "LF_TERMS_marriage_[between|words]_TRUE               0.027037  64  129   0   \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                     0.009249  22    4   0   \n",
       "LF_TERMS_almost_married_[between|words]_FALSE        0.002846   0    0   7   \n",
       "LF_kb_and_marriage                                   0.003557  10    0   0   \n",
       "LF_contrarian                                        0.009249   0    0  22   \n",
       "LF_TERMS_almost_married_[left|words|window=1]_F...   0.001067   0    0   0   \n",
       "LF_TERMS_almost_married_[left|words|window=2]_F...   0.001067   0    0   0   \n",
       "LF_TERMS_almost_married_[left|words|window=3]_F...   0.001067   0    0   0   \n",
       "LF_TERMS_almost_married_[left|words|window=4]_F...   0.001067   0    0   0   \n",
       "LF_too_far_apart                                     0.022768   0    0  22   \n",
       "\n",
       "                                                     TN  Empirical Acc.  \\\n",
       "LF_TERMS_marriage_[between|words]_TRUE                0        0.331606   \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                      0        0.846154   \n",
       "LF_TERMS_almost_married_[between|words]_FALSE        24        0.774194   \n",
       "LF_kb_and_marriage                                    0        1.000000   \n",
       "LF_contrarian                                         4        0.153846   \n",
       "LF_TERMS_almost_married_[left|words|window=1]_F...   13        1.000000   \n",
       "LF_TERMS_almost_married_[left|words|window=2]_F...   14        1.000000   \n",
       "LF_TERMS_almost_married_[left|words|window=3]_F...   18        1.000000   \n",
       "LF_TERMS_almost_married_[left|words|window=4]_F...   18        1.000000   \n",
       "LF_too_far_apart                                    465        0.954825   \n",
       "\n",
       "                                                    Learned Acc.  \n",
       "LF_TERMS_marriage_[between|words]_TRUE                  0.515712  \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                        0.501877  \n",
       "LF_TERMS_almost_married_[between|words]_FALSE           0.498272  \n",
       "LF_kb_and_marriage                                      0.504446  \n",
       "LF_contrarian                                           0.509825  \n",
       "LF_TERMS_almost_married_[left|words|window=1]_F...      0.503472  \n",
       "LF_TERMS_almost_married_[left|words|window=2]_F...      0.501639  \n",
       "LF_TERMS_almost_married_[left|words|window=3]_F...      0.499328  \n",
       "LF_TERMS_almost_married_[left|words|window=4]_F...      0.503309  \n",
       "LF_too_far_apart                                        0.503053  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plotting Marginal Probabilities\n",
    "One immediate santity check  you can peform using the generative model is to visually examine the distribution of predicted training marginals. Ideally, there should get a bimodal distribution with large seperation between each peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d4ced10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20, range=(0.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generative Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.374\n",
      "Neg. class accuracy: 0.969\n",
      "Precision            0.464\n",
      "Recall               0.374\n",
      "F1                   0.414\n",
      "----------------------------------------\n",
      "TP: 71 | FP: 82 | TN: 2539 | FN: 119\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Saving our training labels\n",
    "\n",
    "Finally, we'll save the `training_marginals`, which are our **\"noise-aware training labels\"**, so that we can use them in the next tutorial to train our end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 22254 marginals\n",
      "CPU times: user 14.4 s, sys: 956 ms, total: 15.3 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Advanced Generative Model Features\n",
    "\n",
    "## A. Structure Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to include the dependencies between our LFs when training the generative model. Snorkel makes it easy to do this! `DependencySelector` runs a fast structure learning algorithm over the matrix of LF outputs to identify a set of likely dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)\n",
    "print len(deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the generative model with dependencies, we just pass in the above set as the `deps` argument to our model train function.\n",
    "\n",
    "    searcher = RandomSearch(GenerativeModel, param_grid, L_train, n=4, lf_propensity=False)\n",
    "    gen_model, run_stats = searcher.fit(L_dev, L_gold_dev, deps=deps)\n",
    "    run_stats"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
