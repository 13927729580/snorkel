{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'qalf',\n",
    "    'domain': 'tacred',\n",
    "    'relation': 'org_top_members_employees',\n",
    "    'splits': [0, 1],\n",
    "    'supervision': 'traditional',\n",
    "#     'max_train': 500,\n",
    "#     'max_lfs': 1,\n",
    "#     'learn_deps': True,\n",
    "#     'gen_model_search_space': 1,\n",
    "#     'gen_init_params': {\n",
    "#         'lf_propensity'         : True,\n",
    "#         'class_prior'           : True,\n",
    "#         'lf_class_propensity'   : True,\n",
    "#         'seed'                  : None,\n",
    "#     },\n",
    "#     'gen_params_default': {\n",
    "#         'step_size'     : 0.0001,\n",
    "#         'decay'         : 0.90,\n",
    "#         'reg_param'     : 0.50,\n",
    "#         'epochs'        : 25,\n",
    "#     },    \n",
    "    'disc_model_class': 'logreg',    \n",
    "    'disc_model_search_space': 1,\n",
    "    'disc_params_default': {\n",
    "        'lr'        : 1e-4,\n",
    "        'n_epochs'  : 50,\n",
    "        'l1_penalty': 1e-3,\n",
    "        'l2_penalty': 1e-3,\n",
    "    }\n",
    "#     'disc_params_range': {\n",
    "#         'lr'        : [1e-1, 1e-2, 1e-3, 1e-4, 1e-5],\n",
    "#         'l1_penalty': [1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4],\n",
    "#         'l2_penalty': [1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4],\n",
    "#     },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///qalf_tacred_org_top_members_employees.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'qalf_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting l2_penalty=0 to l2_penalty=0.001\n",
      "Overwriting lr=0.01 to lr=0.0001\n",
      "Overwriting l1_penalty=0 to l1_penalty=0.001\n",
      "Overwriting n_epochs=25 to n_epochs=50\n",
      "Overwriting domain=None to domain=tacred\n",
      "Overwriting batch_size=128 to batch_size=64\n",
      "Overwriting n_epochs=20 to n_epochs=50\n",
      "Overwriting lr=0.01 to lr=0.0001\n",
      "Overwriting l2_penalty=1.0 to l2_penalty=0.001\n",
      "Overwriting l1_penalty=1.0 to l1_penalty=0.001\n",
      "Overwriting disc_model_search_space=10 to disc_model_search_space=1\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting supervision=generative to supervision=majority\n",
      "Overwriting project=babble to project=qalf\n",
      "Overwriting splits=[0, 1, 2] to splits=[0, 1]\n",
      "Using TacredQalfPipeline object.\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'], config['project'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: 7824 Candidates\n",
      "Split 1: 2039 Candidates\n",
      "Split 2: 0 Candidates\n"
     ]
    }
   ],
   "source": [
    "%time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Split 0: Extracted 5200 Candidates\n",
      "CPU times: user 14.1 s, sys: 193 ms, total: 14.3 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "AnnotatorLabels created: 5200\n",
      "CPU times: user 1min 2s, sys: 241 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "# L_gold_train = load_gold_labels(session, annotator_name='gold', split=0)\n",
    "# L_gold_train\n",
    "# pipe.L_train.lf_stats(session, labels=L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.annotations import load_gold_labels\n",
    "# L_gold_dev   = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# L_gold_dev\n",
    "# pipe.L_dev.lf_stats(session, labels=L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'traditional' supervision mode...grabbing candidate and gold label subsets.\n",
      "NOTE: traditional supervision helper assumes all candidates have labels.\n",
      "No value found for max_train. Using all available gold labels.\n",
      "Using 7824 traditional gold labels\n",
      "(7824,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1097abf90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [7.1] Begin training discriminative model\n",
      "Skipping grid search.\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=7824  #epochs=50  batch size=64\n",
      "[SparseLogi...] Epoch 0 (0.35s) \tTrain Loss=1.110\tDev Loss=1.108\tDev F1=19.92\n",
      "[SparseLogi...] Epoch 1 (0.80s) \tTrain Loss=1.068\tDev Loss=1.076\tDev F1=15.57\n",
      "[SparseLogi...] Epoch 2 (1.23s) \tTrain Loss=1.036\tDev Loss=1.051\tDev F1=11.19\n",
      "[SparseLogi...] Epoch 3 (1.65s) \tTrain Loss=1.012\tDev Loss=1.032\tDev F1=4.47\n",
      "[SparseLogi...] Epoch 4 (2.09s) \tTrain Loss=0.993\tDev Loss=1.017\tDev F1=3.04\n",
      "[SparseLogi...] Epoch 5 (2.53s) \tTrain Loss=0.978\tDev Loss=1.004\tDev F1=1.85\n",
      "[SparseLogi...] Epoch 6 (3.08s) \tTrain Loss=0.965\tDev Loss=0.993\tDev F1=1.85\n",
      "[SparseLogi...] Epoch 7 (3.54s) \tTrain Loss=0.955\tDev Loss=0.985\tDev F1=1.85\n",
      "[SparseLogi...] Epoch 8 (4.04s) \tTrain Loss=0.947\tDev Loss=0.977\tDev F1=2.17\n",
      "[SparseLogi...] Epoch 9 (4.46s) \tTrain Loss=0.939\tDev Loss=0.971\tDev F1=3.69\n",
      "[SparseLogi...] Epoch 10 (4.92s) \tTrain Loss=0.931\tDev Loss=0.965\tDev F1=5.18\n",
      "[SparseLogi...] Epoch 11 (5.36s) \tTrain Loss=0.926\tDev Loss=0.960\tDev F1=12.61\n",
      "[SparseLogi...] Epoch 12 (5.80s) \tTrain Loss=0.922\tDev Loss=0.956\tDev F1=37.88\n",
      "[SparseLogi...] Epoch 13 (6.31s) \tTrain Loss=0.917\tDev Loss=0.953\tDev F1=41.86\n",
      "[SparseLogi...] Epoch 14 (6.74s) \tTrain Loss=0.913\tDev Loss=0.950\tDev F1=56.94\n",
      "[SparseLogi...] Epoch 15 (7.19s) \tTrain Loss=0.911\tDev Loss=0.947\tDev F1=59.59\n",
      "[SparseLogi...] Epoch 16 (7.64s) \tTrain Loss=0.907\tDev Loss=0.946\tDev F1=61.38\n",
      "[SparseLogi...] Epoch 17 (8.10s) \tTrain Loss=0.904\tDev Loss=0.944\tDev F1=61.87\n",
      "[SparseLogi...] Epoch 18 (8.68s) \tTrain Loss=0.902\tDev Loss=0.942\tDev F1=62.44\n",
      "[SparseLogi...] Epoch 19 (9.10s) \tTrain Loss=0.900\tDev Loss=0.942\tDev F1=62.89\n",
      "[SparseLogi...] Epoch 20 (9.52s) \tTrain Loss=0.899\tDev Loss=0.941\tDev F1=63.55\n",
      "[SparseLogi...] Epoch 21 (9.92s) \tTrain Loss=0.897\tDev Loss=0.940\tDev F1=63.62\n",
      "[SparseLogi...] Epoch 22 (10.36s) \tTrain Loss=0.896\tDev Loss=0.940\tDev F1=63.69\n",
      "[SparseLogi...] Epoch 23 (10.82s) \tTrain Loss=0.895\tDev Loss=0.940\tDev F1=63.69\n",
      "[SparseLogi...] Epoch 24 (11.27s) \tTrain Loss=0.894\tDev Loss=0.941\tDev F1=63.69\n",
      "[SparseLogi...] Epoch 25 (11.72s) \tTrain Loss=0.893\tDev Loss=0.941\tDev F1=63.35\n",
      "[SparseLogi...] Epoch 26 (12.16s) \tTrain Loss=0.893\tDev Loss=0.942\tDev F1=63.29\n",
      "[SparseLogi...] Epoch 27 (12.61s) \tTrain Loss=0.894\tDev Loss=0.942\tDev F1=63.48\n",
      "[SparseLogi...] Epoch 28 (13.07s) \tTrain Loss=0.894\tDev Loss=0.943\tDev F1=63.48\n",
      "[SparseLogi...] Epoch 29 (13.50s) \tTrain Loss=0.894\tDev Loss=0.944\tDev F1=63.42\n",
      "[SparseLogi...] Epoch 30 (14.05s) \tTrain Loss=0.893\tDev Loss=0.945\tDev F1=63.04\n",
      "[SparseLogi...] Epoch 31 (14.48s) \tTrain Loss=0.893\tDev Loss=0.947\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 32 (14.90s) \tTrain Loss=0.896\tDev Loss=0.948\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 33 (15.32s) \tTrain Loss=0.896\tDev Loss=0.949\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 34 (15.77s) \tTrain Loss=0.895\tDev Loss=0.951\tDev F1=62.99\n",
      "[SparseLogi...] Epoch 35 (16.20s) \tTrain Loss=0.896\tDev Loss=0.953\tDev F1=63.00\n",
      "[SparseLogi...] Epoch 36 (16.63s) \tTrain Loss=0.897\tDev Loss=0.954\tDev F1=63.06\n",
      "[SparseLogi...] Epoch 37 (17.07s) \tTrain Loss=0.899\tDev Loss=0.956\tDev F1=63.05\n",
      "[SparseLogi...] Epoch 38 (17.51s) \tTrain Loss=0.900\tDev Loss=0.958\tDev F1=63.18\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogi...] Epoch 39 (18.37s) \tTrain Loss=0.903\tDev Loss=0.960\tDev F1=63.18\n",
      "[SparseLogi...] Epoch 40 (18.80s) \tTrain Loss=0.902\tDev Loss=0.962\tDev F1=63.12\n",
      "[SparseLogi...] Epoch 41 (19.21s) \tTrain Loss=0.903\tDev Loss=0.965\tDev F1=63.36\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogi...] Epoch 42 (19.96s) \tTrain Loss=0.905\tDev Loss=0.967\tDev F1=63.14\n",
      "[SparseLogi...] Epoch 43 (20.49s) \tTrain Loss=0.907\tDev Loss=0.969\tDev F1=63.14\n",
      "[SparseLogi...] Epoch 44 (20.90s) \tTrain Loss=0.910\tDev Loss=0.972\tDev F1=63.44\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogi...] Epoch 45 (21.69s) \tTrain Loss=0.912\tDev Loss=0.974\tDev F1=63.44\n",
      "[SparseLogi...] Epoch 46 (22.10s) \tTrain Loss=0.912\tDev Loss=0.977\tDev F1=63.44\n",
      "[SparseLogi...] Epoch 47 (22.51s) \tTrain Loss=0.913\tDev Loss=0.979\tDev F1=63.44\n",
      "[SparseLogi...] Epoch 48 (22.92s) \tTrain Loss=0.916\tDev Loss=0.982\tDev F1=63.33\n",
      "[SparseLogi...] Epoch 49 (23.44s) \tTrain Loss=0.920\tDev Loss=0.985\tDev F1=63.33\n",
      "[SparseLogisticRegression] Training done (23.54s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Model saved as <discriminative_tacred>\n",
      "### Done in 24.4s.\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [F1 Score, Precision, Recall]\n",
      "Index: []\n",
      "CPU times: user 35 s, sys: 6.15 s, total: 41.1 s\n",
      "Wall time: 29.9 s\n"
     ]
    }
   ],
   "source": [
    "# pipe.L_dev.lf_stats(session, labels=L_gold_dev)\n",
    "# L_test.lf_stats(session, labels=L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
