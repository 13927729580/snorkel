{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the LFTest Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db')\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.parser import CorpusParser\n",
    "# from snorkel.parser import HTMLParser\n",
    "# from snorkel.parser import OmniParser\n",
    "\n",
    "# path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/lftest_html/'\n",
    "# doc_parser = HTMLParser(path=path)\n",
    "# context_parser = OmniParser()\n",
    "# cp = CorpusParser(doc_parser, context_parser, max_docs=15) \n",
    "\n",
    "# %time corpus = cp.parse_corpus(name='Hardware', session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify documents\n",
    "# for doc in corpus.documents: print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# session.add(corpus)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Corpus and split into Train/Dev/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Corpus\n",
    "\n",
    "# corpus = session.query(Corpus).filter(Corpus.name == 'Hardware').one()\n",
    "# print \"%s contains %d Documents\" % (corpus, len(corpus))\n",
    "\n",
    "\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from snorkel.queries import split_corpus\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "# split_corpus(session, corpus, train=0.8, development=0.2, test=0, seed=None)\n",
    "\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from snorkel.models import Corpus\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "# print \"%s contains %d Documents\" % (corpus, len(corpus))\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "# print \"%s contains %d Documents\" % (corpus, len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If necessary\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ lftest_corpus');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus (Hardware Training) contains 75 Documents\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15c4fe5eb44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mjis_matcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexMatchSpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mothers_matcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexMatchSpan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mparts_matcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeca_matcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjedec_matcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjis_matcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers_matcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Union' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import Corpus\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "print \"%s contains %d Documents\" % (corpus, len(corpus))\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.matchers import RegexMatchSpan\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "\n",
    "eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)')\n",
    "jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)')\n",
    "jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)')\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "\n",
    "\n",
    "temp_matcher = RegexMatchSpan(rgx=r'-[5-7][05]', longest_match_only=False)\n",
    "\n",
    "import os\n",
    "from hardware_utils import get_gold_dict\n",
    "from collections import defaultdict\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "gold_parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    gold_parts_by_doc[part[0]].add(part[1])\n",
    "    \n",
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp\n",
    "\n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=gold_parts_by_doc, n_max=3, split_tokens=None)\n",
    "temp_ngrams = OmniNgramsTemp(n_max=3, split_tokens=None)\n",
    "\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "ce = CandidateExtractor(Part_Temp, [part_ngrams, temp_ngrams], [parts_matcher, temp_matcher])\n",
    "\n",
    "%time train = ce.extract(corpus.documents, 'Hardware Training Candidates', session)\n",
    "print \"%s contains %d Candidates\" % (train, len(train))\n",
    "\n",
    "session.add(train)\n",
    "session.commit()\n",
    "\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ lftest_candidates');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ lftest_candidates snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# candidates = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "\n",
    "# from snorkel.loaders import ExternalAnnotationsLoader\n",
    "\n",
    "# loader = ExternalAnnotationsLoader(session, Part_Temp, \n",
    "#                                    'Hardware Training Candidates -- Gold',\n",
    "#                                    'Hardware Training Labels -- Gold',\n",
    "#                                    expand_candidate_set=True)\n",
    "\n",
    "# import os\n",
    "# from hardware_utils import load_hardware_labels\n",
    "\n",
    "# filename = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# %time load_hardware_labels(loader, candidates, filename, ['part','temp'], gold_attrib='stg_temp_min')\n",
    "\n",
    "# from snorkel.models import Label\n",
    "\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# train_gold = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "# print \"%d/%d Candidates have positive Labels\" % (len(train_gold), len(train))\n",
    "# print \"%d Labels loaded\" % session.query(Label).filter(\n",
    "#     Label.key == loader.annotation_key).count()\n",
    "\n",
    "# for set_name in ['Development']:\n",
    "#     candidate_set_name = 'Hardware %s Candidates' % set_name\n",
    "#     candidates = session.query(CandidateSet).filter(\n",
    "#         CandidateSet.name == candidate_set_name).one()\n",
    "#     loader = ExternalAnnotationsLoader(session, Part_Temp, \n",
    "#                                        'Hardware %s Candidates -- Gold' % set_name,\n",
    "#                                        'Hardware %s Labels -- Gold' % set_name,\n",
    "#                                        expand_candidate_set=True)\n",
    "#     %time load_hardware_labels(loader, candidates, filename, ['part','temp'], gold_attrib='stg_temp_min')\n",
    "#     candidates_gold = session.query(CandidateSet).filter(\n",
    "#         CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "#     print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "#         len(candidates_gold), len(candidates), candidates)\n",
    "#     print \"%d Labels loaded\" % session.query(Label).filter(\n",
    "#         Label.key == loader.annotation_key).count()\n",
    "    \n",
    "# # If necessary\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ lftest_labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ lftest_labels snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager\n",
    "\n",
    "# feature_manager = FeatureManager()\n",
    "\n",
    "# %time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "\n",
    "# %time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)\n",
    "\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "\n",
    "# from snorkel.utils import get_keys_by_candidate\n",
    "\n",
    "# for f in get_keys_by_candidate(F_train, F_train.get_candidate(1))[:10]: print f\n",
    "    \n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ lftest_featurized');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ lftest_featurized snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import LabelManager\n",
    "\n",
    "# label_manager = LabelManager()\n",
    "\n",
    "\n",
    "# from snorkel.lf_helpers import *\n",
    "\n",
    "# LFs = []\n",
    "\n",
    "# # gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# # def LF_training_gold(c):\n",
    "# #     training_gold_dict = get_gold_dict(gold_file, 'stg_temp_min')\n",
    "# #     return 1 if ((c[0].parent.document.name).upper(), \n",
    "# #                  (c[0].get_span()).upper(), \n",
    "# #                  (''.join(c[1].get_span().split())).upper()) in training_gold_dict else 0\n",
    "# # LFs.append(LF_training_gold)\n",
    "\n",
    "# # from hardware_utils import load_extended_parts_dict\n",
    "# # gold_file ='data/hardware/hardware_gold.csv'\n",
    "# # parts_dict = load_extended_parts_dict(gold_file)\n",
    "# # print \"Loaded %d part numbers.\" % len(parts_dict)\n",
    "\n",
    "# # def LF_parts_dict(c):\n",
    "# #     return 1 if (c.temp.parent.words)[0] in parts_dict else -1\n",
    "# # LFs.append(LF_foo)\n",
    "\n",
    "# # POSITIVE\n",
    "\n",
    "# def LF_to_right(c):\n",
    "#     return 1 if 'to' in get_right_ngrams(c.temp, window=1, n_max=1) else 0\n",
    "# LFs.append(LF_to_right)\n",
    "\n",
    "# def LF_150_right(c):\n",
    "#     return 1 if '150' in get_right_ngrams(c.temp, window=4, n_max=1) else 0\n",
    "# LFs.append(LF_150_right)\n",
    "\n",
    "# def LF_storage_row(c):\n",
    "#     return 1 if 'storage' in get_row_ngrams(c.temp, n_max=2) else 0\n",
    "# LFs.append(LF_storage_row)\n",
    "\n",
    "# def LF_operating_row(c):\n",
    "#     return 1 if 'operating' in get_row_ngrams(c.temp, n_max=2) else 0\n",
    "# LFs.append(LF_operating_row)\n",
    "\n",
    "# def LF_c_row(c):\n",
    "#     return 1 if '%C' in get_row_ngrams(c.temp, n_min=1, n_max=2, case_sensitive=True) else 0\n",
    "# LFs.append(LF_c_row)\n",
    "\n",
    "# def LF_temperature_row(c):\n",
    "#     return 1 if 'temperature' in get_row_ngrams(c.temp) else 0\n",
    "# LFs.append(LF_temperature_row)\n",
    "\n",
    "# def LF_tstg_row(c):\n",
    "#     row_ngrams = get_row_ngrams(c.temp, n_max=1)\n",
    "#     return 1 if ('tstg' in row_ngrams or 'ts' in row_ngrams) else 0\n",
    "# LFs.append(LF_tstg_row)\n",
    "\n",
    "\n",
    "# # NEGATIVE\n",
    "\n",
    "# def LF_temp_outside_table(c):\n",
    "#     return -1 if c.temp.parent.table is None else 0\n",
    "# LFs.append(LF_temp_outside_table)\n",
    "\n",
    "# def LF_mv_row(c):\n",
    "#     return -1 if 'mv' in get_row_ngrams(c.temp, infer=True) else 0\n",
    "# LFs.append(LF_mv_row)\n",
    "\n",
    "# def LF_collector_row(c):\n",
    "#     return -1 if 'collector' in get_row_ngrams(c.temp) else 0\n",
    "# LFs.append(LF_collector_row)\n",
    "\n",
    "# def LF_collectorattrib_row(c):\n",
    "#     return -1 if 'collector%' in get_row_ngrams(c.temp) else 0\n",
    "# LFs.append(LF_collectorattrib_row)\n",
    "\n",
    "# def LF_typ_row(c):\n",
    "#     return -1 if 'typ' in get_row_ngrams(c.temp) else 0\n",
    "# LFs.append(LF_collector_row)\n",
    "\n",
    "# def LF_complement_left(c):\n",
    "#     return -1 if 'complement' in get_left_ngrams(c.part) else 0\n",
    "# LFs.append(LF_complement_left)\n",
    "\n",
    "# def LF_voltage_row(c):\n",
    "#     return -1 if 'voltage' in get_row_ngrams(c.temp, infer=True) else 0\n",
    "# LFs.append(LF_voltage_row)\n",
    "\n",
    "# def LF_v_row(c):\n",
    "#     return -1 if 'v' in get_row_ngrams(c.temp, infer=True) else 0\n",
    "# LFs.append(LF_v_row)\n",
    "\n",
    "# def LF_vceo_row(c):\n",
    "#     return -1 if 'vceo' in get_row_ngrams(c.temp, infer=True) else 0\n",
    "# LFs.append(LF_vceo_row)\n",
    "\n",
    "# from snorkel.lf_helpers import get_right_ngrams, get_left_ngrams\n",
    "# from snorkel.lf_helpers import contains_token, contains_regex\n",
    "# from snorkel.lf_helpers import get_phrase_ngrams, get_cell_ngrams, get_neighbor_cell_ngrams\n",
    "# from snorkel.lf_helpers import get_row_ngrams, get_col_ngrams, get_aligned_ngrams\n",
    "# from snorkel.lf_helpers import same_document, same_table, same_cell, same_phrase\n",
    "# c = train[12]\n",
    "# print c.part\n",
    "# print c.temp\n",
    "# print c.temp.parent\n",
    "# print c.temp.parent.table\n",
    "# print same_document(c)\n",
    "# print same_table(c)\n",
    "# print contains_regex(c, rgx=r'849')\n",
    "# print LF_temp_outside_table(c)\n",
    "\n",
    "# %time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "\n",
    "# train_gold = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "\n",
    "# %time print(L_train.lf_stats(train_gold))\n",
    "\n",
    "# documents = set()\n",
    "# for c in train:\n",
    "#     documents.add(str(c.part.parent.document))\n",
    "    \n",
    "# from pprint import pprint\n",
    "# pprint(documents)\n",
    "\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ lftest_features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ lftest_features snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager\n",
    "\n",
    "# feature_manager = FeatureManager()\n",
    "\n",
    "# %time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "\n",
    "# from snorkel.annotations import LabelManager\n",
    "\n",
    "# label_manager = LabelManager()\n",
    "\n",
    "# %time L_train = label_manager.load(session, train, 'LF Labels')\n",
    "\n",
    "# from snorkel.learning import NaiveBayes\n",
    "\n",
    "# gen_model = NaiveBayes()\n",
    "# # gen_model.train(L_train, n_iter=3000, rate=1e-5)\n",
    "# gen_model.train(L_train, n_iter=15000, rate=1e-2)\n",
    "\n",
    "# gen_model.save(session, 'Generative Params')\n",
    "\n",
    "# train_marginals = gen_model.marginals(L_train)\n",
    "\n",
    "# from snorkel.learning import LogReg\n",
    "\n",
    "# disc_model = LogReg()\n",
    "# disc_model.train(F_train, train_marginals, n_iter=1000, rate=1e-3)\n",
    "\n",
    "# disc_model.w.shape\n",
    "\n",
    "\n",
    "# %time disc_model.save(session, \"Discriminative Params\")\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# dev = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "# from snorkel.annotations import FeatureManager\n",
    "\n",
    "# feature_manager = FeatureManager()\n",
    "# %time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "# L_dev = label_manager.load(session, dev, \"Hardware Development Labels -- Gold\")\n",
    "\n",
    "# gold_dev_set = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Development Candidates -- Gold').one()\n",
    "\n",
    "# F_dev.shape\n",
    "\n",
    "# tp, fp, tn, fn = disc_model.score(F_dev, L_dev, gold_dev_set)\n",
    "\n",
    "# from snorkel.models import Corpus\n",
    "# import sys\n",
    "# sys.path.append('../')\n",
    "# from hardware_utils import entity_level_f1\n",
    "# import os\n",
    "\n",
    "# gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Development').one()\n",
    "# (TP, FP, FN) = entity_level_f1(tp, fp, tn, fn, gold_file, corpus, 'stg_temp_min')\n",
    "\n",
    "# print FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
