{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'babble',\n",
    "    'domain': 'protein',\n",
    "    'gold_explanations': True,\n",
    "#     'debug': True,\n",
    "#     'db_name': 'babble_cdr_featurized_temp',\n",
    "#     'lf_source': 'gradturk',\n",
    "#     'max_explanations': 30,\n",
    "    'seed': 1,\n",
    "    'parallelism': 1,\n",
    "    'splits': [0,1,2],\n",
    "    'disc_model_class': 'lstm',\n",
    "    'supervision': 'majority',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_protein.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting domain=None to domain=protein\n",
      "Overwriting babbler_candidate_split=1 to babbler_candidate_split=[0, 1, 2]\n",
      "Overwriting LF_acc_prior_weight_default=1.0 to LF_acc_prior_weight_default=0.5\n",
      "Overwriting init_class_prior=0 to init_class_prior=-1.39\n",
      "Overwriting reg_param=0.1 to reg_param=0.5\n",
      "Overwriting supervision=generative to supervision=majority\n",
      "Overwriting seed=0 to seed=1\n",
      "Overwriting gold_explanations=False to gold_explanations=True\n",
      "Overwriting traditional_split=0 to traditional_split=1\n",
      "Using ProteinPipeline object.\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "if config['debug']:\n",
    "    print(\"NOTE: --debug=True: modifying parameters...\")\n",
    "    config['max_docs'] = 100\n",
    "    config['gen_model_search_space'] = 2\n",
    "    config['disc_model_search_space'] = 2\n",
    "    config['gen_params_default']['epochs'] = 25\n",
    "    config['disc_params_default']['n_epochs'] = 5\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5546\n",
      "1011\n",
      "1058\n"
     ]
    }
   ],
   "source": [
    "for split in [0,1,2]:\n",
    "    print(session.query(pipe.candidate_class).filter(\n",
    "        pipe.candidate_class.split == split).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking candidates...\n",
      "# CANDIDATES: 7615\n",
      "Building list of target candidate ids...\n",
      "Collected 29 unique target candidate ids from 30 explanations.\n",
      "Gathering desired candidates...\n",
      "Found 29/29 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 30/30 explanations\n",
      "Calling babbler...\n",
      "Created grammar with 599 rules\n",
      "WARNING: Number of candidates (1011) does not equal the number of pos (220) + neg (779) = 999 labels.\n",
      "CPU times: user 10.5 s, sys: 671 ms, total: 11.2 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF_by_with_gold\n",
      "LF_NucAc_in_sentence_gold\n",
      "LF_activate_B_gold\n",
      "LF_activates_gold\n",
      "LF_associat_with_gold\n",
      "LF_between_before_gold\n",
      "LF_bind_B_I_gold\n",
      "LF_close_I_gold\n",
      "LF_comma_gold\n",
      "LF_complex_L_gold\n",
      "LF_complex_R_gold\n",
      "LF_dist_sup_gold\n",
      "LF_distant_gold\n",
      "LF_induc_gold\n",
      "LF_influence_B_gold\n",
      "LF_interact_in_sentence_gold\n",
      "LF_interaction_gold\n",
      "LF_levels_gold\n",
      "LF_mutation_list_I_gold\n",
      "LF_no_B_gold\n",
      "LF_phosphory_gold\n",
      "LF_prepositions_I_gold\n",
      "LF_regulate_Betw_gold\n",
      "LF_residue_gold\n",
      "LF_same_gold\n",
      "LF_signaling_gold\n",
      "LF_substrate_B_I_gold\n",
      "LF_transfect_gold\n",
      "LF_uncertain_gold\n",
      "LF_sequenc_in_sentence_gold\n"
     ]
    }
   ],
   "source": [
    "for lf in pipe.lfs:\n",
    "    print(lf.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Labeled split 0: (5546,30) sparse (nnz = 13055)\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Labeled split 1: (1011,30) sparse (nnz = 2442)\n",
      "\n",
      "                               j  Coverage  Overlaps  Conflicts   TP   FP  FN  \\\n",
      "LF_by_with_gold                0  0.077151  0.068249   0.042532   44   33   0   \n",
      "LF_NucAc_in_sentence_gold      1  0.090999  0.088032   0.014837    0    0   4   \n",
      "LF_activate_B_gold             2  0.041543  0.032641   0.029674   18   23   0   \n",
      "LF_activates_gold              3  0.006924  0.006924   0.003956    6    1   0   \n",
      "LF_associat_with_gold          4  0.072206  0.058358   0.026706    0    0  13   \n",
      "LF_between_before_gold         5  0.025717  0.024728   0.017804    8   16   0   \n",
      "LF_bind_B_I_gold               6  0.070227  0.060336   0.040554   34   37   0   \n",
      "LF_close_I_gold                7  0.070227  0.067260   0.031652   38   31   0   \n",
      "LF_comma_gold                  8  0.146390  0.123640   0.057369    0    0  14   \n",
      "LF_complex_L_gold              9  0.005935  0.005935   0.002967    4    2   0   \n",
      "LF_complex_R_gold             10  0.007913  0.007913   0.001978    5    3   0   \n",
      "LF_dist_sup_gold              11  0.000000  0.000000   0.000000    0    0   0   \n",
      "LF_distant_gold               12  0.080119  0.073195   0.019782    0    0   2   \n",
      "LF_induc_gold                 13  0.180020  0.154303   0.033630    0    0  21   \n",
      "LF_influence_B_gold           14  0.005935  0.004946   0.004946    2    4   0   \n",
      "LF_interact_in_sentence_gold  15  0.063304  0.063304   0.028684   41   21   0   \n",
      "LF_interaction_gold           16  0.135509  0.135509   0.078140   72   64   0   \n",
      "LF_levels_gold                17  0.057369  0.054402   0.021761    0    0   5   \n",
      "LF_mutation_list_I_gold       18  0.338279  0.300692   0.117705    0    0  41   \n",
      "LF_no_B_gold                  19  0.235410  0.206726   0.090010    0    0  43   \n",
      "LF_phosphory_gold             20  0.045500  0.045500   0.025717   28   18   0   \n",
      "LF_prepositions_I_gold        21  0.268051  0.232443   0.164194  102  166   0   \n",
      "LF_regulate_Betw_gold         22  0.068249  0.060336   0.049456   26   43   0   \n",
      "LF_residue_gold               23  0.015826  0.015826   0.009891    8    8   0   \n",
      "LF_same_gold                  24  0.029674  0.028684   0.009891    0    0   3   \n",
      "LF_signaling_gold             25  0.174085  0.154303   0.087043    0    0  25   \n",
      "LF_substrate_B_I_gold         26  0.005935  0.004946   0.002967    4    2   0   \n",
      "LF_transfect_gold             27  0.028684  0.023739   0.009891    0    0   1   \n",
      "LF_uncertain_gold             28  0.064293  0.060336   0.030663    0    0  13   \n",
      "LF_sequenc_in_sentence_gold   29  0.003956  0.002967   0.000000    0    0   0   \n",
      "\n",
      "                               TN  Empirical Acc.  \n",
      "LF_by_with_gold                 0        0.571429  \n",
      "LF_NucAc_in_sentence_gold      88        0.956522  \n",
      "LF_activate_B_gold              0        0.439024  \n",
      "LF_activates_gold               0        0.857143  \n",
      "LF_associat_with_gold          60        0.821918  \n",
      "LF_between_before_gold          0        0.333333  \n",
      "LF_bind_B_I_gold                0        0.478873  \n",
      "LF_close_I_gold                 0        0.550725  \n",
      "LF_comma_gold                 130        0.902778  \n",
      "LF_complex_L_gold               0        0.666667  \n",
      "LF_complex_R_gold               0        0.625000  \n",
      "LF_dist_sup_gold                0             NaN  \n",
      "LF_distant_gold                78        0.975000  \n",
      "LF_induc_gold                 161        0.884615  \n",
      "LF_influence_B_gold             0        0.333333  \n",
      "LF_interact_in_sentence_gold    0        0.661290  \n",
      "LF_interaction_gold             0        0.529412  \n",
      "LF_levels_gold                 52        0.912281  \n",
      "LF_mutation_list_I_gold       299        0.879412  \n",
      "LF_no_B_gold                  190        0.815451  \n",
      "LF_phosphory_gold               0        0.608696  \n",
      "LF_prepositions_I_gold          0        0.380597  \n",
      "LF_regulate_Betw_gold           0        0.376812  \n",
      "LF_residue_gold                 0        0.500000  \n",
      "LF_same_gold                   27        0.900000  \n",
      "LF_signaling_gold             151        0.857955  \n",
      "LF_substrate_B_I_gold           0        0.666667  \n",
      "LF_transfect_gold              26        0.962963  \n",
      "LF_uncertain_gold              52        0.800000  \n",
      "LF_sequenc_in_sentence_gold     4        1.000000  \n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[=                                       ] 1%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/repos/snorkel/snorkel/annotations.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ac = (tp+tn).astype(float) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Labeled split 2: (1058,30) sparse (nnz = 2546)\n",
      "\n",
      "CPU times: user 1min 24s, sys: 911 ms, total: 1min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN = 0\n",
    "DEV = 1\n",
    "TEST = 2\n",
    "\n",
    "train = [exp.candidate for exp in pipe.explanations]\n",
    "dev = session.query(pipe.candidate_class).filter(pipe.candidate_class.split == DEV).all()\n",
    "test = session.query(pipe.candidate_class).filter(pipe.candidate_class.split == TEST).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_label_matrix\n",
    "\n",
    "Ls = []\n",
    "Ls.append(load_label_matrix(pipe.session, split=TRAIN))\n",
    "Ls.append(load_label_matrix(pipe.session, split=DEV))\n",
    "Ls.append(load_label_matrix(pipe.session, split=TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "\n",
    "def candidates_to_features(candidates, Ls):\n",
    "    for i, c in enumerate(candidates):\n",
    "        L = Ls[c.split]\n",
    "        row_idx = L.get_row_index(c)\n",
    "        features = L[row_idx,:]\n",
    "        if i == 0:\n",
    "            X = features\n",
    "        else:\n",
    "            X = vstack((X, features))\n",
    "    \n",
    "    # All features are indicators ({0,1})\n",
    "    X = abs(X.todense())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30)\n",
      "(1011, 30)\n",
      "(1058, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train = candidates_to_features(train, Ls)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_dev   = candidates_to_features(dev, Ls)\n",
    "print(X_dev.shape)\n",
    "\n",
    "X_test  = candidates_to_features(test, Ls)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_golds = []\n",
    "L_golds.append(load_gold_labels(pipe.session, annotator_name='gold', split=TRAIN))\n",
    "L_golds.append(load_gold_labels(pipe.session, annotator_name='gold', split=DEV))\n",
    "L_golds.append(load_gold_labels(pipe.session, annotator_name='gold', split=TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def candidates_to_labels(candidates, L_golds):\n",
    "    labels = []\n",
    "    for i, c in enumerate(candidates):\n",
    "        L_gold = L_golds[c.split]\n",
    "        row_idx = L_gold.get_row_index(c)\n",
    "        label = L_gold[row_idx,0]\n",
    "        labels.append(label)\n",
    "    y = np.array(labels)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(1011,)\n",
      "(1058,)\n"
     ]
    }
   ],
   "source": [
    "y_train = candidates_to_labels(train, Ls)\n",
    "print(y_train.shape)\n",
    "\n",
    "y_dev   = candidates_to_labels(dev, Ls)\n",
    "print(y_dev.shape)\n",
    "\n",
    "y_test  = candidates_to_labels(test, Ls)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 1]: f1 = 0.0740740740741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 5]: f1 = 0.689075630252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 10]: f1 = 0.809160305344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 50]: f1 = 0.909090909091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 100]: f1 = 0.924137931034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=500, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 500]: f1 = 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 1000]: f1 = 0.966887417219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C = 10000]: f1 = 0.980392156863\n",
      "\n",
      "Using C = 10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best = -1\n",
    "for C in [1, 5, 10, 50, 100, 500, 1000, 10000]:\n",
    "    logreg = LogisticRegression(C=C)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_dev)\n",
    "    if sum(y_pred) == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = f1_score(y_dev, y_pred)\n",
    "    print(\"[C = {}]: f1 = {}\".format(C, f1))\n",
    "    if f1 > best:\n",
    "        best = f1\n",
    "        best_C = C\n",
    "        \n",
    "print(\"\\nUsing C = {}\".format(best_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, j in zip(y_dev, y_pred):\n",
    "#     print((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 = 0.9802\n"
     ]
    }
   ],
   "source": [
    "logreg.set_params(C=best_C)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Test F1 = {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980198019802\n"
     ]
    }
   ],
   "source": [
    "tp = fp = tn = fn = 0\n",
    "for i, j in zip(y_test, y_pred):\n",
    "    if i == j:\n",
    "        if i == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    else:\n",
    "        if i == 0:\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "p = float(tp)/(tp + fp)\n",
    "r = float(tp)/(tp + fn)\n",
    "f1 = float(2*p*r)/(p + r)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
