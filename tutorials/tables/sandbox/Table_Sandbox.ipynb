{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.remove('snorkel.db')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser import HTMLParser\n",
    "from snorkel.parser import OmniParser\n",
    "\n",
    "file_name = os.environ['SNORKELHOME'] + '/tutorials/tables/sandbox/diseases.xhtml'\n",
    "doc_parser = HTMLParser(path=file_name)\n",
    "context_parser = OmniParser(tabular=True, \n",
    "                            lingual=True, blacklist=['caption'], \n",
    "                            flatten=['span','br','i'], flatten_delim='')\n",
    "#                             replacements=[('Temperature', 'Temp')])\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup, NavigableString, Comment\n",
    "# with open(file_name, 'rb') as f:\n",
    "#     html_doc = f.read()\n",
    "# soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for child in soup.body.children:\n",
    "#     print isinstance(child, Comment)\n",
    "# print isinstance(soup.table.tr, Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "CPU times: user 160 ms, sys: 20.2 ms, total: 180 ms\n",
      "Wall time: 466 ms\n",
      "35 Phrases in Corpus (Sandbox)\n"
     ]
    }
   ],
   "source": [
    "%time corpus = cp.parse_corpus(name='Sandbox', session=session)\n",
    "print \"%d Phrases in %s\" % (\n",
    "    len([phrase for doc in corpus.documents for phrase in doc.phrases]), corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of viruses, coughs, and colds\n",
      "Here isa line break\n",
      "I don't have Brain Canceror the hiccups\n",
      "See Table 1 Below.\n",
      "See Table 2 Below.\n",
      "SeeTable 3Below.\n",
      "Common Ailments\n",
      "Disease\n",
      "Location\n",
      "Year\n",
      "Polio and BC546 is -55OC cold.\n",
      "-Dublin to Milwaukee\n",
      "?\n",
      "2001\n",
      "I don't like Chicken Pox or pizza.\n",
      "Shingles is also bad.\n",
      "whooping cough\n",
      "Scurvy\n",
      "Annapolis\n",
      "Junction and Storage Temperature -55 to 150 o ?\n",
      "C\n",
      "In between the tables there is a nasty case of heart attack\n",
      "Problem\n",
      "Cause\n",
      "Cost\n",
      "Arthritis\n",
      "Pokemon Go\n",
      "Free\n",
      "YellowFever\n",
      "Unicorns\n",
      "$17.75\n",
      "Hypochondria\n",
      "Fear\n",
      "$100\n",
      "And here is a final sentence with warts.\n"
     ]
    }
   ],
   "source": [
    "for p in corpus.documents[0].phrases:\n",
    "    print p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import _get_node\n",
    "from lxml.html import fromstring\n",
    "from lxml import etree\n",
    "\n",
    "p = corpus.documents[0].phrases[0]\n",
    "print p.xpath\n",
    "print p.document.text[:10]\n",
    "tree = etree.ElementTree(fromstring(p.document.text))\n",
    "tree.xpath('/html/body/table[1]')\n",
    "# print type(p.document.etree.xpath('/html'))\n",
    "# .xpath(p.xpath[1:])\n",
    "print _get_node(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in corpus.documents[0].phrases:\n",
    "#     print (p.table, p.cell)\n",
    "        print (p.html_tag, p.xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xpath = '/html/body/table[1]/tbody/tr[5]/td[2]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(34):\n",
    "#     print corpus.documents[0].phrases[i].is_tabular()\n",
    "p = corpus.documents[0].phrases[5]\n",
    "print p.is_lingual()\n",
    "print p.is_tabular()\n",
    "print p.is_visual()\n",
    "print p.is_structural()\n",
    "# # print [phrase for phrase in corpus.documents[0].phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for cell in corpus.documents[0].cells: print cell.text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (a,b,c) = (2,(3 if True else 5) ,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "# Year = candidate_subclass('Year', ['year'])\n",
    "# Temp = candidate_subclass('Temp', ['temp'])\n",
    "# Disease = candidate_subclass('Disease', ['disease'])\n",
    "# Part = candidate_subclass('Part', ['part'])\n",
    "Disease_Part = candidate_subclass('Disease_Part', ['disease','part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import OmniNgrams\n",
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp\n",
    "\n",
    "omni_ngrams = OmniNgrams(n_max=3, split_tokens=None)\n",
    "omni_part = OmniNgrams(n_max=1)\n",
    "# omni_part = OmniNgramsPart(n_max=1)\n",
    "# omni_temp = OmniNgramsTemp(n_max=3)\n",
    "# omni_temp = OmniNgrams(n_max=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diseases = ['viruses', 'coughs', 'colds', 'brain', 'cancer', 'brain cancer', 'hiccups', \n",
    "            'ailments', 'disease', 'polio', 'chicken pox', 'shingles', 'whooping cough',\n",
    "            'scurvy', 'infectious diseases', 'heart attack', 'arthritis', 'fever', \n",
    "            'yellow fever', 'hypochondria', 'pneumonia', 'warts']\n",
    "print \"Loaded %d diseases.\" % len(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import DictionaryMatch, RegexMatchEach, RegexMatchSpan, DateMatcher\n",
    "\n",
    "disease_matcher = DictionaryMatch(d=diseases, ignore_case=True)\n",
    "# year_matcher = DateMatcher()\n",
    "part_matcher = RegexMatchEach(rgx='BC.*')\n",
    "# temp_matcher = RegexMatchSpan(rgx=r'-[5-7][05]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "# ce = CandidateExtractor(Part, [omni_part], [part_matcher])\n",
    "# ce = CandidateExtractor(Disease, [omni_ngrams], [disease_matcher])\n",
    "# ce = CandidateExtractor(Temp, [omni_temp], [temp_matcher])\n",
    "ce = CandidateExtractor(Disease_Part, \n",
    "                        [omni_ngrams, omni_part], \n",
    "                        [disease_matcher, part_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time candidates = ce.extract(corpus.documents, 'Sandbox Candidates', session)\n",
    "print \"%s contains %d Candidates\" % (candidates, len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in candidates:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.features.features import get_all_feats\n",
    "c = candidates[4]\n",
    "print c\n",
    "print\n",
    "for f, _ in get_all_feats(c):\n",
    "    print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "\n",
    "s = c[0]\n",
    "print s\n",
    "print get_tag(s)\n",
    "print get_parent_tag(s)\n",
    "print get_prev_sibling_tags(s)\n",
    "print get_prev_sibling_tags(s)\n",
    "print get_next_sibling_tags(s)\n",
    "print get_ancestor_class_names(s)\n",
    "print get_ancestor_tag_names(s)\n",
    "print get_ancestor_id_names(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "\n",
    "# print [cell.text[:8] for cell in _get_aligned_cells(root_phrase.cell, axis, infer=infer)]\n",
    "# print [phrase.text for cell in _get_aligned_cells(root_phrase.cell, axis, infer=infer) for phrase in cell.phrases]\n",
    "print c.disease.parent\n",
    "print c.part.parent\n",
    "print list(get_left_ngrams(c.part, n_max=1, window=10, lower=False))\n",
    "print list(get_right_ngrams(c.part, n_max=1, window=5))\n",
    "print list(get_phrase_ngrams(c.part, n_max=1))\n",
    "print list(get_cell_ngrams(c.part, n_max=1))\n",
    "print list(get_row_ngrams(c.part, n_max=1, direct=True, infer=True))\n",
    "print list(get_head_ngrams(c.part, 'row'))\n",
    "print list(get_head_ngrams(c.part, 'col'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "train = CandidateSet(name='train', candidates=candidates[:25])\n",
    "dev = CandidateSet(name='test', candidates=candidates[25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.fast_annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.create(session, train, 'Sandbox Features')\n",
    "F_train\n",
    "\n",
    "# from snorkel.features import get_span_feats\n",
    "# c = candidates[10]\n",
    "# %prun for feat in get_span_feats(c): print feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.utils import get_keys_by_candidate\n",
    "\n",
    "c = candidates[1]\n",
    "print c\n",
    "print\n",
    "for f in get_keys_by_candidate(c, F_train)[:]: print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c = candidates[0]\n",
    "# print c\n",
    "# print c.year\n",
    "# print c.year.parent\n",
    "# print c.year.char_start\n",
    "# print c.year.char_end\n",
    "# print c.year.parent.words\n",
    "# print c.year.parent.char_offsets\n",
    "# print c.year.parent.lemmas\n",
    "# print c.year.parent.pos_tags\n",
    "# print c.year.parent.ner_tags\n",
    "# print c.year.parent.dep_parents\n",
    "# print c.year.parent.dep_labels\n",
    "# print c.year.get_word_start()\n",
    "# print c.year.get_word_end()\n",
    "# # print get_row_ngrams(c.year)\n",
    "# # print get_row_ngrams(c.year, infer=True)\n",
    "# %time for i in range(1000): _get_aligned_cells((c.year).parent.cell, 'col', infer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Span, ImplicitSpan, TemporarySpan\n",
    "\n",
    "# print isinstance(c.year, TemporarySpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.lf_helpers import get_between_ngrams, get_left_ngrams, get_right_ngrams\n",
    "# from snorkel.lf_helpers import contains_token, contains_regex\n",
    "# from snorkel.lf_helpers import get_phrase_ngrams, get_cell_ngrams, get_neighbor_cell_ngrams\n",
    "# from snorkel.lf_helpers import get_row_ngrams, get_col_ngrams, get_aligned_ngrams\n",
    "# from snorkel.lf_helpers import same_document, same_table, same_cell, same_phrase\n",
    "# from snorkel.lf_helpers import _get_aligned_cells, _get_nonempty_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "c = candidates[2]\n",
    "print list(get_head_ngrams(c.disease, axis='col'))\n",
    "# print get_left_ngrams(c.disease)\n",
    "# print get_right_ngrams(c.disease)\n",
    "# print contains_token(c, 'plague')\n",
    "# print contains_regex(c, r'pla')\n",
    "# print same_document(c)\n",
    "# print same_table(c)\n",
    "# print same_cell(c)\n",
    "# print same_phrase(c)\n",
    "# print get_phrase_ngrams(c.disease, n_min=1, n_max=3, case_sensitive=True)\n",
    "# print get_cell_ngrams(c.disease, attrib='pos_tags')\n",
    "# print get_neighbor_cell_ngrams(c.disease, dist=2, directions=True)\n",
    "# print get_row_ngrams(c.disease)\n",
    "# print get_col_ngrams(c.disease)\n",
    "# print get_aligned_ngrams(c.disease)\n",
    "# print get_aligned_ngrams(c.disease, infer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import expand_implicit_text \n",
    "\n",
    "# for part in expand_implicit_text(''.join(['BC856/857/858', '/', '859/860'])): print part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def foo(n):\n",
    "#     phrase = 'repeat me'\n",
    "#     pmul = phrase * n\n",
    "#     pjoi = ''.join([phrase for x in xrange(n)])\n",
    "#     pinc = ''\n",
    "#     for x in xrange(n):\n",
    "#         pinc += phrase\n",
    "#     del pmul, pjoi, pinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %lprun -f foo foo(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import get_gold_dict\n",
    "\n",
    "# filename = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# gold_dict = get_gold_dict(filename, 'stg_temp_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(gold_dict.values())\n",
    "# print gold_dict.values().count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import count_hardware_labels\n",
    "\n",
    "# filename = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# %time (certain, maybe) = count_hardware_labels(loader, candidates, filename, attrib='stg_temp_min', attrib_class='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %time \n",
    "# for i in range(10000): \n",
    "#     for j in range(100):\n",
    "#         1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.utils import ProgressBar;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# n = 100000\n",
    "# pb = ProgressBar(n)\n",
    "# for i in xrange(n):\n",
    "#     pb.bar(i)\n",
    "# pb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N = 235\n",
    "# N = 10\n",
    "# ticks = set([int(i * N/100.0) for i in range(1,101)])\n",
    "# print ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for doc, text in doc_parser.parse():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_xpath(tags, counts):\n",
    "    xpath = ''\n",
    "    for i, tag in enumerate(tags):\n",
    "        xpath += '/' + tag\n",
    "        if counts[i] != 1:\n",
    "            xpath += '[%d]' % (counts[i] - 1)\n",
    "    return xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = ['html','body','table','tr','th']\n",
    "counts = [1, 1, 2, 2, 1]\n",
    "print create_xpath(tags, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print soup.html.body.table.next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml.html import fromstring\n",
    "import lxml\n",
    "\n",
    "html = lxml.html.fromstring(text)\n",
    "# htmlparser = etree.HTMLParser()\n",
    "# xml.etree.ElementTree.fromstring(text)\n",
    "# tree = lxml.etree.fromstring(text, htmlparser)\n",
    "# tree.xpath(xpathselector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etree.tostring(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tree.xpath('/html/body/table[1]')\n",
    "print tree.xpath('/html/body/table[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for noe in "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
