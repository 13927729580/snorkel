{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('snorkel.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the `Corpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser import HTMLParser\n",
    "from snorkel.parser import OmniParser\n",
    "\n",
    "doc_parser = HTMLParser(path='data/hardware/hardware_html/')\n",
    "context_parser = OmniParser()\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time corpus = cp.parse_corpus(name='Hardware Training', session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document SCSCS02175-1\n",
      "Document TWSCS04757-1\n",
      "Document BC182\n",
      "Document WEITS00252-1\n",
      "Document PHGLS20126-1\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus.documents[:5]: print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the `Corpus`\n",
    "Finally, we persist the parsed corpus in Snorkel's database backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the `Corpus`\n",
    "If the corpus has already been parsed, load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus (Hardware Training)\n",
      "Hardware Training contains 100 Documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Training').one()\n",
    "print corpus\n",
    "print \"%s contains %d Documents\" % (corpus.name, len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the `Candidates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import OmniNgrams\n",
    "\n",
    "omni_ngrams = OmniNgrams(n_max=3, split_tokens=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5331 part numbers.\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import load_extended_parts_dict\n",
    "\n",
    "filename='data/hardware/gold_all.csv'\n",
    "parts_dict = load_extended_parts_dict(filename)\n",
    "print \"Loaded %d part numbers.\" % len(parts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import DictionaryMatch, RegexMatchSpan\n",
    "\n",
    "parts_matcher = DictionaryMatch(d=parts_dict, ignore_case=True)\n",
    "temp_matcher = RegexMatchSpan(rgx=ur'-\\s?[5-7][05]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "ce = CandidateExtractor(Part_Temp, [omni_ngrams, omni_ngrams], [parts_matcher, temp_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time candidates = ce.extract(corpus.documents, 'Hardware Training Candidates', session)\n",
    "print \"Number of candidates:\", len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# session.rollback()\n",
    "# session.delete(c)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_Temp(Span(\"BC548\", parent=9040, chars=[16,20], words=[4,4]), Span(\"-55\", parent=124348, chars=[0,2], words=[0,0]))\n",
      "Part_Temp(Span(\"BC547\", parent=9040, chars=[8,12], words=[2,2]), Span(\"-55\", parent=124348, chars=[0,2], words=[0,0]))\n",
      "Part_Temp(Span(\"BC817\", parent=9358, chars=[34,38], words=[5,5]), Span(\"- 50\", parent=85151, chars=[0,3], words=[0,1]))\n",
      "Part_Temp(Span(\"BC817\", parent=9358, chars=[34,38], words=[5,5]), Span(\"-50\", parent=127064, chars=[0,2], words=[0,0]))\n",
      "Part_Temp(Span(\"BC807-40\", parent=88043, chars=[30,37], words=[8,8]), Span(\"-50\", parent=129202, chars=[0,2], words=[0,0]))\n"
     ]
    }
   ],
   "source": [
    "for c in candidates[:5]:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the extracted candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.add(candidates)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Set (Hardware Training Candidates)\n",
      "Hardware Training Candidates contains 646 Candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "candidates = session.query(CandidateSet).filter(CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "print candidates\n",
    "print \"%s contains %d Candidates\" % (candidates.name, len(candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make labels gold, candidates gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'Hardware Training Candidates').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 97%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 21.8 s, sys: 565 ms, total: 22.4 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 1.74 ms, total: 147 ms\n",
      "Wall time: 146 ms\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<646x1714 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 10918 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Part_Temp(Span(\"BC548\", parent=9040, chars=[16,20], words=[4,4]), Span(\"-55\", parent=124348, chars=[0,2], words=[0,0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train.get_candidate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnotationKey (TDL_INV_LEMMA:PARENTS-OF-BETWEEN-MENTION-and-MENTION[None])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train.get_key(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotationKey (TDL_INV_LEMMA:PARENTS-OF-BETWEEN-MENTION-and-MENTION[None])\n",
      "AnnotationKey (TDL_INV_LEMMA:BETWEEN-MENTION-and-MENTION[bc546])\n",
      "AnnotationKey (TDL_INV_LEMMA:BETWEEN-MENTION-and-MENTION[bc547])\n",
      "AnnotationKey (TDL_INV_LEMMA:BETWEEN-MENTION-and-MENTION[bc546 bc547])\n",
      "AnnotationKey (TDL_INV_DEP_LABEL:BETWEEN-MENTION-and-MENTION[ROOT])\n",
      "AnnotationKey (TDL_INV_DEP_LABEL:BETWEEN-MENTION-and-MENTION[dep])\n",
      "AnnotationKey (TDL_INV_DEP_LABEL:BETWEEN-MENTION-and-MENTION[ROOT dep])\n",
      "AnnotationKey (TDL_INV_DEP_LABEL|LEMMA:BETWEEN-MENTION-and-MENTION[ROOT|bc546])\n",
      "AnnotationKey (TDL_INV_DEP_LABEL|LEMMA:BETWEEN-MENTION-and-MENTION[dep|bc547])\n",
      "AnnotationKey (TDL_INV_DEP_LABEL|LEMMA:BETWEEN-MENTION-and-MENTION[ROOT|bc546 dep|bc547])\n",
      "AnnotationKey (TDL_INV_LEMMA:SEQ-BETWEEN[/])\n",
      "AnnotationKey (TDL_INV_LEMMA:SEQ-BETWEEN[bc547])\n",
      "AnnotationKey (TDL_INV_LEMMA:SEQ-BETWEEN[/ bc547])\n",
      "AnnotationKey (TDL_INV_LEMMA:SEQ-BETWEEN[bc547 /])\n",
      "AnnotationKey (TDL_INV_LEMMA:SEQ-BETWEEN[/ bc547 /])\n",
      "AnnotationKey (TDL_INV_LEMMA:LEFT-OF-MENTION[/])\n",
      "AnnotationKey (TDL_INV_SEQ-BETWEEN[LEN:0-4])\n",
      "AnnotationKey (TDL_INV_BETWEEN-MENTION-and-MENTION[LEN:0-2])\n"
     ]
    }
   ],
   "source": [
    "from snorkel.utils import get_keys_by_candidate\n",
    "\n",
    "for f in get_keys_by_candidate(F_train, F_train.get_candidate(0)): print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEMP\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])\n",
    "# from snorkel.models import CandidateSet\n",
    "# candidates = session.query(CandidateSet).filter(CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "# print candidates\n",
    "# train = candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_Temp(Span(\"BC548\", parent=9040, chars=[16,20], words=[4,4]), Span(\"-55\", parent=124348, chars=[0,2], words=[0,0]))\n",
      "150,-55~150\n",
      "[]\n",
      "[u'~', u'150']\n",
      "[u'~', u'150']\n",
      "[u'150', u',', u'-55', u'~', u'150']\n",
      "[u'625', u't', u'j', u',', u't', u'stg']\n",
      "[u'junction', u',', u'storage', u'temperature', u't', u'j', u',', u't', u'stg', u'?', u'c']\n",
      "[u'ratings', u'80', u'50', u'30', u'65', u'45', u'30', u'6', u'100', u'625']\n",
      "[u'junction', u',', u'storage', u'temperature', u't', u'j', u',', u't', u'stg', u'?', u'c', u'ratings', u'80', u'50', u'30', u'65', u'45', u'30', u'6', u'100', u'625']\n"
     ]
    }
   ],
   "source": [
    "from snorkel.lf_helpers import get_right_ngrams, get_left_ngrams, contains_token\n",
    "from snorkel.lf_helpers import get_phrase_ngrams, get_cell_ngrams, get_neighbor_cell_ngrams\n",
    "from snorkel.lf_helpers import get_row_ngrams, get_col_ngrams, get_aligned_ngrams\n",
    "cand = train[0]\n",
    "print cand\n",
    "print cand[1].parent.cell.text\n",
    "print get_left_ngrams(cand[1])\n",
    "print get_right_ngrams(cand[1])\n",
    "print get_phrase_ngrams(cand[1])\n",
    "print get_cell_ngrams(cand[1])\n",
    "print get_neighbor_cell_ngrams(cand[1])\n",
    "print get_row_ngrams(cand[1])\n",
    "print get_col_ngrams(cand[1])\n",
    "print get_aligned_ngrams(cand[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "\n",
    "LFs = []\n",
    "\n",
    "def LF_to_range(c):\n",
    "    return 1 if 'to' in get_right_ngrams(c) else 0\n",
    "LFs.append(LF_to_range)\n",
    "\n",
    "def LF_tilde_range(c):\n",
    "    return 1 if '~' in get_right_ngrams(c) else 0\n",
    "LFs.append(LF_tilde_range)\n",
    "\n",
    "def LF_through_range(c):\n",
    "    return 1 if set(['through','thru']).intersection(set(get_right_ngrams(c))) > 0 else 0\n",
    "LFs.append(LF_through_range)\n",
    "\n",
    "def LF_contains_minus(c):\n",
    "    return 1 if contains_token(c, '-') or contains_token(c,'-50') else -1\n",
    "LFs.append(LF_contains_minus)\n",
    "\n",
    "def LF_storage(c):\n",
    "    return 1 if 'storage' in get_row_ngrams(c, attrib='words') else -1\n",
    "LFs.append(LF_storage)\n",
    "\n",
    "def LF_tstg(c):\n",
    "    return 1 if 'tstg' in get_row_ngrams(c, attrib='words') else -1\n",
    "LFs.append(LF_tstg)\n",
    "\n",
    "def LF_tj(c):\n",
    "    return 1 if 'tj' in get_row_ngrams(c, attrib='words') else -1\n",
    "LFs.append(LF_tj)\n",
    "\n",
    "def LF_temperature(c):\n",
    "    return 1 if 'temperature' in get_row_ngrams(c, attrib='words') else -1\n",
    "LFs.append(LF_temperature)\n",
    "\n",
    "def LF_celsius(c):\n",
    "    return 1 if 'c' in get_row_ngrams(c, attrib='words') else -1\n",
    "LFs.append(LF_celsius)\n",
    "\n",
    "def LF_max(c):\n",
    "    return 1 if 'max' in get_aligned_ngrams(c, attrib='words') else 0\n",
    "LFs.append(LF_max)\n",
    "\n",
    "def LF_min(c):\n",
    "    return 1 if 'min' in get_aligned_ngrams(c, attrib='words') else 0\n",
    "LFs.append(LF_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 97%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 10.6 s, sys: 480 ms, total: 11 s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<646x11 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4603 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels2', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conflicts</th>\n",
       "      <th>coverage</th>\n",
       "      <th>j</th>\n",
       "      <th>overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_to_range</th>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tilde_range</th>\n",
       "      <td>0.040248</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_through_range</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_contains_minus</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>3</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_storage</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tstg</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_tj</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_temperature</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_celsius</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>8</td>\n",
       "      <td>0.978328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_max</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   conflicts  coverage   j  overlaps\n",
       "LF_to_range         0.236842  0.236842   0  0.236842\n",
       "LF_tilde_range      0.040248  0.040248   1  0.040248\n",
       "LF_through_range    0.978328  0.978328   2  0.978328\n",
       "LF_contains_minus   0.978328  0.978328   3  0.978328\n",
       "LF_storage          0.978328  0.978328   4  0.978328\n",
       "LF_tstg             0.978328  0.978328   5  0.978328\n",
       "LF_tj               0.978328  0.978328   6  0.978328\n",
       "LF_temperature      0.978328  0.978328   7  0.978328\n",
       "LF_celsius          0.978328  0.978328   8  0.978328\n",
       "LF_max              0.000000  0.000000   9  0.000000\n",
       "LF_min              0.000000  0.000000  10  0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t646\n",
      "Features:\t\t\t11\n",
      "================================================================================\n",
      "Begin training for rate=1e-05, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.913727\n",
      "\tLearning epoch = 250\tGradient mag. = 0.963354\n",
      "\tLearning epoch = 500\tGradient mag. = 0.964895\n",
      "\tLearning epoch = 750\tGradient mag. = 0.966439\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.967987\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.969537\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.971091\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.972648\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.974208\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.975771\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.977337\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.978907\n",
      "Final gradient magnitude for rate=1e-05, mu=1e-06: 0.980\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=3000, rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_model.save(session, 'Generative Params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Discriminative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t632\n",
      "Features:\t\t\t1714\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 438.069018\tGradient magnitude = 441.369984\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 114.074824\tGradient magnitude = 9.462703\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 109.571442\tGradient magnitude = 5.597344\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 107.721648\tGradient magnitude = 4.271160\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 106.637602\tGradient magnitude = 3.614356\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 105.896542\tGradient magnitude = 3.221343\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 105.347617\tGradient magnitude = 2.956399\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 104.921375\tGradient magnitude = 2.763498\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 104.580079\tGradient magnitude = 2.615856\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 104.300807\tGradient magnitude = 2.499049\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 104.068535\tGradient magnitude = 2.404491\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 103.872874\tGradient magnitude = 2.326645\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 103.706352\tGradient magnitude = 2.261722\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 103.563433\tGradient magnitude = 2.207007\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 103.439908\tGradient magnitude = 2.160492\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 103.332518\tGradient magnitude = 2.120656\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 103.238687\tGradient magnitude = 2.086323\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 103.156356\tGradient magnitude = 2.056568\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 103.083852\tGradient magnitude = 2.030657\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 103.019800\tGradient magnitude = 2.007999\n",
      "\tLearning epoch = 2000\tStep size = 0.000135199925397\n",
      "\tLoss = 102.963061\tGradient magnitude = 1.988110\n",
      "\tLearning epoch = 2100\tStep size = 0.00012232783079\n",
      "\tLoss = 102.912680\tGradient magnitude = 1.970597\n",
      "\tLearning epoch = 2200\tStep size = 0.000110681260672\n",
      "\tLoss = 102.867852\tGradient magnitude = 1.955129\n",
      "\tLearning epoch = 2300\tStep size = 0.000100143535489\n",
      "\tLoss = 102.827893\tGradient magnitude = 1.941434\n",
      "\tLearning epoch = 2400\tStep size = 9.06090844946e-05\n",
      "\tLoss = 102.792216\tGradient magnitude = 1.929280\n",
      "\tLearning epoch = 2500\tStep size = 8.19823881078e-05\n",
      "\tLoss = 102.760317\tGradient magnitude = 1.918473\n",
      "\tLearning epoch = 2600\tStep size = 7.41770209616e-05\n",
      "\tLoss = 102.731762\tGradient magnitude = 1.908846\n",
      "\tLearning epoch = 2700\tStep size = 6.71147860624e-05\n",
      "\tLoss = 102.706170\tGradient magnitude = 1.900256\n",
      "\tLearning epoch = 2800\tStep size = 6.07249313844e-05\n",
      "\tLoss = 102.683212\tGradient magnitude = 1.892581\n",
      "\tLearning epoch = 2900\tStep size = 5.49434410507e-05\n",
      "\tLoss = 102.662600\tGradient magnitude = 1.885715\n",
      "\tLearning epoch = 3000\tStep size = 4.9712393998e-05\n",
      "\tLoss = 102.644077\tGradient magnitude = 1.879565\n",
      "\tLearning epoch = 3100\tStep size = 4.49793837036e-05\n",
      "\tLoss = 102.627422\tGradient magnitude = 1.874051\n",
      "\tLearning epoch = 3200\tStep size = 4.06969931571e-05\n",
      "\tLoss = 102.612437\tGradient magnitude = 1.869103\n",
      "\tLearning epoch = 3300\tStep size = 3.68223198197e-05\n",
      "\tLoss = 102.598946\tGradient magnitude = 1.864659\n",
      "\tLearning epoch = 3400\tStep size = 3.33165458113e-05\n",
      "\tLoss = 102.586795\tGradient magnitude = 1.860665\n",
      "\tLearning epoch = 3500\tStep size = 3.01445490191e-05\n",
      "\tLoss = 102.575846\tGradient magnitude = 1.857073\n",
      "\tLearning epoch = 3600\tStep size = 2.72745512307e-05\n",
      "\tLoss = 102.565975\tGradient magnitude = 1.853841\n",
      "\tLearning epoch = 3700\tStep size = 2.46777997696e-05\n",
      "\tLoss = 102.557073\tGradient magnitude = 1.850930\n",
      "\tLearning epoch = 3800\tStep size = 2.23282794396e-05\n",
      "\tLoss = 102.549044\tGradient magnitude = 1.848308\n",
      "\tLearning epoch = 3900\tStep size = 2.02024518955e-05\n",
      "\tLoss = 102.541798\tGradient magnitude = 1.845946\n",
      "\tLearning epoch = 4000\tStep size = 1.82790198275e-05\n",
      "\tLoss = 102.535258\tGradient magnitude = 1.843816\n",
      "\tLearning epoch = 4100\tStep size = 1.65387135968e-05\n",
      "\tLoss = 102.529354\tGradient magnitude = 1.841895\n",
      "\tLearning epoch = 4200\tStep size = 1.49640981858e-05\n",
      "\tLoss = 102.524022\tGradient magnitude = 1.840162\n",
      "\tLearning epoch = 4300\tStep size = 1.35393985271e-05\n",
      "\tLoss = 102.519207\tGradient magnitude = 1.838598\n",
      "\tLearning epoch = 4400\tStep size = 1.2250341464e-05\n",
      "\tLoss = 102.514857\tGradient magnitude = 1.837186\n",
      "\tLearning epoch = 4500\tStep size = 1.10840127561e-05\n",
      "\tLoss = 102.510927\tGradient magnitude = 1.835911\n",
      "\tLearning epoch = 4600\tStep size = 1.00287277002e-05\n",
      "\tLoss = 102.507376\tGradient magnitude = 1.834761\n",
      "\tLearning epoch = 4700\tStep size = 9.0739140687e-06\n",
      "\tLoss = 102.504166\tGradient magnitude = 1.833721\n",
      "\tLearning epoch = 4800\tStep size = 8.21000619294e-06\n",
      "\tLoss = 102.501266\tGradient magnitude = 1.832782\n",
      "\tLearning epoch = 4900\tStep size = 7.42834913113e-06\n",
      "\tLoss = 102.498644\tGradient magnitude = 1.831934\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=5000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 511 ms, sys: 21.6 ms, total: 532 ms\n",
      "Wall time: 533 ms\n"
     ]
    }
   ],
   "source": [
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temporarily test on the training set:\n",
    "from snorkel.models import CandidateSet\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'Hardware Training Candidates').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 97%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 15.9 s, sys: 574 ms, total: 16.5 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_dev = label_manager.load(session, dev, \"CDR Development Labels -- Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_dev_set = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_dev, L_dev, gold_dev_set)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
