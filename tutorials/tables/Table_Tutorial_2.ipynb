{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: `Candidate` Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Training `Corpus`\n",
    "\n",
    "First, we will load the `Corpus` that we preprocessed in Part I:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus (Hardware Training) contains 78 Documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "print \"%s contains %d Documents\" % (corpus, len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a `Candidate` Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a basic `CandidateExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# from hardware_utils import load_extended_parts_dict\n",
    "# gold_file ='data/hardware/hardware_gold.csv'\n",
    "# parts_dict = load_extended_parts_dict(gold_file) # NOTE: this include A/B/C/-16/-25/-40 \n",
    "# print \"Loaded %d part numbers.\" % len(parts_dict)\n",
    "# parts_matcher = DictionaryMatch(d=parts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "# eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,4}[\\s]?[A-Z]{0,2}[0-9]?([-][A-Z0-9]{1,3})?)')\n",
    "# jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]?)')\n",
    "# jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "# others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,3})?)')\n",
    "# parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)')\n",
    "jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)')\n",
    "jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)')\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan\n",
    "\n",
    "temp_matcher = RegexMatchSpan(rgx=r'-[5-7][05]', longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from hardware_utils import get_gold_dict\n",
    "from collections import defaultdict\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "gold_parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    gold_parts_by_doc[part[0]].add(part[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print len(gold_parts_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import codecs\n",
    "# import csv\n",
    "# docs = set()\n",
    "\n",
    "# with codecs.open(gold_file, encoding=\"utf-8\") as csvfile:\n",
    "#     gold_reader = csv.reader(csvfile)\n",
    "#     gold_dict = set()\n",
    "#     i = 0\n",
    "#     for row in gold_reader:\n",
    "#         i += 1\n",
    "#         (doc, part, val, attr) = row\n",
    "#         docs.add(doc)\n",
    "# print i\n",
    "# print len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(get_gold_dict(gold_file, doc_on=True, part_on=False, val_on=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(set([pair[0] for pair in gold_parts]))\n",
    "# print len(gold_parts_by_doc)\n",
    "# print gold_parts_by_doc.items()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from snorkel.models import Corpus\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from hardware_utils import OmniNgramsPart\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "part_ngrams_2 = OmniNgramsPart(n_max=3, split_tokens=None)\n",
    "parts_by_doc = {}\n",
    "for doc in corpus.documents:\n",
    "    for tc in parts_matcher.apply(part_ngrams_2.apply(doc)):\n",
    "        parts_by_doc[tc.parent.document.name.upper()] = tc.get_span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n",
      "set(['PJECS00521-1'])\n"
     ]
    }
   ],
   "source": [
    "print set(parts_by_doc.keys()).difference(set(gold_parts_by_doc.keys()))\n",
    "print set(gold_parts_by_doc.keys()).difference(set(parts_by_doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "print len(parts_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "831\n"
     ]
    }
   ],
   "source": [
    "print sum(len(x) for x in gold_parts_by_doc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627\n"
     ]
    }
   ],
   "source": [
    "print sum(len(x) for x in parts_by_doc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %time\n",
    "# fn = []\n",
    "# for (doc, parts) in gold_parts_by_doc.items():\n",
    "#     if doc not in parts_by_doc:\n",
    "#         for part in parts:\n",
    "#             fn.append((doc, part))\n",
    "#     else:\n",
    "#         for part in parts:\n",
    "#             if part not in parts_by_doc[doc]:\n",
    "#                 fn.append((doc, part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(fn)\n",
    "# print fn[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp\n",
    "\n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=gold_parts_by_doc, n_max=3, split_tokens=None)\n",
    "temp_ngrams = OmniNgramsTemp(n_max=3, split_tokens=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "ce = CandidateExtractor(Part_Temp, [part_ngrams, temp_ngrams], [parts_matcher, temp_matcher])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the `CandidateExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time train = ce.extract(corpus.documents, 'Hardware Training Candidates', session)\n",
    "print \"%s contains %d Candidates\" % (train, len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in train[:3]:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from snorkel.utils import ProgressBar\n",
    "\n",
    "# def get_candidate_id(c):\n",
    "#     return c.part.get_stable_id() + c.temp.get_stable_id()\n",
    "\n",
    "# seen = defaultdict(int)\n",
    "# pb = ProgressBar(len(train))\n",
    "# for i, c in enumerate(train):\n",
    "#     pb.bar(i)\n",
    "#     seen[get_candidate_id(c)] += 1\n",
    "#     if seen[get_candidate_id(c)] == 2:\n",
    "#         import pdb; pdb.set_trace()\n",
    "# pb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print type(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(train) == len(set([c for c in train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the extracted candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.add(train)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "print \"%s contains %d Candidates\" % (train, len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating for development and test corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for corpus_name in ['Hardware Development']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "# dev = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "# test = get_ORM_instance(Corpus, session, 'Hardware Test')\n",
    "# trainies = [d.name for d in train.documents]\n",
    "# len(trainies)\n",
    "# for d in test.documents:\n",
    "#     if d.name in trainies:\n",
    "#         print 'YES!'\n",
    "# # for d in test.documents[:10]: print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORARY - Assessing Total Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import entity_level_total_recall\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "total_set = set([])\n",
    "for c in train:\n",
    "    total_set.add(c)\n",
    "for c in dev:\n",
    "    total_set.add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print list(total_set)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(train)\n",
    "train_set = set([c for c in train])\n",
    "print len(train_set)\n",
    "\n",
    "print len(dev)\n",
    "dev_set = set([c for c in dev])\n",
    "print len(dev_set)\n",
    "\n",
    "print len(total_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "(tp, fp, fn) = entity_level_total_recall(total_set, gold_file, relation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12611\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import get_gold_dict\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_attrib = 'stg_temp_min'\n",
    "gold = gold_dict = get_gold_dict(gold_file, gold_attrib)\n",
    "print len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12611\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "gold_dict_by_doc = defaultdict(set)\n",
    "for g in gold_dict:\n",
    "    gold_dict_by_doc[g[0]].add(g)\n",
    "print sum([len(gold_dict_by_doc[g]) for g in gold_dict_by_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.utils import ProgressBar\n",
    "# target = sorted(list(fn))[-1]\n",
    "# print target\n",
    "# print \"-------------------------------\"\n",
    "# pb = ProgressBar(len(candidates))\n",
    "# for i, c in enumerate(list(candidates)[:]):\n",
    "#     pb.bar(i)\n",
    "#     if (c.part.parent.document.name.upper() == target[0].upper())\n",
    "#         and c.part.get_span().upper() == target[1].upper()):\n",
    "#         print c\n",
    "# pb.close()\n",
    "# print len(tp)\n",
    "# for c in sorted(list(tp))[:5]:\n",
    "#     print c\n",
    "# print \"-------------------------------\"\n",
    "# print len(fn)\n",
    "# for c in sorted(list(fn))[:50]:\n",
    "#     print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import part_error_analysis\n",
    "\n",
    "# for c in total_set:\n",
    "#     if c.part.parent.document.name.upper()=='BC546-D' and c.part.get_span() == 'BC547':\n",
    "#         part_error_analysis(c)\n",
    "#         import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corpus = session.query(Corpus).filter(Corpus.name == 'Hardware').one()\n",
    "\n",
    "# for doc in corpus.documents:\n",
    "#     if doc.name == 'PNJIS00254-1':\n",
    "#         d = doc\n",
    "#         break\n",
    "# print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for phrase in d.phrases:\n",
    "#     if '55' in phrase.words:\n",
    "#         p = phrase\n",
    "#         print p.cell\n",
    "#         import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# candies = sorted(candidates, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import count_hardware_labels\n",
    "\n",
    "# filename = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# %time count_hardware_labels(candidates, filename, attrib='stg_temp_min', attrib_class='temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORARY - Return to Normalcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part 3, we will load `Labels` for each of our `Candidates` so that we can evaluate performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
