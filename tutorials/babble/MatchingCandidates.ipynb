{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to find candidates for explanations that do not have a candidate for consistency checking. For each explanation missing a candidate, loop through the candidates until you find one that matches. Confirm that the parse of the function is the right one, then move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'cdr',\n",
    "    'debug': False,\n",
    "    'postgres': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_cdr.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting domain=None to domain=cdr\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = session.query(pipe.candidate_class).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading canonical ID ontologies...\n",
      "Finished loading canonical ID ontologies.\n"
     ]
    }
   ],
   "source": [
    "from tutorials.babble.cdr.cdr_examples import get_explanations, get_user_lists\n",
    "\n",
    "explanations = get_explanations()\n",
    "user_lists = get_user_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building list of target candidate ids...\n",
      "Collected 28 unique target candidate ids from 30 explanations.\n",
      "Gathering desired candidates...\n",
      "Found 28/28 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 28/30 explanations\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.babble.utils import link_explanation_candidates\n",
    "explanations = link_explanation_candidates(explanations, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing all parses from previous explanation set.\n",
      "Created grammar with 592 rules\n",
      "30 explanation(s) out of 30 were parseable.\n",
      "106 parse(s) generated from 30 explanation(s).\n",
      "82 parse(s) remain (24 parse(s) removed by DuplicateSemanticsFilter).\n",
      "Note: 9 LFs did not have candidates and therefore could not be filtered.\n",
      "53 parse(s) remain (29 parse(s) removed by ConsistencyFilter).\n",
      "### Applying labeling functions to split 1\n",
      "[========================================] 100%\n",
      "\n",
      "### Done in 5.6s.\n",
      "\n",
      "44 parse(s) remain (9 parse(s) removed by UniformSignatureFilter: (9 None, 0 All)).\n",
      "31 parse(s) remain (13 parse(s) removed by DuplicateSignatureFilter).\n",
      "Added 31 parse(s) from 27 explanations to set. (Total # parses = 31)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.contrib.babble import Babbler\n",
    "\n",
    "babbler = Babbler(session,\n",
    "                  mode='text', \n",
    "                  candidate_class=pipe.candidate_class, \n",
    "                  user_lists=user_lists)\n",
    "babbler.apply(explanations, \n",
    "              split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parses = babbler.get_parses(translate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation(\"LF_c_cause_d: True, between the chemical and the disease, there is a causal word and the word 'not' is not between them.\")\n",
      "('.root', ('.label', ('.bool', True), ('.and', ('.any', ('.map', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.user_list', ('.string', 'causal')))), ('.not', ('.call', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.string', 'not'))))))\n",
      "return 1 if (any([s.in(text(between([X,Y]))) for s in user_list('causal')]) and not ('not'.in(text(between([X,Y]))))) else 0\n",
      "\n",
      "Explanation(\"LF_c_d: True, the disease is immediately preceded by the chemical.\")\n",
      "('.root', ('.label', ('.bool', True), ('.call', ('.in', ('.extract_text', ('.right', ('.arg', ('.int', 1)), ('.string', '.eq'), ('.int', 1), ('.string', 'words')))), ('.arg_to_string', ('.arg', ('.int', 2))))))\n",
      "return 1 if text(Y).in(text(exactly 1 word(s) to the right of X)) else 0\n",
      "\n",
      "Explanation(\"LF_c_induced_d: True, the disease is immediately preceded by the chemical, and the chemical name contains an \"induc\" or \"assoc\" word.\")\n",
      "('.root', ('.label', ('.bool', True), ('.and', ('.call', ('.in', ('.extract_text', ('.right', ('.arg', ('.int', 1)), ('.string', '.eq'), ('.int', 1), ('.string', 'words')))), ('.arg_to_string', ('.arg', ('.int', 2)))), ('.call', ('.composite_or', ('.contains',), ('.list', ('.string', 'induc'), ('.string', 'assoc'))), ('.arg_to_string', ('.arg', ('.int', 1)))))))\n",
      "return 1 if (text(Y).in(text(exactly 1 word(s) to the right of X)) and text(X).(.contains(u) for at least one u in ['induc','assoc'])) else 0\n",
      "\n",
      "Explanation(\"LF_c_treat_d: False, the chemical precedes the disease by no more than 100 characters, and a word between the disease and the chemical contains a word in the treat dictionary.\")\n",
      "('.root', ('.label', ('.bool', False), ('.and', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2)), ('.string', '.leq'), ('.int', 100), ('.string', 'chars')))), ('.arg_to_string', ('.arg', ('.int', 1)))), ('.any', ('.map', ('.composite_or', ('.contains',), ('.user_list', ('.string', 'treat'))), ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*'))))))\n",
      "return -1 if (text(X).in(text(no more than 100 chars to the left of Y)) and any([s.(.contains(u) for at least one u in user_list('treat')) for s in [w for w in the word(s) between([X,Y])]])) else 0\n",
      "\n",
      "Explanation(\"LF_c_treat_d_wide: False, the chemical comes before the disease, and a word between them contains a treat word.\")\n",
      "('.root', ('.label', ('.bool', False), ('.and', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2))))), ('.arg_to_string', ('.arg', ('.int', 1)))), ('.any', ('.map', ('.composite_or', ('.contains',), ('.user_list', ('.string', 'treat'))), ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*'))))))\n",
      "return -1 if (text(X).in(text(greater than 0 word(s) to the left of Y)) and any([s.(.contains(u) for at least one u in user_list('treat')) for s in [w for w in the word(s) between([X,Y])]])) else 0\n",
      "\n",
      "Explanation(\"LF_ctd_marker_c_d: True, the disease is immediately preceded by the chemical, and the pair of the chemical and the disease canonical IDs appears in the ctd_marker dictionary.\")\n",
      "('.root', ('.label', ('.bool', True), ('.and', ('.call', ('.in', ('.extract_text', ('.right', ('.arg', ('.int', 1)), ('.string', '.eq'), ('.int', 1), ('.string', 'words')))), ('.arg_to_string', ('.arg', ('.int', 2)))), ('.call', ('.in', ('.user_list', ('.string', 'ctd_marker'))), ('.tuple', ('.map', ('.cid',), ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))))))\n",
      "return 1 if (text(Y).in(text(exactly 1 word(s) to the right of X)) and tuple([s.cid for s in [X,Y]]).in(user_list('ctd_marker'))) else 0\n",
      "\n",
      "Explanation(\"LF_ctd_therapy_treat: False, Label false because (the chemical comes before the disease, and a word between them contains a treat word) and (the pair of the chemical and the disease canonical IDs appears in the ctd_therapy dictionary.)\")\n",
      "('.root', ('.label', ('.bool', False), ('.and', ('.and', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2))))), ('.arg_to_string', ('.arg', ('.int', 1)))), ('.any', ('.map', ('.composite_or', ('.contains',), ('.user_list', ('.string', 'treat'))), ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*')))), ('.call', ('.in', ('.user_list', ('.string', 'ctd_therapy'))), ('.tuple', ('.map', ('.cid',), ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))))))\n",
      "return -1 if ((text(X).in(text(greater than 0 word(s) to the left of Y)) and any([s.(.contains(u) for at least one u in user_list('treat')) for s in [w for w in the word(s) between([X,Y])]])) and tuple([s.cid for s in [X,Y]]).in(user_list('ctd_therapy'))) else 0\n",
      "\n",
      "Explanation(\"LF_ctd_unspecified_treat: False, Label false because (the chemical comes before the disease, and a word between them contains a treat word) and (the pair of the chemical and the disease canonical IDs appears in the ctd_unspecified dictionary.)\")\n",
      "('.root', ('.label', ('.bool', False), ('.and', ('.and', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2))))), ('.arg_to_string', ('.arg', ('.int', 1)))), ('.any', ('.map', ('.composite_or', ('.contains',), ('.user_list', ('.string', 'treat'))), ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*')))), ('.call', ('.in', ('.user_list', ('.string', 'ctd_unspecified'))), ('.tuple', ('.map', ('.cid',), ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))))))\n",
      "return -1 if ((text(X).in(text(greater than 0 word(s) to the left of Y)) and any([s.(.contains(u) for at least one u in user_list('treat')) for s in [w for w in the word(s) between([X,Y])]])) and tuple([s.cid for s in [X,Y]]).in(user_list('ctd_unspecified'))) else 0\n",
      "\n",
      "Explanation(\"LF_d_induced_by_c: True, \"induced by\", \"caused by\", or \"due to\" appears between the chemical and the disease.\")\n",
      "('.root', ('.label', ('.bool', True), ('.any', ('.map', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.list', ('.string', 'induced by'), ('.string', 'caused by'), ('.string', 'due to'))))))\n",
      "return 1 if any([s.in(text(between([X,Y]))) for s in ['induced by','caused by','due to']]) else 0\n",
      "\n",
      "Explanation(\"LF_d_induced_by_c_tight: True, the chemical is immediately preceded by the word \"by\" or \"to\", and the words \"induced by\", \"caused by\", or \"due to\" appear between the chemical and the disease.\")\n",
      "('.root', ('.label', ('.bool', True), ('.or', ('.call', ('.eq', ('.index_word', ('.string', 'by'), ('.int', 1))), ('.arg_to_string', ('.arg', ('.int', 1)))), ('.any', ('.map', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.list', ('.string', 'to'), ('.index_word', ('.string', 'induced by'), ('.int', 0)), ('.string', 'caused by'), ('.string', 'due to')))))))\n",
      "return 1 if (text(X).(= 'by'[0]) or any([s.in(text(between([X,Y]))) for s in ['to','induced by'[0],'caused by','due to']])) else 0\n",
      "\n",
      "Explanation(\"LF_d_induced_by_c_tight: True, the chemical is immediately preceded by the word \"by\" or \"to\", and the words \"induced by\", \"caused by\", or \"due to\" appear between the chemical and the disease.\")\n",
      "('.root', ('.label', ('.bool', True), ('.or', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1)), ('.string', '.eq'), ('.int', 1), ('.string', 'words')))), ('.string', 'by')), ('.any', ('.map', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.list', ('.string', 'to'), ('.index_word', ('.string', 'induced by'), ('.int', 0)), ('.string', 'caused by'), ('.string', 'due to')))))))\n",
      "return 1 if ('by'.in(text(exactly 1 word(s) to the left of X)) or any([s.in(text(between([X,Y]))) for s in ['to','induced by'[0],'caused by','due to']])) else 0\n",
      "\n",
      "Explanation(\"LF_d_treat_c: False, the disease precedes the chemical by no more than 100 characters, and at least word between them contains a treat word.\")\n",
      "('.root', ('.label', ('.bool', False), ('.and', ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1)), ('.string', '.leq'), ('.int', 100), ('.string', 'chars')))), ('.arg_to_string', ('.arg', ('.int', 2)))), ('.any', ('.map', ('.in', ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*')), ('.user_list', ('.string', 'treat')))))))\n",
      "return -1 if (text(Y).in(text(no more than 100 chars to the left of X)) and any([s.in([w for w in the word(s) between([X,Y])]) for s in user_list('treat')])) else 0\n",
      "\n",
      "Explanation(\"LF_develop_d_following_c: True, a word containing 'develop' appears somewhere before the chemical, and the word 'following' is between the disease and the chemical.\")\n",
      "('.root', ('.label', ('.bool', True), ('.any', ('.map', ('.in', ('.extract_text', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))))), ('.list', ('.string', 'develop'), ('.arg_to_string', ('.arg', ('.int', 1))), ('.index_word', ('.string', 'following'), ('.int', 0)))))))\n",
      "return 1 if any([s.in(text(between([X,Y]))) for s in ['develop',text(X),'following'[0]]]) else 0\n",
      "\n",
      "Explanation(\"LF_far_c_d: False, the chemical appears more than 100 characters before the disease.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2)), ('.string', '.gt'), ('.int', 100), ('.string', 'chars')))), ('.arg_to_string', ('.arg', ('.int', 1))))))\n",
      "return -1 if text(X).in(text(greater than 100 chars to the left of Y)) else 0\n",
      "\n",
      "Explanation(\"LF_far_c_d: False, the chemical appears more than 100 characters before the disease.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.gt', ('.int', 100)), ('.count', ('.filter', ('.left', ('.arg', ('.int', 2))), 'chars', None)))))\n",
      "return -1 if count([char(s) greater than 0 word(s) to the left of Y]).(> 100) else 0\n",
      "\n",
      "Explanation(\"LF_far_d_c: False, the disease appears more than 100 characters before the chemical.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1)), ('.string', '.gt'), ('.int', 100), ('.string', 'chars')))), ('.arg_to_string', ('.arg', ('.int', 2))))))\n",
      "return -1 if text(Y).in(text(greater than 100 chars to the left of X)) else 0\n",
      "\n",
      "Explanation(\"LF_far_d_c: False, the disease appears more than 100 characters before the chemical.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.gt', ('.int', 100)), ('.count', ('.filter', ('.left', ('.arg', ('.int', 1))), 'chars', None)))))\n",
      "return -1 if count([char(s) greater than 0 word(s) to the left of X]).(> 100) else 0\n",
      "\n",
      "Explanation(\"LF_improve_before_disease: False, a word starting with \"improv\" appears before the chemical.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 1))))), ('.string', 'improv'))))\n",
      "return -1 if 'improv'.in(text(greater than 0 word(s) to the left of X)) else 0\n",
      "\n",
      "Explanation(\"LF_in_ctd_unspecified: False, the pair of canonical IDs of the chemical and the disease are in the ctd_unspecified dictionary.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.in', ('.user_list', ('.string', 'ctd_unspecified'))), ('.tuple', ('.map', ('.cid',), ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2))))))))\n",
      "return -1 if tuple([s.cid for s in [X,Y]]).in(user_list('ctd_unspecified')) else 0\n",
      "\n",
      "Explanation(\"LF_in_ctd_therapy: False, the pair of canonical IDs of the chemical and the disease are in the ctd_therapy dictionary.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.in', ('.user_list', ('.string', 'ctd_therapy'))), ('.tuple', ('.map', ('.cid',), ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2))))))))\n",
      "return -1 if tuple([s.cid for s in [X,Y]]).in(user_list('ctd_therapy')) else 0\n",
      "\n",
      "Explanation(\"LF_in_ctd_marker: True, the pair of canonical IDs of the chemical and the disease are in the ctd_marker dictionary.\")\n",
      "('.root', ('.label', ('.bool', True), ('.call', ('.in', ('.user_list', ('.string', 'ctd_marker'))), ('.tuple', ('.map', ('.cid',), ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2))))))))\n",
      "return 1 if tuple([s.cid for s in [X,Y]]).in(user_list('ctd_marker')) else 0\n",
      "\n",
      "Explanation(\"LF_in_patient_with: False, a patient phrase comes no more than four words before the disease.\")\n",
      "('.root', ('.label', ('.bool', False), ('.any', ('.map', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2)), ('.string', '.leq'), ('.int', 4), ('.string', 'words')))), ('.user_list', ('.string', 'patient'))))))\n",
      "return -1 if any([s.in(text(no more than 4 word(s) to the left of Y)) for s in user_list('patient')]) else 0\n",
      "\n",
      "Explanation(\"LF_in_patient_with: False, a patient phrase comes no more than four words before the disease.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.geq', ('.int', 1)), ('.count', ('.filter', ('.left', ('.arg', ('.int', 2)), ('.string', '.leq'), ('.int', 4), ('.string', 'words')), 'words', '\\\\w+\\\\S*')))))\n",
      "return -1 if count([w for w in the word(s) no more than 4 word(s) to the left of Y]).(>= 1) else 0\n",
      "\n",
      "Explanation(\"LF_induce: True, a word between the chemical and the disease contains \"induc\".\")\n",
      "('.root', ('.label', ('.bool', True), ('.any', ('.map', ('.contains', ('.string', 'induc')), ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*')))))\n",
      "return 1 if any([s.contains('induc') for s in [w for w in the word(s) between([X,Y])]]) else 0\n",
      "\n",
      "Explanation(\"LF_induce_name: True, the chemical contains \"induc\".\")\n",
      "('.root', ('.label', ('.bool', True), ('.call', ('.contains', ('.string', 'induc')), ('.arg_to_string', ('.arg', ('.int', 1))))))\n",
      "return 1 if text(X).contains('induc') else 0\n",
      "\n",
      "Explanation(\"LF_induced_other: False, a word between the chemical and the disease ends with \"induced\".\")\n",
      "('.root', ('.label', ('.bool', False), ('.any', ('.map', ('.endswith', ('.string', 'induced')), ('.filter', ('.between', ('.list', ('.arg', ('.int', 1)), ('.arg', ('.int', 2)))), 'words', '\\\\w+\\\\S*')))))\n",
      "return -1 if any([s.endswith('induced') for s in [w for w in the word(s) between([X,Y])]]) else 0\n",
      "\n",
      "Explanation(\"LF_level: False, the word \"level\" comes after the chemical.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.in', ('.extract_text', ('.right', ('.arg', ('.int', 1))))), ('.string', 'level'))))\n",
      "return -1 if 'level'.in(text(greater than 0 word(s) to the right of X)) else 0\n",
      "\n",
      "Explanation(\"LF_measure: False, a word before the chemical starts with \"measur\".\")\n",
      "('.root', ('.label', ('.bool', False), ('.any', ('.map', ('.startswith', ('.string', 'measur')), ('.filter', ('.left', ('.arg', ('.int', 1))), 'words', '\\\\w+\\\\S*')))))\n",
      "return -1 if any([s.startswith('measur') for s in [w for w in the word(s) greater than 0 word(s) to the left of X]]) else 0\n",
      "\n",
      "Explanation(\"LF_neg_d: False, \"none\", \"not\", or \"no\" precedes the disease by no more than 30 characters. \")\n",
      "('.root', ('.label', ('.bool', False), ('.any', ('.map', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2)), ('.string', '.leq'), ('.int', 30), ('.string', 'chars')))), ('.list', ('.string', 'none'), ('.string', 'not'), ('.string', 'no'))))))\n",
      "return -1 if any([s.in(text(no more than 30 chars to the left of Y)) for s in ['none','not','no']]) else 0\n",
      "\n",
      "Explanation(\"LF_risk_d: True, \"risk of\" comes before the disease.\")\n",
      "('.root', ('.label', ('.bool', True), ('.call', ('.in', ('.extract_text', ('.left', ('.arg', ('.int', 2))))), ('.string', 'risk of'))))\n",
      "return 1 if 'risk of'.in(text(greater than 0 word(s) to the left of Y)) else 0\n",
      "\n",
      "Explanation(\"LF_weak_assertions: False, at least one weak phrase is in the sentence.\")\n",
      "('.root', ('.label', ('.bool', False), ('.call', ('.geq', ('.int', 1)), ('.sum', ('.map', ('.in', ('.extract_text', ('.sentence',))), ('.user_list', ('.string', 'weak')))))))\n",
      "return -1 if sum([s.in(text(the sentence)) for s in user_list('weak')]).(>= 1) else 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for parse in parses:\n",
    "    print(parse.explanation)\n",
    "    print(parse.semantics)\n",
    "    print(babbler.semparser.grammar.translate(parse.semantics))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "seen = set()\n",
    "explanation_map = defaultdict(list)\n",
    "for parse in parses:\n",
    "    if parse.explanation.candidate is None:\n",
    "        print(parse.explanation)\n",
    "        print(\"\")\n",
    "        for c in candidates:\n",
    "            if parse.function(c):\n",
    "                print((c[0].get_span(), c[1].get_span()))\n",
    "                print(\"\")\n",
    "                print(c.get_parent().text)\n",
    "                print(\"\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN = 0\n",
    "# candidates = session.query(pipe.candidate_class).filter(\n",
    "#     pipe.candidate_class.split == TRAIN)\n",
    "# for c in candidates:\n",
    "#     sentence = c.get_parent().text\n",
    "#     if 'develop' in sentence and 'following' in sentence:\n",
    "#         print(sentence)\n",
    "#         print(\"\")\n",
    "#         print(c)\n",
    "#         print(c.get_stable_id())\n",
    "#         print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
