{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment as hungarian\n",
    "from editdistance import eval as editdist\n",
    "from pdb import set_trace as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# html = ['animal','cat','dog','bird','1','2','3','color','oops','red','4','pet','dog','3','fig']\n",
    "# pdf = ['animal','cat','1','fig','dog','2','bird','3','color','ref','4','pet','whoops','dog','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: \n",
    "make parallel lists\n",
    "scramble locally\n",
    "make some duplicate words\n",
    "replace a few words entirely\n",
    "cut some words in half\n",
    "\n",
    "\"\"\" \n",
    "import copy\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def make_lists(N, \n",
    "               scramble_pct=0, \n",
    "               scramble_rng=10, \n",
    "               duplicate_pct=0, \n",
    "               mismatch_pct=.05,\n",
    "               partial_pct=0,\n",
    "               offset=0):\n",
    "    duplicate_num = 0\n",
    "    mismatch_num = 0\n",
    "    partial_num = 0\n",
    "    uid = 0\n",
    "    \n",
    "    # make parallel lists\n",
    "    html = [(i, ''.join(random.sample(alphabet, random.randint(3,10)))) for i in range(N)]\n",
    "    pdf = copy.deepcopy(html)\n",
    "    uid = N\n",
    "    \n",
    "    # make some duplicate words\n",
    "    for i in range(N):\n",
    "        if random.random() < duplicate_pct:\n",
    "            duplicate_num += 2\n",
    "            html[i] = (uid, html[random.randint(0, N-1)][1])\n",
    "            pdf[i] = html[i]\n",
    "            uid += 1\n",
    "    \n",
    "    # replace some words\n",
    "    for i in range(N):\n",
    "        if random.random() < mismatch_pct:\n",
    "            mismatch_num += 1\n",
    "            html[i] = (None, html[i][1])\n",
    "            pdf[i] = (None, ''.join(random.sample(alphabet, random.randint(3,10))))\n",
    "            uid += 1\n",
    "    \n",
    "    # cut some words in half\n",
    "    for i in range(N):\n",
    "        if random.random() < partial_pct:\n",
    "            partial_num += 1\n",
    "            if random.random() < 0.5:\n",
    "                html[i] = (html[i][0], html[i][1][:random.randint(2, len(html[i]))])\n",
    "            else:\n",
    "                pdf[i] = (pdf[i][0], pdf[i][1][:random.randint(2, len(html[i]))])\n",
    "                                   \n",
    "    # scramble locally\n",
    "    old_pdf = pdf\n",
    "    pdf = [None] * N\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in range(N):\n",
    "        if i < (N - scramble_rng) and random.random() < scramble_pct:\n",
    "            jump = random.randint(1,scramble_rng)\n",
    "            k = j + jump\n",
    "            while pdf[k] is not None:\n",
    "                k += 1\n",
    "            pdf[k] = old_pdf[i]\n",
    "        else:\n",
    "            while pdf[j] is not None:\n",
    "                j += 1\n",
    "            pdf[j] = old_pdf[i]  \n",
    "\n",
    "    # offset \n",
    "    for i in range(offset):\n",
    "        pdf = [(None, ''.join(random.sample(alphabet, random.randint(3,10))))] + pdf\n",
    "    \n",
    "    duplicate_pct = float(duplicate_num)/N\n",
    "    mismatch_pct = float(mismatch_num)/N\n",
    "    partial_pct = float(partial_num)/N\n",
    "\n",
    "    return (html, pdf, duplicate_pct, mismatch_pct, partial_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate: 0.0\n",
      "Mismatch:  0.05\n",
      "Partial:   0.0\n",
      "Aligned:   1.0\n",
      "CPU times: user 1.92 ms, sys: 201 µs, total: 2.12 ms\n",
      "Wall time: 2.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pprint import pprint\n",
    "\n",
    "N = 100\n",
    "(html, pdf, dup, mis, part) = make_lists(N)\n",
    "print \"Duplicate: %s\" % dup\n",
    "print \"Mismatch:  %s\" % mis\n",
    "print \"Partial:   %s\" % part\n",
    "print \"Aligned:   %s\" % (sum([html[i][0] == pdf[i][0] for i in range(N)]) / float(N))\n",
    "# pprint(zip(html, pdf))\n",
    "# for i in max(len(html), len(pdf)):\n",
    "#     print \"%s:%s\" % (html[i][1] if i < len(html) else 'None', pdf[i][1] if i < len(pdf) else 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: hungarian does a good job matching, but it's expensive as an n^3 algorithm. But we know that matches won't be found from the top of one to the bottom of the other, so only give a small portion at a time to match. Use a sliding window of 'small' size and find matches. Then start the next window (correcting for the difference in i and j of the last members of the previous window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 'ztwfo'), (0, 'ztwfo'))\n",
      "((1, 'dyborct'), (1, 'dyborct'))\n",
      "((2, 'mthucbw'), (2, 'mthucbw'))\n",
      "((3, 'arobnghel'), (3, 'arobnghel'))\n",
      "((None, 'acw'), (None, 'gevb'))\n",
      "((5, 'kmgxeszhyl'), (5, 'kmgxeszhyl'))\n",
      "((6, 'mrnacdy'), (6, 'mrnacdy'))\n",
      "((7, 'vnbeah'), (7, 'vnbeah'))\n",
      "Offset: 0\n",
      "CPU times: user 493 µs, sys: 374 µs, total: 867 µs\n",
      "Wall time: 844 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def calculate_offset(listA, listB, offsetN, offsetM):\n",
    "    wordsA = zip(*listA[:offsetN])[1]\n",
    "    wordsB = zip(*listB[:offsetM])[1]\n",
    "    offsets = []\n",
    "    for i in range(offsetN):\n",
    "        try:\n",
    "            offsets.append(wordsB.index(wordsA[i]) - i)\n",
    "        except:\n",
    "            pass\n",
    "    # DEBUGGING:\n",
    "    for i, offset in enumerate(offsets):\n",
    "        print (listA[i], listB[i + offset])\n",
    "    # DEBUGGING\n",
    "    return int(np.median(offsets))\n",
    "\n",
    "offsetN = 10\n",
    "offsetM = 100\n",
    "offset = calculate_offset(html, pdf, offsetN, offsetM)\n",
    "\n",
    "print \"Offset: %d\" % int(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((0, 'ztwfo'), (0, 'ztwfo')),\n",
      " ((1, 'dyborct'), (1, 'dyborct')),\n",
      " ((2, 'mthucbw'), (2, 'mthucbw')),\n",
      " ((3, 'arobnghel'), (3, 'arobnghel')),\n",
      " ((None, 'acw'), (None, 'gevb')),\n",
      " ((5, 'kmgxeszhyl'), (5, 'kmgxeszhyl')),\n",
      " ((6, 'mrnacdy'), (6, 'mrnacdy')),\n",
      " ((7, 'vnbeah'), (7, 'vnbeah')),\n",
      " ((None, 'hykvlr'), (None, 'pegajqlokz')),\n",
      " ((9, 'ixp'), (9, 'ixp'))]\n",
      "[((10, 'qnd'), (10, 'qnd')),\n",
      " ((11, 'vmpnct'), (11, 'vmpnct')),\n",
      " ((None, 'pctrnl'), (None, 'raqyuxv')),\n",
      " ((13, 'waucxiepr'), (13, 'waucxiepr')),\n",
      " ((14, 'qcivfg'), (14, 'qcivfg')),\n",
      " ((15, 'ykm'), (15, 'ykm')),\n",
      " ((16, 'buzyfhxi'), (16, 'buzyfhxi')),\n",
      " ((17, 'krtc'), (17, 'krtc')),\n",
      " ((18, 'usr'), (18, 'usr')),\n",
      " ((19, 'wtngsrzh'), (19, 'wtngsrzh'))]\n",
      "[((20, 'dbhpgwu'), (20, 'dbhpgwu')),\n",
      " ((21, 'jozcehudg'), (21, 'jozcehudg')),\n",
      " ((22, 'xrfiwgqlm'), (22, 'xrfiwgqlm')),\n",
      " ((23, 'ckgrp'), (23, 'ckgrp')),\n",
      " ((24, 'xoqjuwrnbh'), (24, 'xoqjuwrnbh')),\n",
      " ((25, 'tjzlpxvwh'), (25, 'tjzlpxvwh')),\n",
      " ((None, 'onvy'), (None, 'xoiykbj')),\n",
      " ((27, 'xweir'), (27, 'xweir')),\n",
      " ((28, 'ejbodgas'), (28, 'ejbodgas')),\n",
      " ((29, 'kjr'), (29, 'kjr'))]\n",
      "[((30, 'qzpxyesn'), (30, 'qzpxyesn')),\n",
      " ((31, 'wotdvnmyek'), (31, 'wotdvnmyek')),\n",
      " ((32, 'zhpuq'), (32, 'zhpuq')),\n",
      " ((33, 'zfwanuo'), (33, 'zfwanuo')),\n",
      " ((34, 'cmd'), (34, 'cmd')),\n",
      " ((35, 'cqmoyuht'), (35, 'cqmoyuht')),\n",
      " ((36, 'uhobdnx'), (36, 'uhobdnx')),\n",
      " ((37, 'afto'), (37, 'afto')),\n",
      " ((38, 'eflty'), (38, 'eflty')),\n",
      " ((39, 'thp'), (39, 'thp'))]\n",
      "[((40, 'przctshw'), (40, 'przctshw')),\n",
      " ((41, 'dfcxy'), (41, 'dfcxy')),\n",
      " ((42, 'jiy'), (42, 'jiy')),\n",
      " ((43, 'ywcrpd'), (43, 'ywcrpd')),\n",
      " ((44, 'yurlz'), (44, 'yurlz')),\n",
      " ((45, 'dnq'), (45, 'dnq')),\n",
      " ((46, 'kyepxigc'), (46, 'kyepxigc')),\n",
      " ((47, 'renbohmsj'), (47, 'renbohmsj')),\n",
      " ((48, 'tiacgdzlhv'), (48, 'tiacgdzlhv')),\n",
      " ((49, 'wfcji'), (49, 'wfcji'))]\n",
      "[((50, 'mizoy'), (50, 'mizoy')),\n",
      " ((51, 'mjxzidro'), (51, 'mjxzidro')),\n",
      " ((52, 'egfc'), (52, 'egfc')),\n",
      " ((53, 'pyfutldhb'), (53, 'pyfutldhb')),\n",
      " ((54, 'mlbjf'), (54, 'mlbjf')),\n",
      " ((55, 'pmotl'), (55, 'pmotl')),\n",
      " ((56, 'cbzvdnr'), (56, 'cbzvdnr')),\n",
      " ((57, 'yncwofh'), (57, 'yncwofh')),\n",
      " ((58, 'tqdoljcf'), (58, 'tqdoljcf')),\n",
      " ((59, 'smpf'), (59, 'smpf'))]\n",
      "[((60, 'mwz'), (60, 'mwz')),\n",
      " ((61, 'apzw'), (61, 'apzw')),\n",
      " ((62, 'jtyw'), (62, 'jtyw')),\n",
      " ((63, 'mnjkegwycu'), (63, 'mnjkegwycu')),\n",
      " ((64, 'fnjbwylg'), (64, 'fnjbwylg')),\n",
      " ((65, 'diof'), (65, 'diof')),\n",
      " ((66, 'rwzlu'), (66, 'rwzlu')),\n",
      " ((67, 'humd'), (67, 'humd')),\n",
      " ((68, 'pmbud'), (68, 'pmbud')),\n",
      " ((69, 'uclsiwy'), (69, 'uclsiwy'))]\n",
      "[((70, 'agmky'), (70, 'agmky')),\n",
      " ((71, 'tixrbc'), (71, 'tixrbc')),\n",
      " ((72, 'amorvngsb'), (72, 'amorvngsb')),\n",
      " ((73, 'wtsarzlc'), (73, 'wtsarzlc')),\n",
      " ((74, 'axlsk'), (74, 'axlsk')),\n",
      " ((75, 'wcmfvs'), (75, 'wcmfvs')),\n",
      " ((76, 'qelp'), (76, 'qelp')),\n",
      " ((77, 'ruzqsclw'), (77, 'ruzqsclw')),\n",
      " ((78, 'prfld'), (78, 'prfld')),\n",
      " ((None, 'yxgncw'), (None, 'rpkmtxcb'))]\n",
      "[((80, 'bdgm'), (80, 'bdgm')),\n",
      " ((81, 'xfbkzgvdo'), (81, 'xfbkzgvdo')),\n",
      " ((82, 'wxuiycap'), (82, 'wxuiycap')),\n",
      " ((83, 'ztn'), (83, 'ztn')),\n",
      " ((84, 'ipytab'), (84, 'ipytab')),\n",
      " ((85, 'cbxkfiwa'), (85, 'cbxkfiwa')),\n",
      " ((86, 'lxtdjgn'), (86, 'lxtdjgn')),\n",
      " ((87, 'dmj'), (87, 'dmj')),\n",
      " ((88, 'lehzujikc'), (88, 'lehzujikc')),\n",
      " ((89, 'zhwvxponj'), (89, 'zhwvxponj'))]\n",
      "[((90, 'ltojgrdb'), (90, 'ltojgrdb')),\n",
      " ((91, 'hswrdcyvum'), (91, 'hswrdcyvum')),\n",
      " ((92, 'hsc'), (92, 'hsc')),\n",
      " ((93, 'asfno'), (93, 'asfno')),\n",
      " ((94, 'fpmwl'), (94, 'fpmwl')),\n",
      " ((95, 'fuy'), (95, 'fuy')),\n",
      " ((96, 'pjqynl'), (96, 'pjqynl')),\n",
      " ((97, 'nmxvypsuz'), (97, 'nmxvypsuz')),\n",
      " ((98, 'vtjug'), (98, 'vtjug')),\n",
      " ((99, 'hbnusig'), (99, 'hbnusig'))]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# define costs\n",
    "index_dist_cost = 1\n",
    "edit_dist_cost = 50\n",
    "\n",
    "N = 100\n",
    "M = 120\n",
    "W = 10\n",
    "scale = 1\n",
    "offset = 0\n",
    "for i in range(N/W + 1):\n",
    "    wordsA = html[max(i*W,0):min((i+1)*W,N)]\n",
    "    wordsB = pdf[max(i*W - W*(scale-1) + offset, 0):min((i+1)*W + W*(scale-1) + offset, M)]\n",
    "    pprint(zip(wordsA, wordsB))\n",
    "    \n",
    "\n",
    "# start_html = html[:10]\n",
    "# start_pdf  = pdf[:10]\n",
    "\n",
    "# NOTE: pre-generate offset matrix once\n",
    "# NOTE: base matrix size on W, not len(html)\n",
    "\n",
    "# # start with index distances \n",
    "# x = np.arange(len(start_html))\n",
    "# y = np.arange(len(start_pdf))\n",
    "# xx, yy = np.meshgrid(x,y)\n",
    "# X = (abs(xx - yy) + yy * .01) * index_dist_cost\n",
    "\n",
    "# # add edit distances\n",
    "# for i, a in enumerate(start_html):\n",
    "#     for j, b in enumerate(start_pdf):\n",
    "#         X[i,j] += editdist(a[1], b[1]) * edit_dist_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# row_ind, col_ind = hungarian(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 ms, sys: 3.91 ms, total: 170 ms\n",
      "Wall time: 208 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.random.rand(10,100)\n",
    "for _ in range(400):\n",
    "    hungarian(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_html = [html[row_ind[i]] for i in range(N)]\n",
    "new_pdf = [pdf[col_ind[i]] for i in range(N)]\n",
    "\n",
    "# partial = sum([(new_html[i] != new_pdf[i] and\n",
    "#               (new_html[i].startswith(new_pdf[i]) or\n",
    "#                new_pdf[i].startswith(new_html[i]))) for i in range(N)])\n",
    "# print \"Duplicate: %s\" % ?\n",
    "# print \"Partial:   %f\" % partial/N\n",
    "# print \"Mismatch:  %f\" % sum([new_html[i] != new_pdf[i] for i in range(N)]) - partial\n",
    "\n",
    "print \"Aligned:   %s\" % sum([new_html[i][0] == new_pdf[i][0] for i in range(N)])\n",
    "\n",
    "for i in xrange(len(row_ind)):\n",
    "    print html[row_ind[i]], pdf[col_ind[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sum([html[row_ind[i]] == pdf[col_ind[i]] for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
