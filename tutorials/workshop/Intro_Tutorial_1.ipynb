{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Intro. to Snorkel: Extracting Spouse Relations from the News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part I: Preprocessing\n",
    "\n",
    "In this tutorial, we will walk through the process of using `Snorkel` to identify mentions of spouses in a corpus of news articles. The tutorial is broken up into 5 notebooks, each covering a step in the pipeline:\n",
    "1. Preprocessing\n",
    "2. Candidate Extraction\n",
    "3. Annotating Evaluation Data\n",
    "4. Featurization & Training\n",
    "5. Evaluation\n",
    "\n",
    "In this notebook, we preprocess several documents using `Snorkel` utilities, parsing them into a simple hierarchy of component parts of our input data, which we refer to as _contexts_. We also extract standard linguistic features from each context which will be useful downstream using [CoreNLP](http://stanfordnlp.github.io/CoreNLP/), \n",
    "\n",
    "All of this preprocessed input data is saved to a database.  (Connection strings can be specified by setting the `SNORKELDB` environment variable.  In Snorkel, if no database is specified, then a SQLite database at `./snorkel.db` is created by default--so no setup is needed here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Initializing a `SnorkelSession`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, we initialize a `SnorkelSession`, which manages a connection to a database automatically for us, and will enable us to save intermediate results.  If we don't specify any particular database (see commented-out code below), then it will automatically create a SQLite database in the background for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# TO USE A DATABASE OTHER THAN SQLITE, USE THIS LINE\n",
    "# Note that this is necessary for parallel execution amongst other things...\n",
    "# os.environ['SNORKELDB'] = 'postgres:///snorkel-intro'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Here, we just set a global variable related to automatic testing- you can safely ignore this!\n",
    "max_docs = 50 if 'CI' in os.environ else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading the Corpus\n",
    "\n",
    "Next, we load and pre-process the corpus of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Configuring a `DocPreprocessor`\n",
    "\n",
    "We'll start by defining a `TSVDocPreprocessor` class to read in the documents, which are stored in a tab-seperated value format as pairs of document names and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import codecs\n",
    "# rows = []\n",
    "# with codecs.open(\"data/articles.tsv\",\"rU\",\"utf-8\") as fp:\n",
    "#     for line in fp:\n",
    "#         row = line.split(\"\\t\")\n",
    "#         doc = row[1]\n",
    "#         doc = doc.replace(\"\\\\n\",\"\\n\")\n",
    "#         doc = doc.replace('\"\"','\"')\n",
    "#         sents = [s.strip() for s in doc.split(\"\\n\") if len(s.strip()) > 0]\n",
    "#         rows.append([row[0],\" \".join(sents)])\n",
    "\n",
    "# with codecs.open(\"data/articles4.tsv\",\"w\",\"utf-8\") as fp:\n",
    "#     for r in rows:\n",
    "#         fp.write(\"\\t\".join(r) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TSVDocPreprocessor\n",
    "\n",
    "doc_preprocessor = TSVDocPreprocessor('data/articles.tsv', max_docs=max_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Running a `CorpusParser`\n",
    "\n",
    "We'll use an NLP preprocessing tool to split our documents into sentences, tokens, and provide annotations---part-of-speech tags, dependency parse structure, lemmatized word forms, named entities, etc.---for these sentences.\n",
    "\n",
    "Let's run it single-threaded first; **note that this may take around 10 minutes depending on your machine**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.contrib.parser import *\n",
    "#parser = RuleBasedParser()\n",
    "#parser = Spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 1min 55s, sys: 2.9 s, total: 1min 58s\n",
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "corpus_parser = CorpusParser()\n",
    "%time corpus_parser.apply(doc_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can then use simple database queries (written in the syntax of [SQLAlchemy](http://www.sqlalchemy.org/), which Snorkel uses) to check how many documents and sentences were parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Documents:', 997)\n",
      "('Sentences:', 28985)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'The', u'Duke', u'of', u'Cambridge', u'has', u'thrown', u'his', u'support', u'behind', u'an', u'organisation', u\"'s\", u'fight', u'against', u'bullying', u'-', u'and', u'listed', u'an', u'enviable', u'support', u'network', u'.']\n",
      "The Duke of Cambridge has thrown his support behind an organisation's fight against bullying - and listed an enviable support network.\n",
      "[u'O', u'ORGANIZATION', u'O', u'LOCATION', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nWilliam', u'wrote', u'down', u'Catherine', u',', u'Harry', u',', u'father', u',', u'grandmother', u',', u'grandfather', u'and', u'an', u'extra', u'-', u'his', u'dog', u'Lupo', u'-', u'when', u'he', u'joined', u'a', u'Diana', u'Fund', u'trainee', u'session', u'for', u'anti-bullying', u'ambassadors', u'.']\n",
      "\\n \\nWilliam wrote down Catherine, Harry, father, grandmother, grandfather and an extra - his dog Lupo - when he joined a Diana Fund trainee session for anti-bullying ambassadors.\n",
      "[u'O', u'O', u'O', u'O', u'O', u'O', u'PERSON', u'O', u'PERSON', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'PERSON', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nFifty', u'youngsters', u'from', u'across', u'the', u'country', u'were', u'set', u'the', u'``', u'high', u'five', u\"''\", u'task', u'of', u'naming', u'five', u'people', u'they', u'would', u'turn', u'to', u'for', u'help', u'with', u'verbal', u',', u'physical', u'or', u'cyber', u'abuse', u'.']\n",
      "\\n \\nFifty youngsters from across the country were set the \"high five\" task of naming five people they would turn to for help with verbal, physical or cyber abuse.\n",
      "[u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nThe', u'Duke', u'was', u'given', u'a', u'large', u'cardboard', u'hand', u'to', u'fill', u'in', u'and', u'named', u'his', u'immediate', u'family', u'-', u'better', u'known', u'as', u'wife', u'Kate', u',', u'Prince', u'Harry', u',', u'the', u'Prince', u'of', u'Wales', u',', u'the', u'Queen', u'and', u'the', u'Duke', u'of', u'Edinburgh', u'-', u'before', u'signing', u'the', u'palm', u'with', u'his', u'name', u'.']\n",
      "\\n \\nThe Duke was given a large cardboard hand to fill in and named his immediate family - better known as wife Kate, Prince Harry, the Prince of Wales, the Queen and the Duke of Edinburgh - before signing the palm with his name.\n",
      "[u'O', u'O', u'NUMBER', u'O', u'PERSON', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'PERSON', u'O', u'O', u'PERSON', u'O', u'O', u'LOCATION', u'LOCATION', u'LOCATION', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'LOCATION', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nWhen', u'William', u'joined', u'a', u'group', u'discussing', u'LGBT', '(', u'lesbian', u',', u'gay', u',', u'bisexual', u',', u'and', u'transgender', ')', u'issues', u',', u'they', u'were', u'asked', u'how', u'they', u'would', u'react', u'to', u'homophobic', u'bullying', u',', u'and', u'the', u'Duke', u'indicated', u'he', u'would', u'confront', u'those', u'behind', u'any', u'comments', u'and', u'comfort', u'the', u'victims', u'.']\n",
      "\\n \\nWhen William joined a group discussing LGBT (lesbian, gay, bisexual, and transgender) issues, they were asked how they would react to homophobic bullying, and the Duke indicated he would confront those behind any comments and comfort the victims.\n",
      "[u'O', u'O', u'NUMBER', u'O', u'PERSON', u'O', u'O', u'O', u'O', u'MISC', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nThe', u'youngsters', u'were', u'asked', u'to', u'move', u'to', u'one', u'side', u'if', u'they', u'would', u'support', u'the', u'victim', u',', u'another', u'to', u'confront', u'the', u'perpetrator', u'and', u'stay', u'in', u'the', u'middle', u'for', u'another', u'course', u'of', u'action', u'.']\n",
      "\\n \\nThe youngsters were asked to move to one side if they would support the victim, another to confront the perpetrator and stay in the middle for another course of action.\n",
      "[u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nWilliam', u'joined', u'the', u'confront', u'group', u'but', u'indicated', u'he', u'would', u'have', u'started', u'at', u'the', u'comfort', u'side', u':', u'``', u'I', u'would', u'start', u'on', u'that', u'side', u'and', u'end', u'up', u'here', u'.', u\"''\"]\n",
      "\\n \\nWilliam joined the confront group but indicated he would have started at the comfort side:  \"I would start on that side and end up here.\"\n",
      "[u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nA', u'student', u'had', u'told', u'the', u'group', u'he', u'would', u'confront', u'the', u'homophobic', u'bully', u'and', u'the', u'Duke', u'echoed', u'his', u'words', u':', u'``', u'As', u'the', u'young', u'man', u'said', u',', u'I', u'would', u'try', u'to', u'confront', u'.', u\"''\"]\n",
      "\\n \\nA student had told the group he would confront the homophobic bully and the Duke echoed his words: \"As the young man said, I would try to confront.\"\n",
      "[u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'PERSON', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'n', u'Share', u'article', u'\\\\', u'n', u'\\\\', u'nThe', u'Diana', u'Award', u\"'s\", u'nationwide', u'Anti-Bullying', u'Ambassadors', u'programme', u'has', u'been', u'running', u'for', u'a', u'number', u'of', u'years', u'and', u'has', u'more', u'than', u'16,000', u'ambassadors', u'-', u'mostly', u'students', u'-', u'supporting', u'pupils', u'in', u'3,000', u'schools', u'across', u'the', u'UK', u'and', u'Ireland', u'.']\n",
      "\\n   \\n Share article  \\n   \\nThe Diana Award's nationwide Anti-Bullying Ambassadors programme has been running for a number of years and has more than 16,000 ambassadors - mostly students - supporting pupils in 3,000 schools across the UK and Ireland.\n",
      "[u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'NUMBER', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'DURATION', u'O', u'O', u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'LOCATION', u'O', u'LOCATION', u'O']\n",
      "[u'\\\\', u'n', u'\\\\', u'nThe', u'Diana', u'Award', u'backs', u'the', u'Princess', u'of', u'Wales', u\"'s\", u'belief', u'that', u'young', u'people', u'have', u'the', u'power', u'to', u'change', u'the', u'world', u'for', u'the', u'better', u'and', u'is', u'committed', u'to', u'empowering', u'them', u'to', u'tackle', u'social', u'issues', u'affecting', u'their', u'peer', u'group', u'.']\n",
      "\\n \\nThe Diana Award backs the Princess of Wales's belief that young people have the power to change the world for the better and is committed to empowering them to tackle social issues affecting their peer group.\n",
      "[u'O', u'O', u'NUMBER', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'LOCATION', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O', u'O']\n"
     ]
    }
   ],
   "source": [
    "documents = session.query(Document).all()\n",
    "\n",
    "for doc in documents:\n",
    "    for sent in doc.sentences:\n",
    "        print sent.words\n",
    "        print sent.text\n",
    "        print sent.ner_tags\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Running in parallel\n",
    "\n",
    "Note that any time we execute a `UDFRunner` like `CorpusParser`, we can also execute it in parallel by running e.g.:\n",
    "```python\n",
    "corpus_parser.apply(doc_preprocessor, parallelism=20)\n",
    "```\n",
    "**Note, however, that this parallel execution will not work with SQLite, the database system used by default**; you will need to use e.g. Postgres for this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, in Part 2, we will look at how to extract `Candidate` relations from our saved corpus."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
