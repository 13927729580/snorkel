{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel Workshop: Extracting Spouse Relations from the News\n",
    "\n",
    "## Part 4: Training our End Extraction Model\n",
    "\n",
    "In this final section of the tutorial, we'll use the noisy training labels we generated in the last tutorial part to train our end extraction model.\n",
    "\n",
    "For this tutorial, we will be training a simple - but fairly effective - logistic regression model.  More generally, however, Snorkel plugs in with many ML libraries including [TensorFlow](https://www.tensorflow.org/), making it easy to use almost any state-of-the-art model as the end extractor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "from lib.init import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our definition of the `Spouse` `Candidate` subclass, and load the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the training marginals to train a discriminative model that classifies each `Candidate` as a true or false mention. We'll use a random hyperparameter search, evaluated on the development set labels, to find the best hyperparameters for our model. To run a hyperparameter search, we need labels for a development set. If they aren't already available, we can manually create labels using the Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cands = session.query(Spouse).filter(Spouse.split == 0).order_by(Spouse.id).all()\n",
    "dev_cands   = session.query(Spouse).filter(Spouse.split == 1).order_by(Spouse.id).all()\n",
    "test_cands  = session.query(Spouse).filter(Spouse.split == 2).order_by(Spouse.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, load_as_array=True, zero_one=True)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Training model\n",
      "[reRNN] n_train=17217  #epochs=20  batch size=256\n",
      "[reRNN] Epoch 0 (40.25s)\tAverage loss=0.582597\tDev F1=13.55\n",
      "[reRNN] Epoch 1 (84.93s)\tAverage loss=0.542717\tDev F1=33.33\n",
      "[reRNN] Epoch 2 (132.68s)\tAverage loss=0.537067\tDev F1=35.32\n",
      "[reRNN] Epoch 3 (178.95s)\tAverage loss=0.536432\tDev F1=37.55\n",
      "[reRNN] Epoch 4 (223.45s)\tAverage loss=0.535999\tDev F1=34.89\n",
      "[reRNN] Epoch 5 (268.81s)\tAverage loss=0.535783\tDev F1=37.27\n",
      "[reRNN] Epoch 6 (315.81s)\tAverage loss=0.535106\tDev F1=37.78\n",
      "[reRNN] Epoch 7 (360.98s)\tAverage loss=0.535300\tDev F1=37.94\n",
      "[reRNN] Epoch 8 (407.18s)\tAverage loss=0.535028\tDev F1=38.80\n",
      "[reRNN] Epoch 9 (454.38s)\tAverage loss=0.535006\tDev F1=39.16\n",
      "[reRNN] Epoch 10 (500.35s)\tAverage loss=0.534756\tDev F1=39.64\n",
      "[reRNN] Epoch 11 (549.25s)\tAverage loss=0.534703\tDev F1=40.47\n",
      "[reRNN] Epoch 12 (597.67s)\tAverage loss=0.534757\tDev F1=39.57\n",
      "[reRNN] Epoch 13 (651.31s)\tAverage loss=0.534573\tDev F1=40.76\n",
      "[reRNN] Model saved as <reRNN>\n",
      "[reRNN] Epoch 14 (702.29s)\tAverage loss=0.534339\tDev F1=40.60\n",
      "[reRNN] Epoch 15 (747.53s)\tAverage loss=0.534251\tDev F1=40.97\n",
      "[reRNN] Model saved as <reRNN>\n",
      "[reRNN] Epoch 16 (794.97s)\tAverage loss=0.534396\tDev F1=41.83\n",
      "[reRNN] Model saved as <reRNN>\n",
      "[reRNN] Epoch 17 (844.44s)\tAverage loss=0.534240\tDev F1=42.74\n",
      "[reRNN] Model saved as <reRNN>\n",
      "[reRNN] Epoch 18 (895.49s)\tAverage loss=0.534174\tDev F1=40.54\n",
      "[reRNN] Epoch 19 (942.43s)\tAverage loss=0.534317\tDev F1=42.41\n",
      "[reRNN] Training done (945.12s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/reRNN/reRNN-17\n",
      "[reRNN] Loaded model <reRNN>\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.001,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   20,\n",
    "    'dropout':    0.5,\n",
    "    'print_freq': 1,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the precision, recall, and F1 score from the discriminative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.384, Recall: 0.606, F1 Score: 0.470\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the candidates returned in sets (true positives, false positives, true negatives, false negatives) as well as a more detailed score report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.606\n",
      "Neg. class accuracy: 0.915\n",
      "Precision            0.384\n",
      "Recall               0.606\n",
      "F1                   0.47\n",
      "----------------------------------------\n",
      "TP: 132 | FP: 212 | TN: 2271 | FN: 86\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save our model for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Model saved as <best.lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(\"spouse.lstm\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
