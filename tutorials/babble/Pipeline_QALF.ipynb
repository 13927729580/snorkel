{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'spouse',\n",
    "    'supervision': 'majority',\n",
    "#     'learn_deps': False,\n",
    "#     'gen_model_search_space': 1,\n",
    "#     'gen_init_params': {\n",
    "#         'lf_propensity'         : True,\n",
    "#         'class_prior'           : True,\n",
    "#         'lf_class_propensity'   : True,\n",
    "#         'seed'                  : None,\n",
    "#     },\n",
    "#     'gen_params_default': {\n",
    "#         'step_size'     : 0.0001,\n",
    "#         'decay'         : 0.90,\n",
    "#         'reg_param'     : 0.50,\n",
    "#         'epochs'        : 25,\n",
    "#     },    \n",
    "    'disc_model_class': 'logreg',    \n",
    "    'disc_model_search_space': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_spouse.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting domain=None to domain=spouse\n",
      "Overwriting print_freq=1 to print_freq=5\n",
      "Overwriting LF_acc_prior_weight_default=1.0 to LF_acc_prior_weight_default=0.5\n",
      "Overwriting decay=0.95 to decay=0.99\n",
      "Overwriting init_class_prior=0 to init_class_prior=-1.15\n",
      "Overwriting reg_param=0.1 to reg_param=0.5\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting supervision=generative to supervision=majority\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 446 ms, total: 19.8 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "from tutorials.babble.spouse.spouse_qalf import QalfConverter\n",
    "\n",
    "qc = QalfConverter(session, pipe.candidate_class)\n",
    "fpath = (os.environ['SNORKELHOME'] + \n",
    "    '/tutorials/babble/spouse/data/qalf_matrix_hp.tsv')\n",
    "L_train, L_dev, L_test = qc.convert(fpath)\n",
    "\n",
    "pipe.L_train = L_train\n",
    "pipe.L_dev = L_dev\n",
    "pipe.L_test = L_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L_train: <22195x24 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 9463 stored elements in Compressed Sparse Row format>\n",
      "Using L_gold_train: <22195x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 22195 stored elements in Compressed Sparse Row format>\n",
      "Positive Fraction: 7.0%\n",
      "\n",
      "Using L_dev: <2796x24 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 1250 stored elements in Compressed Sparse Row format>\n",
      "Using L_gold_dev: <2796x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 2796 stored elements in Compressed Sparse Row format>\n",
      "Positive Fraction: 7.0%\n",
      "\n",
      "Using L_test: <2697x24 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 1198 stored elements in Compressed Sparse Row format>\n",
      "Using L_gold_test: <2697x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 2697 stored elements in Compressed Sparse Row format>\n",
      "Positive Fraction: 8.3%\n",
      "\n",
      "Saved 22195 marginals\n",
      "CPU times: user 1.98 s, sys: 57.9 ms, total: 2.03 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22195,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngPYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105d58350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### [7.1] Begin training discriminative model\n",
      "============================================================\n",
      "[1] Testing dim = 64, dropout = 2.50e-01, batch_size = 64, n_epochs = 50, lr = 1.00e-03, rebalance = 2.50e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=5388  #epochs=50  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (0.55s)\tAverage loss=0.619325\tDev F1=16.37\n",
      "[SparseLogisticRegression] Epoch 5 (3.53s)\tAverage loss=0.207024\tDev F1=43.90\n",
      "[SparseLogisticRegression] Epoch 10 (6.44s)\tAverage loss=0.125583\tDev F1=45.19\n",
      "[SparseLogisticRegression] Epoch 15 (9.33s)\tAverage loss=0.087903\tDev F1=45.11\n",
      "[SparseLogisticRegression] Epoch 20 (12.23s)\tAverage loss=0.065986\tDev F1=45.26\n",
      "[SparseLogisticRegression] Epoch 25 (15.15s)\tAverage loss=0.051135\tDev F1=44.60\n",
      "[SparseLogisticRegression] Epoch 30 (18.11s)\tAverage loss=0.041605\tDev F1=45.61\n",
      "[SparseLogisticRegression] Epoch 35 (21.08s)\tAverage loss=0.032945\tDev F1=45.71\n",
      "[SparseLogisticRegression] Epoch 40 (24.08s)\tAverage loss=0.027062\tDev F1=45.82\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 45 (27.32s)\tAverage loss=0.022305\tDev F1=46.19\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 49 (30.02s)\tAverage loss=0.019482\tDev F1=45.75\n",
      "[SparseLogisticRegression] Training done (30.17s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.461904761905\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "============================================================\n",
      "[2] Testing dim = 128, dropout = 5.00e-01, batch_size = 16, n_epochs = 100, lr = 1.00e-03, rebalance = 2.50e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=5388  #epochs=100  batch size=16\n",
      "[SparseLogisticRegression] Epoch 0 (1.05s)\tAverage loss=0.563659\tDev F1=26.14\n",
      "[SparseLogisticRegression] Epoch 5 (6.30s)\tAverage loss=0.125365\tDev F1=46.46\n",
      "[SparseLogisticRegression] Epoch 10 (11.53s)\tAverage loss=0.063785\tDev F1=46.63\n",
      "[SparseLogisticRegression] Epoch 15 (16.79s)\tAverage loss=0.037206\tDev F1=46.15\n",
      "[SparseLogisticRegression] Epoch 20 (21.99s)\tAverage loss=0.023063\tDev F1=45.18\n",
      "[SparseLogisticRegression] Epoch 25 (27.39s)\tAverage loss=0.014692\tDev F1=45.43\n",
      "[SparseLogisticRegression] Epoch 30 (32.85s)\tAverage loss=0.009583\tDev F1=44.40\n",
      "[SparseLogisticRegression] Epoch 35 (38.28s)\tAverage loss=0.006383\tDev F1=44.40\n",
      "[SparseLogisticRegression] Epoch 40 (43.77s)\tAverage loss=0.004323\tDev F1=44.01\n",
      "[SparseLogisticRegression] Epoch 45 (49.08s)\tAverage loss=0.002977\tDev F1=41.79\n",
      "[SparseLogisticRegression] Epoch 50 (54.63s)\tAverage loss=0.002046\tDev F1=41.26\n",
      "[SparseLogisticRegression] Epoch 55 (60.03s)\tAverage loss=0.001417\tDev F1=40.58\n",
      "[SparseLogisticRegression] Epoch 60 (65.81s)\tAverage loss=0.001014\tDev F1=39.76\n",
      "[SparseLogisticRegression] Epoch 65 (71.20s)\tAverage loss=0.000718\tDev F1=39.20\n",
      "[SparseLogisticRegression] Epoch 70 (76.69s)\tAverage loss=0.000514\tDev F1=39.04\n",
      "[SparseLogisticRegression] Epoch 75 (81.90s)\tAverage loss=0.000379\tDev F1=38.89\n",
      "[SparseLogisticRegression] Epoch 80 (87.38s)\tAverage loss=0.000273\tDev F1=38.34\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 85 (93.06s)\tAverage loss=0.000204\tDev F1=36.95\n",
      "[SparseLogisticRegression] Epoch 90 (98.31s)\tAverage loss=0.000152\tDev F1=36.70\n",
      "[SparseLogisticRegression] Epoch 95 (103.60s)\tAverage loss=0.000112\tDev F1=36.36\n",
      "[SparseLogisticRegression] Epoch 99 (107.87s)\tAverage loss=0.000089\tDev F1=36.46\n",
      "[SparseLogisticRegression] Training done (108.08s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.383399209486\n",
      "============================================================\n",
      "[3] Testing dim = 128, dropout = 1.00e-01, batch_size = 32, n_epochs = 25, lr = 1.00e-02, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=2694  #epochs=25  batch size=32\n",
      "[SparseLogisticRegression] Epoch 0 (0.35s)\tAverage loss=0.599716\tDev F1=37.93\n",
      "[SparseLogisticRegression] Epoch 5 (2.19s)\tAverage loss=0.031418\tDev F1=35.23\n",
      "[SparseLogisticRegression] Epoch 10 (4.03s)\tAverage loss=0.012666\tDev F1=33.87\n",
      "[SparseLogisticRegression] Epoch 15 (5.89s)\tAverage loss=0.007272\tDev F1=34.22\n",
      "[SparseLogisticRegression] Epoch 20 (7.75s)\tAverage loss=0.003627\tDev F1=33.33\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 24 (9.57s)\tAverage loss=0.002678\tDev F1=33.33\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (10.08s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.333333333333\n",
      "============================================================\n",
      "[4] Testing dim = 64, dropout = 5.00e-01, batch_size = 32, n_epochs = 100, lr = 1.00e-04, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=2694  #epochs=100  batch size=32\n",
      "[SparseLogisticRegression] Epoch 0 (0.34s)\tAverage loss=0.781671\tDev F1=11.69\n",
      "[SparseLogisticRegression] Epoch 5 (2.18s)\tAverage loss=0.641214\tDev F1=14.12\n",
      "[SparseLogisticRegression] Epoch 10 (4.06s)\tAverage loss=0.541698\tDev F1=16.07\n",
      "[SparseLogisticRegression] Epoch 15 (5.87s)\tAverage loss=0.466687\tDev F1=17.55\n",
      "[SparseLogisticRegression] Epoch 20 (7.71s)\tAverage loss=0.410367\tDev F1=19.25\n",
      "[SparseLogisticRegression] Epoch 25 (9.58s)\tAverage loss=0.364472\tDev F1=20.70\n",
      "[SparseLogisticRegression] Epoch 30 (11.39s)\tAverage loss=0.326940\tDev F1=21.40\n",
      "[SparseLogisticRegression] Epoch 35 (13.19s)\tAverage loss=0.294986\tDev F1=23.14\n",
      "[SparseLogisticRegression] Epoch 40 (15.00s)\tAverage loss=0.268808\tDev F1=24.16\n",
      "[SparseLogisticRegression] Epoch 45 (16.84s)\tAverage loss=0.245921\tDev F1=25.44\n",
      "[SparseLogisticRegression] Epoch 50 (18.68s)\tAverage loss=0.225459\tDev F1=25.98\n",
      "[SparseLogisticRegression] Epoch 55 (20.59s)\tAverage loss=0.208585\tDev F1=26.81\n",
      "[SparseLogisticRegression] Epoch 60 (22.51s)\tAverage loss=0.195127\tDev F1=27.65\n",
      "[SparseLogisticRegression] Epoch 65 (24.44s)\tAverage loss=0.180673\tDev F1=28.45\n",
      "[SparseLogisticRegression] Epoch 70 (26.31s)\tAverage loss=0.167627\tDev F1=29.12\n",
      "[SparseLogisticRegression] Epoch 75 (28.36s)\tAverage loss=0.158762\tDev F1=29.43\n",
      "[SparseLogisticRegression] Epoch 80 (30.28s)\tAverage loss=0.145867\tDev F1=29.87\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 85 (32.55s)\tAverage loss=0.137812\tDev F1=30.37\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 90 (34.87s)\tAverage loss=0.128784\tDev F1=30.25\n",
      "[SparseLogisticRegression] Epoch 95 (36.69s)\tAverage loss=0.120867\tDev F1=30.83\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 99 (38.55s)\tAverage loss=0.115464\tDev F1=31.19\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (39.21s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.311881188119\n",
      "============================================================\n",
      "[5] Testing dim = 128, dropout = 1.00e-01, batch_size = 32, n_epochs = 25, lr = 1.00e-02, rebalance = 0.00e+00\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=22195  #epochs=25  batch size=32\n",
      "[SparseLogisticRegression] Epoch 0 (2.86s)\tAverage loss=0.253826\tDev F1=40.99\n",
      "[SparseLogisticRegression] Epoch 5 (17.49s)\tAverage loss=0.038396\tDev F1=33.11\n",
      "[SparseLogisticRegression] Epoch 10 (32.95s)\tAverage loss=0.023117\tDev F1=34.73\n",
      "[SparseLogisticRegression] Epoch 15 (48.34s)\tAverage loss=0.020392\tDev F1=35.47\n",
      "[SparseLogisticRegression] Epoch 20 (63.24s)\tAverage loss=0.014643\tDev F1=35.56\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 24 (75.55s)\tAverage loss=0.010489\tDev F1=36.75\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (76.19s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.367454068241\n",
      "============================================================\n",
      "[6] Testing dim = 128, dropout = 1.00e-01, batch_size = 32, n_epochs = 50, lr = 1.00e-04, rebalance = 2.50e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=5388  #epochs=50  batch size=32\n",
      "[SparseLogisticRegression] Epoch 0 (0.73s)\tAverage loss=0.803855\tDev F1=10.97\n",
      "[SparseLogisticRegression] Epoch 5 (4.29s)\tAverage loss=0.513445\tDev F1=14.60\n",
      "[SparseLogisticRegression] Epoch 10 (7.90s)\tAverage loss=0.412746\tDev F1=22.82\n",
      "[SparseLogisticRegression] Epoch 15 (11.59s)\tAverage loss=0.343185\tDev F1=30.45\n",
      "[SparseLogisticRegression] Epoch 20 (17.08s)\tAverage loss=0.291469\tDev F1=37.68\n",
      "[SparseLogisticRegression] Epoch 25 (29.18s)\tAverage loss=0.251616\tDev F1=40.46\n",
      "[SparseLogisticRegression] Epoch 30 (39.91s)\tAverage loss=0.220463\tDev F1=42.58\n",
      "[SparseLogisticRegression] Epoch 35 (51.13s)\tAverage loss=0.194281\tDev F1=44.26\n",
      "[SparseLogisticRegression] Epoch 40 (58.42s)\tAverage loss=0.173261\tDev F1=44.69\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 45 (63.65s)\tAverage loss=0.155769\tDev F1=44.62\n",
      "[SparseLogisticRegression] Epoch 49 (66.83s)\tAverage loss=0.144458\tDev F1=45.16\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (67.31s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.451612903226\n",
      "============================================================\n",
      "[7] Testing dim = 128, dropout = 1.00e-01, batch_size = 16, n_epochs = 50, lr = 1.00e-04, rebalance = 2.50e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=5388  #epochs=50  batch size=16\n",
      "[SparseLogisticRegression] Epoch 0 (1.05s)\tAverage loss=0.671764\tDev F1=12.87\n",
      "[SparseLogisticRegression] Epoch 5 (6.54s)\tAverage loss=0.440692\tDev F1=20.92\n",
      "[SparseLogisticRegression] Epoch 10 (11.95s)\tAverage loss=0.334052\tDev F1=35.50\n",
      "[SparseLogisticRegression] Epoch 15 (17.33s)\tAverage loss=0.264603\tDev F1=40.58\n",
      "[SparseLogisticRegression] Epoch 20 (22.75s)\tAverage loss=0.216961\tDev F1=45.00\n",
      "[SparseLogisticRegression] Epoch 25 (28.30s)\tAverage loss=0.182676\tDev F1=46.99\n",
      "[SparseLogisticRegression] Epoch 30 (33.61s)\tAverage loss=0.156868\tDev F1=47.57\n",
      "[SparseLogisticRegression] Epoch 35 (39.11s)\tAverage loss=0.136579\tDev F1=47.57\n",
      "[SparseLogisticRegression] Epoch 40 (44.47s)\tAverage loss=0.120397\tDev F1=48.40\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 45 (50.22s)\tAverage loss=0.107203\tDev F1=48.81\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 49 (55.08s)\tAverage loss=0.098313\tDev F1=47.89\n",
      "[SparseLogisticRegression] Training done (55.31s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.488063660477\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_6>\n",
      "============================================================\n",
      "[8] Testing dim = 128, dropout = 5.00e-01, batch_size = 32, n_epochs = 100, lr = 1.00e-02, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=2694  #epochs=100  batch size=32\n",
      "[SparseLogisticRegression] Epoch 0 (0.54s)\tAverage loss=0.587232\tDev F1=37.72\n",
      "[SparseLogisticRegression] Epoch 5 (7.34s)\tAverage loss=0.030624\tDev F1=35.61\n",
      "[SparseLogisticRegression] Epoch 10 (14.10s)\tAverage loss=0.012493\tDev F1=35.10\n",
      "[SparseLogisticRegression] Epoch 15 (19.02s)\tAverage loss=0.007287\tDev F1=35.71\n",
      "[SparseLogisticRegression] Epoch 20 (22.79s)\tAverage loss=0.003595\tDev F1=34.97\n",
      "[SparseLogisticRegression] Epoch 25 (26.15s)\tAverage loss=0.002446\tDev F1=34.99\n",
      "[SparseLogisticRegression] Epoch 30 (28.37s)\tAverage loss=0.001773\tDev F1=34.64\n",
      "[SparseLogisticRegression] Epoch 35 (30.49s)\tAverage loss=0.001294\tDev F1=34.40\n",
      "[SparseLogisticRegression] Epoch 40 (32.59s)\tAverage loss=0.000978\tDev F1=32.92\n",
      "[SparseLogisticRegression] Epoch 45 (34.71s)\tAverage loss=0.000730\tDev F1=32.95\n",
      "[SparseLogisticRegression] Epoch 50 (36.77s)\tAverage loss=0.000563\tDev F1=33.08\n",
      "[SparseLogisticRegression] Epoch 55 (38.84s)\tAverage loss=0.000443\tDev F1=32.49\n",
      "[SparseLogisticRegression] Epoch 60 (40.85s)\tAverage loss=0.000357\tDev F1=32.74\n",
      "[SparseLogisticRegression] Epoch 65 (42.93s)\tAverage loss=0.000280\tDev F1=32.74\n",
      "[SparseLogisticRegression] Epoch 70 (45.07s)\tAverage loss=0.000219\tDev F1=32.74\n",
      "[SparseLogisticRegression] Epoch 75 (47.08s)\tAverage loss=0.000182\tDev F1=32.99\n",
      "[SparseLogisticRegression] Epoch 80 (49.15s)\tAverage loss=0.000142\tDev F1=32.74\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 85 (51.52s)\tAverage loss=0.000116\tDev F1=32.74\n",
      "[SparseLogisticRegression] Epoch 90 (53.59s)\tAverage loss=0.000093\tDev F1=32.74\n",
      "[SparseLogisticRegression] Epoch 95 (55.71s)\tAverage loss=0.000075\tDev F1=32.70\n",
      "[SparseLogisticRegression] Epoch 99 (57.37s)\tAverage loss=0.000063\tDev F1=32.79\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (58.07s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.327868852459\n",
      "============================================================\n",
      "[9] Testing dim = 128, dropout = 2.50e-01, batch_size = 16, n_epochs = 25, lr = 1.00e-04, rebalance = 2.50e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=5388  #epochs=25  batch size=16\n",
      "[SparseLogisticRegression] Epoch 0 (1.07s)\tAverage loss=0.766629\tDev F1=12.34\n",
      "[SparseLogisticRegression] Epoch 5 (6.42s)\tAverage loss=0.479163\tDev F1=16.39\n",
      "[SparseLogisticRegression] Epoch 10 (12.19s)\tAverage loss=0.358678\tDev F1=29.87\n",
      "[SparseLogisticRegression] Epoch 15 (17.74s)\tAverage loss=0.280629\tDev F1=37.00\n",
      "[SparseLogisticRegression] Epoch 20 (23.52s)\tAverage loss=0.227751\tDev F1=40.41\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 24 (28.40s)\tAverage loss=0.196721\tDev F1=42.30\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (28.93s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.422976501305\n",
      "============================================================\n",
      "[10] Testing dim = 128, dropout = 5.00e-01, batch_size = 16, n_epochs = 50, lr = 1.00e-02, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=2694  #epochs=50  batch size=16\n",
      "[SparseLogisticRegression] Epoch 0 (0.50s)\tAverage loss=0.581941\tDev F1=40.14\n",
      "[SparseLogisticRegression] Epoch 5 (3.14s)\tAverage loss=0.022819\tDev F1=34.73\n",
      "[SparseLogisticRegression] Epoch 10 (5.87s)\tAverage loss=0.010040\tDev F1=33.96\n",
      "[SparseLogisticRegression] Epoch 15 (8.58s)\tAverage loss=0.003066\tDev F1=33.20\n",
      "[SparseLogisticRegression] Epoch 20 (11.22s)\tAverage loss=0.001727\tDev F1=32.66\n",
      "[SparseLogisticRegression] Epoch 25 (14.02s)\tAverage loss=0.001092\tDev F1=32.90\n",
      "[SparseLogisticRegression] Epoch 30 (16.68s)\tAverage loss=0.002014\tDev F1=30.47\n",
      "[SparseLogisticRegression] Epoch 35 (19.63s)\tAverage loss=0.000407\tDev F1=28.70\n",
      "[SparseLogisticRegression] Epoch 40 (22.44s)\tAverage loss=0.000263\tDev F1=28.67\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 45 (25.65s)\tAverage loss=0.000177\tDev F1=28.35\n",
      "[SparseLogisticRegression] Epoch 49 (28.06s)\tAverage loss=0.008214\tDev F1=29.65\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (28.74s)\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1.0 Score: 0.296470588235\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_6>\n",
      "   dim  dropout  batch_size  n_epochs      lr  rebalance     Prec.      Rec.  \\\n",
      "6  128     0.10          16        50  0.0001       0.25  0.508287  0.469388   \n",
      "0   64     0.25          64        50  0.0010       0.25  0.433036  0.494898   \n",
      "5  128     0.10          32        50  0.0001       0.25  0.477273  0.428571   \n",
      "8  128     0.25          16        25  0.0001       0.25  0.433155  0.413265   \n",
      "1  128     0.50          16       100  0.0010       0.25  0.312903  0.494898   \n",
      "4  128     0.10          32        25  0.0100       0.00  0.378378  0.357143   \n",
      "2  128     0.10          32        25  0.0100       0.50  0.225000  0.642857   \n",
      "7  128     0.50          32       100  0.0100       0.50  0.217755  0.663265   \n",
      "3   64     0.50          32       100  0.0001       0.50  0.205882  0.642857   \n",
      "9  128     0.50          16        50  0.0100       0.50  0.192661  0.642857   \n",
      "\n",
      "      F-1.0  \n",
      "6  0.488064  \n",
      "0  0.461905  \n",
      "5  0.451613  \n",
      "8  0.422977  \n",
      "1  0.383399  \n",
      "4  0.367454  \n",
      "2  0.333333  \n",
      "7  0.327869  \n",
      "3  0.311881  \n",
      "9  0.296471  \n",
      "[SparseLogisticRegression] Model saved as <discriminative_spouse>\n",
      "### Done in 510.7s.\n",
      "\n",
      "### [7.2] Evaluate generative model (opt_b=0.5)\n",
      "### Done in 0.0s.\n",
      "\n",
      "### [7.3] Evaluate discriminative model (opt_b=0.5)\n",
      "### Done in 0.1s.\n",
      "\n",
      "      F1 Score  Precision    Recall\n",
      "Disc  0.470120   0.424460  0.526786\n",
      "Gen   0.444444   0.472362  0.419643\n",
      "CPU times: user 16min 30s, sys: 3min 25s, total: 19min 56s\n",
      "Wall time: 9min 17s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
