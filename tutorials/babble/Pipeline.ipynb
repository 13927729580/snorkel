{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'domain': 'drink',\n",
    "    'debug': True,\n",
    "    'postgres': False,\n",
    "    'parallelism': 1,\n",
    "    'splits': [0,1,2],\n",
    "    'disc_model_class': 'logreg',\n",
    "    'supervision': 'generative',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$SNORKELDB = sqlite:///babble_drink_debug.db\n"
     ]
    }
   ],
   "source": [
    "# Get DB connection string and add to globals\n",
    "# NOTE: $SNORKELDB must be set before any snorkel imports\n",
    "import os\n",
    "\n",
    "default_db_name = 'babble_' + config['domain'] + ('_debug' if config.get('debug', False) else '')\n",
    "DB_NAME = config.get('db_name', default_db_name)\n",
    "if 'postgres' in config and config['postgres']:\n",
    "    DB_TYPE = 'postgres'\n",
    "else:\n",
    "    DB_TYPE = 'sqlite'\n",
    "    DB_NAME += '.db'\n",
    "DB_ADDR = \"localhost:{0}\".format(config['db_port']) if 'db_port' in config else \"\"\n",
    "os.environ['SNORKELDB'] = '{0}://{1}/{2}'.format(DB_TYPE, DB_ADDR, DB_NAME)\n",
    "print(\"$SNORKELDB = {0}\".format(os.environ['SNORKELDB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting splits=[0, 1] to splits=[0, 1, 2]\n",
      "Overwriting disc_model_class=inception_v3 to disc_model_class=logreg\n",
      "Overwriting epochs=[25, 50, 75] to epochs=[50]\n",
      "Overwriting step_size=[0.01, 0.001, 0.0001, 1e-05] to step_size=[1e-05]\n",
      "Overwriting reg_param=[0.0, 0.01, 0.1, 0.25, 0.5] to reg_param=[0.01]\n",
      "Overwriting decay=[0.9, 0.95, 0.99] to decay=[0.9]\n",
      "Overwriting lr=[0.01, 0.001, 0.0001] to lr=[50, 100]\n",
      "Overwriting babbler_candidate_split=1 to babbler_candidate_split=0\n",
      "Overwriting LF_acc_prior_weight_default=1.0 to LF_acc_prior_weight_default=0.5\n",
      "Overwriting decay=0.95 to decay=0.9\n",
      "Overwriting epochs=50 to epochs=100\n",
      "Overwriting reg_param=0.1 to reg_param=0.01\n",
      "Overwriting disc_model_class=lstm to disc_model_class=logreg\n",
      "Overwriting domain=None to domain=drink\n",
      "Overwriting tune_b=True to tune_b=False\n",
      "Overwriting debug=False to debug=True\n",
      "Overwriting gen_model_search_space=10 to gen_model_search_space=1\n",
      "NOTE: --debug=True: modifying parameters...\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Resolve config conflicts (nb_config > local_config > global_config)\n",
    "from snorkel.contrib.babble.pipelines import merge_configs, get_local_pipeline\n",
    "config = merge_configs(config)\n",
    "\n",
    "if config['debug']:\n",
    "    print(\"NOTE: --debug=True: modifying parameters...\")\n",
    "    config['max_docs'] = 100\n",
    "    config['gen_model_search_space'] = 2\n",
    "    config['disc_model_search_space'] = 2\n",
    "    config['gen_params_default']['epochs'] = 25\n",
    "    config['disc_params_default']['n_epochs'] = 5\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "candidate_class = candidate_subclass(config['candidate_name'], config['candidate_entities'])\n",
    "\n",
    "pipeline = get_local_pipeline(config['domain'])\n",
    "pipe = pipeline(session, candidate_class, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "Running UDF...\n",
      "CPU times: user 19.8 s, sys: 520 ms, total: 20.3 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction was performed during parse stage.\n",
      "Candidates [Split 0]: 15711\n",
      "Candidates [Split 1]: 3377\n",
      "Candidates [Split 2]: 0\n",
      "CPU times: user 16 ms, sys: 16 ms, total: 32 ms\n",
      "Wall time: 18.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time pipe.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train CSV!\n",
      "Num HITs unique: 1525\n",
      "Num HITs total: 3050\n",
      "Unanimous: 4542\n",
      "Majority: 2211\n",
      "Bad: 450\n",
      "Reading val CSV!\n",
      "Num HITs unique: 184\n",
      "Num HITs total: 368\n",
      "Unanimous: 474\n",
      "Majority: 318\n",
      "Bad: 100\n",
      "AnnotatorLabels created: 5648\n",
      "AnnotatorLabels created: 634\n",
      "CPU times: user 59.2 s, sys: 552 ms, total: 59.8 s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.load_gold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %time pipe.featurize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train CSV!\n",
      "Num HITs unique: 44\n",
      "Num HITs total: 132\n",
      "Unanimous: 112\n",
      "Majority: 54\n",
      "Bad: 37\n",
      "Building list of target candidate ids...\n",
      "Collected 139 unique target candidate ids from 370 explanations.\n",
      "Gathering desired candidates...\n",
      "Found 139/139 desired candidates\n",
      "Linking explanations to candidates...\n",
      "Linked 370/370 explanations\n",
      "Calling babbler...\n",
      "WARNING: Number of candidates (3377) does not equal the number of pos (168) + neg (466) = 634 labels.\n",
      "Flushing all parses from previous explanation set.\n",
      "Created grammar with 453 rules\n",
      "121 explanation(s) out of 370 were parseable.\n",
      "171 parse(s) generated from 370 explanation(s).\n",
      "49 parse(s) remain (122 parse(s) removed by DuplicateSemanticsFilter).\n",
      "24 parse(s) remain (25 parse(s) removed by ConsistencyFilter).\n",
      "### Applying labeling functions to split 1\n",
      "[========================================] 100%\n",
      "\n",
      "### Done in 4.6s.\n",
      "\n",
      "18 parse(s) remain (6 parse(s) removed by UniformSignatureFilter: (0 None, 6 All)).\n",
      "14 parse(s) remain (4 parse(s) removed by DuplicateSignatureFilter).\n",
      "Added 14 parse(s) from 13 explanations to set. (Total # parses = 14)\n",
      "CPU times: user 16.5 s, sys: 1.42 s, total: 17.9 s\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Labeled split 0: (15711,14) sparse (nnz = 87722)\n",
      "\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Labeled split 1: (3377,14) sparse (nnz = 18749)\n",
      "\n",
      "                   j  Coverage  Overlaps  Conflicts   TP   FP   FN   TN  \\\n",
      "Explanation3_0     0  0.859639  0.859639   0.859639    0    0   87  332   \n",
      "Explanation5_0     1  0.058632  0.058632   0.058632   54  103    0    0   \n",
      "Explanation6_2     2  0.852236  0.852236   0.851051  158  433    0    0   \n",
      "Explanation9_0     3  0.038496  0.038496   0.037903   31   47    0    0   \n",
      "Explanation38_0    4  0.514658  0.514658   0.513473  129  325    0    0   \n",
      "Explanation42_1    5  0.481492  0.481492   0.480308   73  246    0    0   \n",
      "Explanation51_0    6  0.159313  0.159313   0.159017   70  139    0    0   \n",
      "Explanation61_0    7  0.326917  0.326917   0.325733   89  149    0    0   \n",
      "Explanation61_1    8  0.156648  0.156648   0.155760   58  162    0    0   \n",
      "Explanation126_0   9  0.904649  0.904649   0.904649    0    0  165  428   \n",
      "Explanation127_0  10  0.517323  0.517323   0.517323   93  220    0    0   \n",
      "Explanation137_0  11  0.047379  0.047379   0.046787   18   46    0    0   \n",
      "Explanation143_0  12  0.148060  0.148060   0.148060    0    0   10   33   \n",
      "Explanation187_0  13  0.486527  0.486527   0.486527    0    0   39  142   \n",
      "\n",
      "                  Empirical Acc.  \n",
      "Explanation3_0          0.792363  \n",
      "Explanation5_0          0.343949  \n",
      "Explanation6_2          0.267343  \n",
      "Explanation9_0          0.397436  \n",
      "Explanation38_0         0.284141  \n",
      "Explanation42_1         0.228840  \n",
      "Explanation51_0         0.334928  \n",
      "Explanation61_0         0.373950  \n",
      "Explanation61_1         0.263636  \n",
      "Explanation126_0        0.721754  \n",
      "Explanation127_0        0.297125  \n",
      "Explanation137_0        0.281250  \n",
      "Explanation143_0        0.767442  \n",
      "Explanation187_0        0.784530  \n",
      "CPU times: user 2min 1s, sys: 800 ms, total: 2min 2s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%time pipe.label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using L_train: <15711x14 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 87722 stored elements in Compressed Sparse Row format>\n",
      "Using L_gold_train: <15711x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 5648 stored elements in Compressed Sparse Row format>\n",
      "Positive Fraction: 7.5%\n",
      "\n",
      "Using L_dev: <3377x14 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 18749 stored elements in Compressed Sparse Row format>\n",
      "Using L_gold_dev: <3377x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 634 stored elements in Compressed Sparse Row format>\n",
      "Positive Fraction: 5.0%\n",
      "\n",
      "Using L_test: <0x14 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 0 stored elements in Compressed Sparse Row format>\n",
      "Using L_gold_test: <0x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 0 stored elements in Compressed Sparse Row format>\n",
      "============================================================\n",
      "[1] Testing epochs = 50, step_size = 1.00e-05, reg_param = 1.00e-02, decay = 9.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "too many arguments: expected 6, got 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-398a769740bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time pipe.supervise()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/paroma/anaconda2/envs/babble/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/contrib/babble/pipelines/snorkel_pipeline.py\u001b[0m in \u001b[0;36msupervise\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reports_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen_f_beta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mtune_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tune_b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             )\n\u001b[1;32m    278\u001b[0m             \u001b[0mtrain_marginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarginals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/contrib/babble/utils.pyc\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_class, X_train, Y_train, X_dev, Y_dev, search_size, search_params, rand_seed, n_threads, verbose, cardinality, params_default, model_init_params, model_name, save_dir, beta, eval_batch_size, tune_b)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Run random grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             model, run_stats, opt_b = searcher.fit(X_dev, Y_dev, n_threads=n_threads,\n\u001b[0;32m--> 131\u001b[0;31m                 beta=beta, eval_batch_size=eval_batch_size)\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/utils.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_valid, Y_valid, b, beta, set_unlabeled_as_neg, n_threads, eval_batch_size)\u001b[0m\n\u001b[1;32m    405\u001b[0m             opt_model, run_stats = self._fit_st(X_valid, Y_valid, b=b, \n\u001b[1;32m    406\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_unlabeled_as_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_unlabeled_as_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 eval_batch_size=eval_batch_size)\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mopt_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/utils.pyc\u001b[0m in \u001b[0;36m_fit_st\u001b[0;34m(self, X_valid, Y_valid, b, beta, set_unlabeled_as_neg, eval_batch_size)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                     run_scores = model.score(X_valid, Y_valid, b=b, beta=beta,\n\u001b[1;32m    464\u001b[0m                         \u001b[0mset_unlabeled_as_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_unlabeled_as_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/snorkel/learning/gen_learning.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, L, deps, LF_acc_prior_weights, LF_acc_prior_weight_default, labels, label_prior_weight, init_deps, init_class_prior, epochs, step_size, decay, reg_param, reg_type, verbose, truncation, burn_in, cardinality, timer, candidate_ranges, threads)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         )\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadFactorGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/paroma/numbskull/numbskull/numbskull.py\u001b[0m in \u001b[0;36mloadFactorGraph\u001b[0;34m(self, weight, variable, factor, fmap, domain_mask, edges, var_copies, weight_copies, factors_to_skip)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Numba-based method. Defined in dataloading.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         compute_var_map(variable, factor, fmap, vmap,\n\u001b[0;32m--> 237\u001b[0;31m                         factor_index, domain_mask, factors_to_skip)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         fg = FactorGraph(weight, variable, factor, fmap, vmap, factor_index,\n",
      "\u001b[0;31mTypeError\u001b[0m: too many arguments: expected 6, got 7"
     ]
    }
   ],
   "source": [
    "%time pipe.supervise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config['display_marginals'] = False\n",
    "config['download_data'] = False\n",
    "config['disc_model_class'] = 'inception_v3'\n",
    "\n",
    "%time pipe.classify(slim_ws_path='/dfs/scratch0/paroma/slim_new/slim_ws/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
